{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_ReLu(number):\n",
    "    if number > 0:\n",
    "        return number\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def activation_ReLu_partial_derivative(number):\n",
    "    if number > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_data():\n",
    "    result = []\n",
    "\n",
    "    for x in range(1000):\n",
    "        n1 = np.random.randint(0, 5)\n",
    "        n2 = np.random.randint(3, 7)\n",
    "\n",
    "        n3 = n1 ** 2 + n2 + np.random.randint(0, 5)\n",
    "        n3 = int(n3)\n",
    "\n",
    "        result.append([n1, n2, n3])\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assign valuesw1 to w6\n",
    "w1 = 1\n",
    "w2 = 0.5\n",
    "w3 = 1\n",
    "w4 = -0.5\n",
    "w5 = 1\n",
    "w6 = 1\n",
    "\n",
    "# and three biases\n",
    "bias1 = 0.5\n",
    "bias2 = 0\n",
    "bias3 = 0.5\n",
    "\n",
    "# We store the original weights and biases\n",
    "w1_initial = w1\n",
    "w2_initial = w2\n",
    "w3_initial = w3\n",
    "w4_initial = w4\n",
    "w5_initial = w5\n",
    "w6_initial = w6\n",
    "bias1_initial = bias1\n",
    "bias2_initial = bias2\n",
    "bias3_initial = bias3\n",
    "\n",
    "# Training Parameters\n",
    "LR = 0.001\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "# Dataset for training\n",
    "data = [\n",
    "    [1, 0, 2],\n",
    "    [2, 1, 6],\n",
    "    [3, 3, 17]\n",
    "]\n",
    "\n",
    "data = generate_train_data()\n",
    "\n",
    "# Initialize a list for loss points\n",
    "loss_points = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss 2.9427171004048756\n",
      "Epoch: 2, loss 2.0433637200866253\n",
      "Epoch: 3, loss 1.6190514982084165\n",
      "Epoch: 4, loss 1.3325815266622096\n",
      "Epoch: 5, loss 1.1416224153047128\n",
      "Epoch: 6, loss 1.0181940044765438\n",
      "Epoch: 7, loss 0.9409862884226627\n",
      "Epoch: 8, loss 0.8425194298764365\n",
      "Epoch: 9, loss 0.8223768365435706\n",
      "Epoch: 10, loss 0.7648932353197188\n",
      "Epoch: 11, loss 0.7315647188151484\n",
      "Epoch: 12, loss 0.7176732779427653\n",
      "Epoch: 13, loss 0.698427308759479\n",
      "Epoch: 14, loss 0.6836502086793245\n",
      "Epoch: 15, loss 0.6721223037713461\n",
      "Epoch: 16, loss 0.6633180932325573\n",
      "Epoch: 17, loss 0.6562559206670171\n",
      "Epoch: 18, loss 0.6503636895238597\n",
      "Epoch: 19, loss 0.6455474782901902\n",
      "Epoch: 20, loss 0.6414810051541481\n",
      "Epoch: 21, loss 0.6379854045867677\n",
      "Epoch: 22, loss 0.6349659205316343\n",
      "Epoch: 23, loss 0.6323499816605345\n",
      "Epoch: 24, loss 0.6300804181431555\n",
      "Epoch: 25, loss 0.6281109898010317\n",
      "Epoch: 26, loss 0.6264034334297204\n",
      "Epoch: 27, loss 0.6249254994798784\n",
      "Epoch: 28, loss 0.6236496251576639\n",
      "Epoch: 29, loss 0.6225520141058885\n",
      "Epoch: 30, loss 0.6216119759503432\n",
      "Epoch: 31, loss 0.6208114335810314\n",
      "Epoch: 32, loss 0.620134540991621\n",
      "Epoch: 33, loss 0.61956737638883\n",
      "Epoch: 34, loss 0.6190976887290758\n",
      "Epoch: 35, loss 0.6185138002319512\n",
      "Epoch: 36, loss 0.6181093816111647\n",
      "Epoch: 37, loss 0.6178528848846422\n",
      "Epoch: 38, loss 0.6176918294544457\n",
      "Epoch: 39, loss 0.6175978111345887\n",
      "Epoch: 40, loss 0.6175549710878472\n",
      "Epoch: 41, loss 0.6175539530969794\n",
      "Epoch: 42, loss 0.6175887749306391\n",
      "Epoch: 43, loss 0.6176552255057645\n",
      "Epoch: 44, loss 0.6177500530244119\n",
      "Epoch: 45, loss 0.6178705583151323\n",
      "Epoch: 46, loss 0.6180143927881353\n",
      "Epoch: 47, loss 0.6181794578891596\n",
      "Epoch: 48, loss 0.6183638537843433\n",
      "Epoch: 49, loss 0.6185658512548695\n",
      "Epoch: 50, loss 0.6187838741543489\n",
      "Epoch: 51, loss 0.619016486487117\n",
      "Epoch: 52, loss 0.6192623814558397\n",
      "Epoch: 53, loss 0.6195203713918163\n",
      "Epoch: 54, loss 0.6197893781915054\n",
      "Epoch: 55, loss 0.6200684241809926\n",
      "Epoch: 56, loss 0.6203566234355344\n",
      "Epoch: 57, loss 0.6206531736037048\n",
      "Epoch: 58, loss 0.6209573482755415\n",
      "Epoch: 59, loss 0.6212684899150069\n",
      "Epoch: 60, loss 0.6215860033577699\n",
      "Epoch: 61, loss 0.6219093498612948\n",
      "Epoch: 62, loss 0.6222380416826372\n",
      "Epoch: 63, loss 0.6225716371533929\n",
      "Epoch: 64, loss 0.6229097362172339\n",
      "Epoch: 65, loss 0.6232519763941083\n",
      "Epoch: 66, loss 0.6235980291352029\n",
      "Epoch: 67, loss 0.6239475965342622\n",
      "Epoch: 68, loss 0.6243004083620304\n",
      "Epoch: 69, loss 0.6246562193935756\n",
      "Epoch: 70, loss 0.6250148069997616\n",
      "Epoch: 71, loss 0.6253759689770949\n",
      "Epoch: 72, loss 0.6257395215921362\n",
      "Epoch: 73, loss 0.6261052978190337\n",
      "Epoch: 74, loss 0.6264731457506795\n",
      "Epoch: 75, loss 0.6268429271660855\n",
      "Epoch: 76, loss 0.627214516238072\n",
      "Epoch: 77, loss 0.6275877983670427\n",
      "Epoch: 78, loss 0.6279626691284859\n",
      "Epoch: 79, loss 0.6283390333221474\n",
      "Epoch: 80, loss 0.6287168041133047\n",
      "Epoch: 81, loss 0.6290959022563571\n",
      "Epoch: 82, loss 0.6294762553929538\n",
      "Epoch: 83, loss 0.6298577974169629\n",
      "Epoch: 84, loss 0.6302404678998174\n",
      "Epoch: 85, loss 0.6306242115701662\n",
      "Epoch: 86, loss 0.6310089778425788\n",
      "Epoch: 87, loss 0.6313947203905591\n",
      "Epoch: 88, loss 0.6317813967593164\n",
      "Epoch: 89, loss 0.632168968014747\n",
      "Epoch: 90, loss 0.6325573984248738\n",
      "Epoch: 91, loss 0.6329466551708302\n",
      "Epoch: 92, loss 0.6333367080843332\n",
      "Epoch: 93, loss 0.6337275294093591\n",
      "Epoch: 94, loss 0.6341190935855765\n",
      "Epoch: 95, loss 0.6345113770515072\n",
      "Epoch: 96, loss 0.6349043580655314\n",
      "Epoch: 97, loss 0.6352980165432024\n",
      "Epoch: 98, loss 0.6356923339091451\n",
      "Epoch: 99, loss 0.6360872929623569\n",
      "Epoch: 100, loss 0.6364828777535216\n",
      "Epoch: 101, loss 0.6368790734733621\n",
      "Epoch: 102, loss 0.6372758663509728\n",
      "Epoch: 103, loss 0.6376732435611063\n",
      "Epoch: 104, loss 0.6380711931398297\n",
      "Epoch: 105, loss 0.638469703907473\n",
      "Epoch: 106, loss 0.6388687653986341\n",
      "Epoch: 107, loss 0.6392683677980642\n",
      "Epoch: 108, loss 0.6396685018824435\n",
      "Epoch: 109, loss 0.6400691589671768\n",
      "Epoch: 110, loss 0.6404703308578267\n",
      "Epoch: 111, loss 0.6408720098058212\n",
      "Epoch: 112, loss 0.6412741884680903\n",
      "Epoch: 113, loss 0.6416768598701168\n",
      "Epoch: 114, loss 0.6420800173723404\n",
      "Epoch: 115, loss 0.6424836546394096\n",
      "Epoch: 116, loss 0.6428877656120942\n",
      "Epoch: 117, loss 0.6432923444817042\n",
      "Epoch: 118, loss 0.6436973856667132\n",
      "Epoch: 119, loss 0.6441028837914129\n",
      "Epoch: 120, loss 0.6445088336664055\n",
      "Epoch: 121, loss 0.644915230270823\n",
      "Epoch: 122, loss 0.6453220687361269\n",
      "Epoch: 123, loss 0.6457293443312389\n",
      "Epoch: 124, loss 0.6461370524489843\n",
      "Epoch: 125, loss 0.6465451885938248\n",
      "Epoch: 126, loss 0.6469537483705963\n",
      "Epoch: 127, loss 0.6473627274741641\n",
      "Epoch: 128, loss 0.6477721216800939\n",
      "Epoch: 129, loss 0.6481819268361273\n",
      "Epoch: 130, loss 0.6485921388544164\n",
      "Epoch: 131, loss 0.6490027537043829\n",
      "Epoch: 132, loss 0.649413767406315\n",
      "Epoch: 133, loss 0.6498251760255018\n",
      "Epoch: 134, loss 0.6502369756668265\n",
      "Epoch: 135, loss 0.6506491624700144\n",
      "Epoch: 136, loss 0.651061732605136\n",
      "Epoch: 137, loss 0.6514746822686744\n",
      "Epoch: 138, loss 0.6518880076798793\n",
      "Epoch: 139, loss 0.652301705077497\n",
      "Epoch: 140, loss 0.6527157707167655\n",
      "Epoch: 141, loss 0.6531302008667936\n",
      "Epoch: 142, loss 0.6535449918080971\n",
      "Epoch: 143, loss 0.6539601398304504\n",
      "Epoch: 144, loss 0.654375641230914\n",
      "Epoch: 145, loss 0.6547914923121104\n",
      "Epoch: 146, loss 0.6552076893806128\n",
      "Epoch: 147, loss 0.6556242287455996\n",
      "Epoch: 148, loss 0.6560411067175311\n",
      "Epoch: 149, loss 0.6564583196071692\n",
      "Epoch: 150, loss 0.6568758637244781\n",
      "Epoch: 151, loss 0.6572937353778486\n",
      "Epoch: 152, loss 0.6577119308733187\n",
      "Epoch: 153, loss 0.6581304465139496\n",
      "Epoch: 154, loss 0.6585492785992638\n",
      "Epoch: 155, loss 0.6589684234247573\n",
      "Epoch: 156, loss 0.6593878772815258\n",
      "Epoch: 157, loss 0.6598076364559033\n",
      "Epoch: 158, loss 0.6602276972292139\n",
      "Epoch: 159, loss 0.6606480558775935\n",
      "Epoch: 160, loss 0.6610687086717706\n",
      "Epoch: 161, loss 0.6614896518770091\n",
      "Epoch: 162, loss 0.66191088175301\n",
      "Epoch: 163, loss 0.6623323945538938\n",
      "Epoch: 164, loss 0.6627541865281725\n",
      "Epoch: 165, loss 0.663176253918923\n",
      "Epoch: 166, loss 0.663598592963632\n",
      "Epoch: 167, loss 0.6640211998944628\n",
      "Epoch: 168, loss 0.664444070938349\n",
      "Epoch: 169, loss 0.6648672023170424\n",
      "Epoch: 170, loss 0.6652905902473758\n",
      "Epoch: 171, loss 0.6657142309413511\n",
      "Epoch: 172, loss 0.6661381206064042\n",
      "Epoch: 173, loss 0.6665622554455343\n",
      "Epoch: 174, loss 0.6669866316575458\n",
      "Epoch: 175, loss 0.6674112454373076\n",
      "Epoch: 176, loss 0.6678360929758848\n",
      "Epoch: 177, loss 0.668261170460921\n",
      "Epoch: 178, loss 0.66868647407672\n",
      "Epoch: 179, loss 0.6691120000046626\n",
      "Epoch: 180, loss 0.6695377444233079\n",
      "Epoch: 181, loss 0.6699637035087764\n",
      "Epoch: 182, loss 0.6703898734349216\n",
      "Epoch: 183, loss 0.6708162503736687\n",
      "Epoch: 184, loss 0.6712428304951981\n",
      "Epoch: 185, loss 0.6716696099683037\n",
      "Epoch: 186, loss 0.672096584960583\n",
      "Epoch: 187, loss 0.6725237516387558\n",
      "Epoch: 188, loss 0.6729511061688965\n",
      "Epoch: 189, loss 0.6733786447167425\n",
      "Epoch: 190, loss 0.6738063634478806\n",
      "Epoch: 191, loss 0.6742342585281328\n",
      "Epoch: 192, loss 0.6746623261236856\n",
      "Epoch: 193, loss 0.6750905624014654\n",
      "Epoch: 194, loss 0.6755189635292861\n",
      "Epoch: 195, loss 0.6759475256762085\n",
      "Epoch: 196, loss 0.6763762450127065\n",
      "Epoch: 197, loss 0.6768051177110102\n",
      "Epoch: 198, loss 0.6772341399452202\n",
      "Epoch: 199, loss 0.6776633078916994\n",
      "Epoch: 200, loss 0.6780926177292114\n",
      "Epoch: 201, loss 0.6785220656391608\n",
      "Epoch: 202, loss 0.6789516478059032\n",
      "Epoch: 203, loss 0.6793813604168982\n",
      "Epoch: 204, loss 0.6798111996629624\n",
      "Epoch: 205, loss 0.6802411617385048\n",
      "Epoch: 206, loss 0.6806712428417165\n",
      "Epoch: 207, loss 0.681101439174802\n",
      "Epoch: 208, loss 0.681531746944216\n",
      "Epoch: 209, loss 0.6819621623608368\n",
      "Epoch: 210, loss 0.6823926816401521\n",
      "Epoch: 211, loss 0.6828233010025381\n",
      "Epoch: 212, loss 0.6832540166733765\n",
      "Epoch: 213, loss 0.6836848248832813\n",
      "Epoch: 214, loss 0.6841157218682988\n",
      "Epoch: 215, loss 0.6845467038700649\n",
      "Epoch: 216, loss 0.6849777671359819\n",
      "Epoch: 217, loss 0.6854089079195015\n",
      "Epoch: 218, loss 0.6858401224801184\n",
      "Epoch: 219, loss 0.6862714070837079\n",
      "Epoch: 220, loss 0.6867027580025913\n",
      "Epoch: 221, loss 0.6871341715157374\n",
      "Epoch: 222, loss 0.6875656439089597\n",
      "Epoch: 223, loss 0.6879971714749885\n",
      "Epoch: 224, loss 0.6884287505136977\n",
      "Epoch: 225, loss 0.6888603773322255\n",
      "Epoch: 226, loss 0.6892920482451546\n",
      "Epoch: 227, loss 0.6897237595746035\n",
      "Epoch: 228, loss 0.6901555076503784\n",
      "Epoch: 229, loss 0.6905872888102006\n",
      "Epoch: 230, loss 0.6910190993997116\n",
      "Epoch: 231, loss 0.6914509357726774\n",
      "Epoch: 232, loss 0.6918827942911177\n",
      "Epoch: 233, loss 0.6923146713254114\n",
      "Epoch: 234, loss 0.6927465632544489\n",
      "Epoch: 235, loss 0.6931784664657036\n",
      "Epoch: 236, loss 0.6936103773554074\n",
      "Epoch: 237, loss 0.6940422923286588\n",
      "Epoch: 238, loss 0.694474207799451\n",
      "Epoch: 239, loss 0.6949061201909223\n",
      "Epoch: 240, loss 0.6953380259353495\n",
      "Epoch: 241, loss 0.6957699214743208\n",
      "Epoch: 242, loss 0.6962018032587781\n",
      "Epoch: 243, loss 0.6966336677491721\n",
      "Epoch: 244, loss 0.6970655114155466\n",
      "Epoch: 245, loss 0.6974973307376227\n",
      "Epoch: 246, loss 0.6979291222049071\n",
      "Epoch: 247, loss 0.6983608823167238\n",
      "Epoch: 248, loss 0.6987926075824469\n",
      "Epoch: 249, loss 0.699224294521402\n",
      "Epoch: 250, loss 0.6996559396630702\n",
      "Epoch: 251, loss 0.700087539547197\n",
      "Epoch: 252, loss 0.7005190907237477\n",
      "Epoch: 253, loss 0.7009505897530997\n",
      "Epoch: 254, loss 0.7013820332060687\n",
      "Epoch: 255, loss 0.7018134176639778\n",
      "Epoch: 256, loss 0.702244739718784\n",
      "Epoch: 257, loss 0.7026759959730646\n",
      "Epoch: 258, loss 0.7031071830401624\n",
      "Epoch: 259, loss 0.7035382975442245\n",
      "Epoch: 260, loss 0.7039693361202776\n",
      "Epoch: 261, loss 0.7044002954142549\n",
      "Epoch: 262, loss 0.7048311720831008\n",
      "Epoch: 263, loss 0.7052619627948401\n",
      "Epoch: 264, loss 0.7056926642285877\n",
      "Epoch: 265, loss 0.7061232730746534\n",
      "Epoch: 266, loss 0.706553786034564\n",
      "Epoch: 267, loss 0.7069841998211859\n",
      "Epoch: 268, loss 0.7074145111586582\n",
      "Epoch: 269, loss 0.7078447167825688\n",
      "Epoch: 270, loss 0.7082748134399176\n",
      "Epoch: 271, loss 0.7087047978892337\n",
      "Epoch: 272, loss 0.709134666900579\n",
      "Epoch: 273, loss 0.7095644172555654\n",
      "Epoch: 274, loss 0.7099940457475437\n",
      "Epoch: 275, loss 0.7104235491814462\n",
      "Epoch: 276, loss 0.7108529243739712\n",
      "Epoch: 277, loss 0.7112821681535928\n",
      "Epoch: 278, loss 0.7117112773606012\n",
      "Epoch: 279, loss 0.7121402488470956\n",
      "Epoch: 280, loss 0.7125690794771137\n",
      "Epoch: 281, loss 0.7133821373951401\n",
      "Epoch: 282, loss 0.7140238285404443\n",
      "Epoch: 283, loss 0.7145757859664744\n",
      "Epoch: 284, loss 0.7151133511069083\n",
      "Epoch: 285, loss 0.7156401979844096\n",
      "Epoch: 286, loss 0.7161587838848523\n",
      "Epoch: 287, loss 0.7166707994669657\n",
      "Epoch: 288, loss 0.716637605033184\n",
      "Epoch: 289, loss 0.7169844546699979\n",
      "Epoch: 290, loss 0.7173421348614024\n",
      "Epoch: 291, loss 0.7177064863941419\n",
      "Epoch: 292, loss 0.7184285583983979\n",
      "Epoch: 293, loss 0.7189027416494755\n",
      "Epoch: 294, loss 0.7193659183784867\n",
      "Epoch: 295, loss 0.7198207226812753\n",
      "Epoch: 296, loss 0.7202687435636627\n",
      "Epoch: 297, loss 0.7207111411550133\n",
      "Epoch: 298, loss 0.7211487397171429\n",
      "Epoch: 299, loss 0.7215821204754975\n",
      "Epoch: 300, loss 0.7220116965948339\n",
      "Epoch: 301, loss 0.7224377679098504\n",
      "Epoch: 302, loss 0.7228884498939135\n",
      "Epoch: 303, loss 0.7231606592980604\n",
      "Epoch: 304, loss 0.723582996739152\n",
      "Epoch: 305, loss 0.7241531766458214\n",
      "Epoch: 306, loss 0.7244855542459568\n",
      "Epoch: 307, loss 0.7248825792830869\n",
      "Epoch: 308, loss 0.7252702977975413\n",
      "Epoch: 309, loss 0.7247965152584555\n",
      "Epoch: 310, loss 0.7250024939058576\n",
      "Epoch: 311, loss 0.72521385697435\n",
      "Epoch: 312, loss 0.7110015178833857\n",
      "Epoch: 313, loss 0.7117645325368704\n",
      "Epoch: 314, loss 0.7167021394216082\n",
      "Epoch: 315, loss 0.7168284596931984\n",
      "Epoch: 316, loss 0.7172987243162531\n",
      "Epoch: 317, loss 0.7179559288708639\n",
      "Epoch: 318, loss 0.7182015213704865\n",
      "Epoch: 319, loss 0.7185372965988908\n",
      "Epoch: 320, loss 0.7188368871445313\n",
      "Epoch: 321, loss 0.7190671835706345\n",
      "Epoch: 322, loss 0.7190416547852636\n",
      "Epoch: 323, loss 0.7194038655957418\n",
      "Epoch: 324, loss 0.7197296201430685\n",
      "Epoch: 325, loss 0.7200310129369584\n",
      "Epoch: 326, loss 0.7202982576222923\n",
      "Epoch: 327, loss 0.720493066890807\n",
      "Epoch: 328, loss 0.7207024930981821\n",
      "Epoch: 329, loss 0.7208936812215655\n",
      "Epoch: 330, loss 0.7210708907889366\n",
      "Epoch: 331, loss 0.7212366936247395\n",
      "Epoch: 332, loss 0.7213626304707987\n",
      "Epoch: 333, loss 0.7214797675126537\n",
      "Epoch: 334, loss 0.7215744228412202\n",
      "Epoch: 335, loss 0.7215813435034828\n",
      "Epoch: 336, loss 0.7216326289399249\n",
      "Epoch: 337, loss 0.7216691408465477\n",
      "Epoch: 338, loss 0.7217019417009937\n",
      "Epoch: 339, loss 0.7217308128009822\n",
      "Epoch: 340, loss 0.7217578953299405\n",
      "Epoch: 341, loss 0.7217842486100955\n",
      "Epoch: 342, loss 0.7218103960146274\n",
      "Epoch: 343, loss 0.7218314618069341\n",
      "Epoch: 344, loss 0.7218727717674491\n",
      "Epoch: 345, loss 0.7219200120346259\n",
      "Epoch: 346, loss 0.7211671317876913\n",
      "Epoch: 347, loss 0.721173647076984\n",
      "Epoch: 348, loss 0.7211697735088447\n",
      "Epoch: 349, loss 0.7211603989914318\n",
      "Epoch: 350, loss 0.7211498304012177\n",
      "Epoch: 351, loss 0.7211400063993297\n",
      "Epoch: 352, loss 0.7211317634612914\n",
      "Epoch: 353, loss 0.7211254167234882\n",
      "Epoch: 354, loss 0.7211210302990855\n",
      "Epoch: 355, loss 0.7211185466379514\n",
      "Epoch: 356, loss 0.7211279021701832\n",
      "Epoch: 357, loss 0.7211208849290774\n",
      "Epoch: 358, loss 0.7211136046622202\n",
      "Epoch: 359, loss 0.7211067263698475\n",
      "Epoch: 360, loss 0.7226451876817896\n",
      "Epoch: 361, loss 0.7227502249820269\n",
      "Epoch: 362, loss 0.7228640273589313\n",
      "Epoch: 363, loss 0.722982294185793\n",
      "Epoch: 364, loss 0.7230979172764508\n",
      "Epoch: 365, loss 0.7231273286421736\n",
      "Epoch: 366, loss 0.7232207115389405\n",
      "Epoch: 367, loss 0.7233058411139761\n",
      "Epoch: 368, loss 0.7233834571305342\n",
      "Epoch: 369, loss 0.7234547098486191\n",
      "Epoch: 370, loss 0.7237149547852499\n",
      "Epoch: 371, loss 0.7234871074040883\n",
      "Epoch: 372, loss 0.7237258949050659\n",
      "Epoch: 373, loss 0.7236764664030134\n",
      "Epoch: 374, loss 0.7234283362617371\n",
      "Epoch: 375, loss 0.7236550319932081\n",
      "Epoch: 376, loss 0.7236025666498564\n",
      "Epoch: 377, loss 0.7235485153057963\n",
      "Epoch: 378, loss 0.7234913046411403\n",
      "Epoch: 379, loss 0.7234358315367986\n",
      "Epoch: 380, loss 0.7233840595981218\n",
      "Epoch: 381, loss 0.7233366530659864\n",
      "Epoch: 382, loss 0.7232937000470822\n",
      "Epoch: 383, loss 0.7232550335809793\n",
      "Epoch: 384, loss 0.7232203782487246\n",
      "Epoch: 385, loss 0.723189419045527\n",
      "Epoch: 386, loss 0.7231618345456562\n",
      "Epoch: 387, loss 0.7231373130704869\n",
      "Epoch: 388, loss 0.7231155604361094\n",
      "Epoch: 389, loss 0.7233162144690137\n",
      "Epoch: 390, loss 0.723385832680774\n",
      "Epoch: 391, loss 0.7234613536768735\n",
      "Epoch: 392, loss 0.7235362314180597\n",
      "Epoch: 393, loss 0.7236074329156418\n",
      "Epoch: 394, loss 0.7236737966503239\n",
      "Epoch: 395, loss 0.7239360763583217\n",
      "Epoch: 396, loss 0.7236057462388004\n",
      "Epoch: 397, loss 0.7239752084955643\n",
      "Epoch: 398, loss 0.7236342119226992\n",
      "Epoch: 399, loss 0.7235852089494538\n",
      "Epoch: 400, loss 0.7239430858264725\n",
      "Epoch: 401, loss 0.7235938755956864\n",
      "Epoch: 402, loss 0.7235416090804393\n",
      "Epoch: 403, loss 0.7234906235159815\n",
      "Epoch: 404, loss 0.7234383099896826\n",
      "Epoch: 405, loss 0.7233882035886312\n",
      "Epoch: 406, loss 0.7233416454232553\n",
      "Epoch: 407, loss 0.7232990211258098\n",
      "Epoch: 408, loss 0.7232603026193396\n",
      "Epoch: 409, loss 0.7232252852402218\n",
      "Epoch: 410, loss 0.7231936945962972\n",
      "Epoch: 411, loss 0.7231652360574423\n",
      "Epoch: 412, loss 0.7231396181322105\n",
      "Epoch: 413, loss 0.7231165634964404\n",
      "Epoch: 414, loss 0.7230958139366555\n",
      "Epoch: 415, loss 0.7230771321727959\n",
      "Epoch: 416, loss 0.7230603020312211\n",
      "Epoch: 417, loss 0.7230451277365778\n",
      "Epoch: 418, loss 0.7230314327436945\n",
      "Epoch: 419, loss 0.723019058350143\n",
      "Epoch: 420, loss 0.7230078622309334\n",
      "Epoch: 421, loss 0.7229977169785827\n",
      "Epoch: 422, loss 0.722988508697662\n",
      "Epoch: 423, loss 0.7229801356808307\n",
      "Epoch: 424, loss 0.7229725071801528\n",
      "Epoch: 425, loss 0.7229655422786051\n",
      "Epoch: 426, loss 0.7229591688616299\n",
      "Epoch: 427, loss 0.7229533226850441\n",
      "Epoch: 428, loss 0.7229479465339181\n",
      "Epoch: 429, loss 0.7229429894660254\n",
      "Epoch: 430, loss 0.7229384061330414\n",
      "Epoch: 431, loss 0.7229341561725363\n",
      "Epoch: 432, loss 0.7230393007233604\n",
      "Epoch: 433, loss 0.7230777888336826\n",
      "Epoch: 434, loss 0.7231155544832395\n",
      "Epoch: 435, loss 0.7231509888604545\n",
      "Epoch: 436, loss 0.7231834410185155\n",
      "Epoch: 437, loss 0.7232127914130952\n",
      "Epoch: 438, loss 0.7232391485198415\n",
      "Epoch: 439, loss 0.7232627128475759\n",
      "Epoch: 440, loss 0.723283715852475\n",
      "Epoch: 441, loss 0.7233023922919738\n",
      "Epoch: 442, loss 0.7233189677368825\n",
      "Epoch: 443, loss 0.7233336531313236\n",
      "Epoch: 444, loss 0.7233466427367048\n",
      "Epoch: 445, loss 0.7233581137548736\n",
      "Epoch: 446, loss 0.7233682268026719\n",
      "Epoch: 447, loss 0.723377126816357\n",
      "Epoch: 448, loss 0.7233849441584267\n",
      "Epoch: 449, loss 0.7233917958000805\n",
      "Epoch: 450, loss 0.7233977865059493\n",
      "Epoch: 451, loss 0.7234030099786649\n",
      "Epoch: 452, loss 0.7234075499394581\n",
      "Epoch: 453, loss 0.723411481132861\n",
      "Epoch: 454, loss 0.7234148702504346\n",
      "Epoch: 455, loss 0.723417776773139\n",
      "Epoch: 456, loss 0.7234202537354372\n",
      "Epoch: 457, loss 0.7234223484145131\n",
      "Epoch: 458, loss 0.723424102950476\n",
      "Epoch: 459, loss 0.7234255549025911\n",
      "Epoch: 460, loss 0.7234267377472244\n",
      "Epoch: 461, loss 0.7234276813229188\n",
      "Epoch: 462, loss 0.7234284122278067\n",
      "Epoch: 463, loss 0.7234289541738822\n",
      "Epoch: 464, loss 0.7234293283029681\n",
      "Epoch: 465, loss 0.7234295534679924\n",
      "Epoch: 466, loss 0.7234296464835821\n",
      "Epoch: 467, loss 0.7234296223491042\n",
      "Epoch: 468, loss 0.7234294944470547\n",
      "Epoch: 469, loss 0.7234292747198443\n",
      "Epoch: 470, loss 0.7234289738269464\n",
      "Epoch: 471, loss 0.7234286012847377\n",
      "Epoch: 472, loss 0.7234281655909425\n",
      "Epoch: 473, loss 0.7234276743354968\n",
      "Epoch: 474, loss 0.72342713429899\n",
      "Epoch: 475, loss 0.7234265515404509\n",
      "Epoch: 476, loss 0.7234259314754047\n",
      "Epoch: 477, loss 0.7234252789454031\n",
      "Epoch: 478, loss 0.7234245982798555\n",
      "Epoch: 479, loss 0.7234238933511814\n",
      "Epoch: 480, loss 0.7234231676238417\n",
      "Epoch: 481, loss 0.72342242419807\n",
      "Epoch: 482, loss 0.7234216658487742\n",
      "Epoch: 483, loss 0.7234208950602513\n",
      "Epoch: 484, loss 0.7234201140570998\n",
      "Epoch: 485, loss 0.7234193248317304\n",
      "Epoch: 486, loss 0.7234185291689628\n",
      "Epoch: 487, loss 0.7234177286679522\n",
      "Epoch: 488, loss 0.7234169247616496\n",
      "Epoch: 489, loss 0.7234161187342862\n",
      "Epoch: 490, loss 0.7234153117368863\n",
      "Epoch: 491, loss 0.7234145048011565\n",
      "Epoch: 492, loss 0.7234136988518082\n",
      "Epoch: 493, loss 0.72341289471775\n",
      "Epoch: 494, loss 0.723412093141837\n",
      "Epoch: 495, loss 0.7234112947896808\n",
      "Epoch: 496, loss 0.7234105002576288\n",
      "Epoch: 497, loss 0.7234097100798157\n",
      "Epoch: 498, loss 0.7234089247342863\n",
      "Epoch: 499, loss 0.7234081446488457\n",
      "Epoch: 500, loss 0.723407370205942\n",
      "Epoch: 501, loss 0.7234066017473147\n",
      "Epoch: 502, loss 0.7234058395778618\n",
      "Epoch: 503, loss 0.7234050839694353\n",
      "Epoch: 504, loss 0.7234043351639662\n",
      "Epoch: 505, loss 0.7234035933764011\n",
      "Epoch: 506, loss 0.7234028587973198\n",
      "Epoch: 507, loss 0.7234021315952549\n",
      "Epoch: 508, loss 0.7234014119188202\n",
      "Epoch: 509, loss 0.7234006998985052\n",
      "Epoch: 510, loss 0.7233999956485001\n",
      "Epoch: 511, loss 0.7233992992681225\n",
      "Epoch: 512, loss 0.7233986108432192\n",
      "Epoch: 513, loss 0.7233979304473689\n",
      "Epoch: 514, loss 0.7233972581430486\n",
      "Epoch: 515, loss 0.7233965939825643\n",
      "Epoch: 516, loss 0.7233959380089819\n",
      "Epoch: 517, loss 0.7233952902569792\n",
      "Epoch: 518, loss 0.7233946507535226\n",
      "Epoch: 519, loss 0.7233940195185442\n",
      "Epoch: 520, loss 0.7233933965655521\n",
      "Epoch: 521, loss 0.7233927819021624\n",
      "Epoch: 522, loss 0.7233921755306489\n",
      "Epoch: 523, loss 0.7233915774482514\n",
      "Epoch: 524, loss 0.7233909876477803\n",
      "Epoch: 525, loss 0.7233904061177792\n",
      "Epoch: 526, loss 0.7233898328429788\n",
      "Epoch: 527, loss 0.7233892678046349\n",
      "Epoch: 528, loss 0.7233887109806556\n",
      "Epoch: 529, loss 0.7233881623460241\n",
      "Epoch: 530, loss 0.723387621872938\n",
      "Epoch: 531, loss 0.7233870895310142\n",
      "Epoch: 532, loss 0.7233865652875314\n",
      "Epoch: 533, loss 0.7233860491075745\n",
      "Epoch: 534, loss 0.7233855409542346\n",
      "Epoch: 535, loss 0.7233850407886505\n",
      "Epoch: 536, loss 0.7233845485703602\n",
      "Epoch: 537, loss 0.7233840642572095\n",
      "Epoch: 538, loss 0.7233835878055759\n",
      "Epoch: 539, loss 0.7233831191704654\n",
      "Epoch: 540, loss 0.7233826583056028\n",
      "Epoch: 541, loss 0.7233822051635771\n",
      "Epoch: 542, loss 0.7233817596958412\n",
      "Epoch: 543, loss 0.7233813218528088\n",
      "Epoch: 544, loss 0.7233808915840296\n",
      "Epoch: 545, loss 0.7233804688381471\n",
      "Epoch: 546, loss 0.723380053562989\n",
      "Epoch: 547, loss 0.7233796457057062\n",
      "Epoch: 548, loss 0.7233792452127067\n",
      "Epoch: 549, loss 0.7233788520298065\n",
      "Epoch: 550, loss 0.7233784661022048\n",
      "Epoch: 551, loss 0.7233780873746545\n",
      "Epoch: 552, loss 0.7233777157913461\n",
      "Epoch: 553, loss 0.7233773512960778\n",
      "Epoch: 554, loss 0.7233769938322185\n",
      "Epoch: 555, loss 0.7233766433427873\n",
      "Epoch: 556, loss 0.7233762997704947\n",
      "Epoch: 557, loss 0.7233759630577372\n",
      "Epoch: 558, loss 0.7233756331466763\n",
      "Epoch: 559, loss 0.723375309979201\n",
      "Epoch: 560, loss 0.7233749934970376\n",
      "Epoch: 561, loss 0.7233746836417192\n",
      "Epoch: 562, loss 0.7233743803546944\n",
      "Epoch: 563, loss 0.7233740835771943\n",
      "Epoch: 564, loss 0.7233737932504201\n",
      "Epoch: 565, loss 0.723373509315464\n",
      "Epoch: 566, loss 0.7233732317133824\n",
      "Epoch: 567, loss 0.7233729603852198\n",
      "Epoch: 568, loss 0.723372695271954\n",
      "Epoch: 569, loss 0.7233724363146237\n",
      "Epoch: 570, loss 0.7233721834542614\n",
      "Epoch: 571, loss 0.7233719366319723\n",
      "Epoch: 572, loss 0.7233716957888802\n",
      "Epoch: 573, loss 0.7233714608661871\n",
      "Epoch: 574, loss 0.7233712318052342\n",
      "Epoch: 575, loss 0.7233710085473994\n",
      "Epoch: 576, loss 0.7233707910342054\n",
      "Epoch: 577, loss 0.7233705792073443\n",
      "Epoch: 578, loss 0.723370373008587\n",
      "Epoch: 579, loss 0.7233701723799035\n",
      "Epoch: 580, loss 0.7233699772634037\n",
      "Epoch: 581, loss 0.7233697876014081\n",
      "Epoch: 582, loss 0.7233696033363772\n",
      "Epoch: 583, loss 0.7233694244110248\n",
      "Epoch: 584, loss 0.7233692507682161\n",
      "Epoch: 585, loss 0.7233690823510945\n",
      "Epoch: 586, loss 0.7233689191030026\n",
      "Epoch: 587, loss 0.7233687609674827\n",
      "Epoch: 588, loss 0.7233686078883733\n",
      "Epoch: 589, loss 0.7233684598097365\n",
      "Epoch: 590, loss 0.7233683166759186\n",
      "Epoch: 591, loss 0.7233681784314654\n",
      "Epoch: 592, loss 0.7233680450212913\n",
      "Epoch: 593, loss 0.7233679163905041\n",
      "Epoch: 594, loss 0.7233677924845384\n",
      "Epoch: 595, loss 0.7233676732491123\n",
      "Epoch: 596, loss 0.7233675586302286\n",
      "Epoch: 597, loss 0.7233674485742161\n",
      "Epoch: 598, loss 0.7233673430276635\n",
      "Epoch: 599, loss 0.7233672419375284\n",
      "Epoch: 600, loss 0.7233671452510405\n",
      "Epoch: 601, loss 0.7233670529157615\n",
      "Epoch: 602, loss 0.7233669648795618\n",
      "Epoch: 603, loss 0.72336688109068\n",
      "Epoch: 604, loss 0.7233668014976274\n",
      "Epoch: 605, loss 0.7233667260493137\n",
      "Epoch: 606, loss 0.7233666546949024\n",
      "Epoch: 607, loss 0.7233665873839985\n",
      "Epoch: 608, loss 0.7233665240664545\n",
      "Epoch: 609, loss 0.7233664646925343\n",
      "Epoch: 610, loss 0.7233664092128157\n",
      "Epoch: 611, loss 0.7233663575782273\n",
      "Epoch: 612, loss 0.7233663097400481\n",
      "Epoch: 613, loss 0.7233662656499378\n",
      "Epoch: 614, loss 0.7233662252598948\n",
      "Epoch: 615, loss 0.7233661885222498\n",
      "Epoch: 616, loss 0.723366155389714\n",
      "Epoch: 617, loss 0.7233661258153617\n",
      "Epoch: 618, loss 0.7233660997526415\n",
      "Epoch: 619, loss 0.7233660771553045\n",
      "Epoch: 620, loss 0.7233660579775246\n",
      "Epoch: 621, loss 0.7233660421738143\n",
      "Epoch: 622, loss 0.7233660296990728\n",
      "Epoch: 623, loss 0.7233660205085077\n",
      "Epoch: 624, loss 0.7233660145577494\n",
      "Epoch: 625, loss 0.7233660118027608\n",
      "Epoch: 626, loss 0.7233660121998797\n",
      "Epoch: 627, loss 0.7233660157058124\n",
      "Epoch: 628, loss 0.7233660222776094\n",
      "Epoch: 629, loss 0.7233660318727266\n",
      "Epoch: 630, loss 0.7233660444489521\n",
      "Epoch: 631, loss 0.7233660599644487\n",
      "Epoch: 632, loss 0.7233660783777235\n",
      "Epoch: 633, loss 0.7233660996476766\n",
      "Epoch: 634, loss 0.7233661237335588\n",
      "Epoch: 635, loss 0.7233661505949953\n",
      "Epoch: 636, loss 0.7233661801919378\n",
      "Epoch: 637, loss 0.7233662124847307\n",
      "Epoch: 638, loss 0.7233662474340568\n",
      "Epoch: 639, loss 0.7233662850010041\n",
      "Epoch: 640, loss 0.7233663251469445\n",
      "Epoch: 641, loss 0.7233663678336727\n",
      "Epoch: 642, loss 0.7233664130233162\n",
      "Epoch: 643, loss 0.7233664606783284\n",
      "Epoch: 644, loss 0.7233665107615741\n",
      "Epoch: 645, loss 0.7233665632362318\n",
      "Epoch: 646, loss 0.723366618065807\n",
      "Epoch: 647, loss 0.7233666752142339\n",
      "Epoch: 648, loss 0.7233667346457003\n",
      "Epoch: 649, loss 0.7233667963248177\n",
      "Epoch: 650, loss 0.723366860216499\n",
      "Epoch: 651, loss 0.7233669262860444\n",
      "Epoch: 652, loss 0.7233669944990259\n",
      "Epoch: 653, loss 0.7233670648214142\n",
      "Epoch: 654, loss 0.7233671372195066\n",
      "Epoch: 655, loss 0.7233672116599206\n",
      "Epoch: 656, loss 0.7233672881096422\n",
      "Epoch: 657, loss 0.7233673665359477\n",
      "Epoch: 658, loss 0.7233674469064758\n",
      "Epoch: 659, loss 0.7233675291892098\n",
      "Epoch: 660, loss 0.7233676133523989\n",
      "Epoch: 661, loss 0.7233676993646848\n",
      "Epoch: 662, loss 0.7233677871950119\n",
      "Epoch: 663, loss 0.7233678768126265\n",
      "Epoch: 664, loss 0.7233679681871433\n",
      "Epoch: 665, loss 0.7233680612884312\n",
      "Epoch: 666, loss 0.7233681560867395\n",
      "Epoch: 667, loss 0.72336825255259\n",
      "Epoch: 668, loss 0.723368350656842\n",
      "Epoch: 669, loss 0.7233684503706336\n",
      "Epoch: 670, loss 0.7233685516654712\n",
      "Epoch: 671, loss 0.723368654513109\n",
      "Epoch: 672, loss 0.7233687588856216\n",
      "Epoch: 673, loss 0.7233688647554339\n",
      "Epoch: 674, loss 0.7233689720951643\n",
      "Epoch: 675, loss 0.7233690808778602\n",
      "Epoch: 676, loss 0.7233691910767505\n",
      "Epoch: 677, loss 0.7233693026654627\n",
      "Epoch: 678, loss 0.723369415617836\n",
      "Epoch: 679, loss 0.7233695299080416\n",
      "Epoch: 680, loss 0.7233696455105052\n",
      "Epoch: 681, loss 0.7233697623999782\n",
      "Epoch: 682, loss 0.7233698805514721\n",
      "Epoch: 683, loss 0.7233699999402763\n",
      "Epoch: 684, loss 0.7233701205419947\n",
      "Epoch: 685, loss 0.7233702423324545\n",
      "Epoch: 686, loss 0.7233703652878032\n",
      "Epoch: 687, loss 0.7233704893844545\n",
      "Epoch: 688, loss 0.7233706145990634\n",
      "Epoch: 689, loss 0.7233707409085995\n",
      "Epoch: 690, loss 0.7233708682902619\n",
      "Epoch: 691, loss 0.7233709967215034\n",
      "Epoch: 692, loss 0.7233711261801153\n",
      "Epoch: 693, loss 0.7233712566440523\n",
      "Epoch: 694, loss 0.7233713880915951\n",
      "Epoch: 695, loss 0.7233715205012661\n",
      "Epoch: 696, loss 0.7233716538518056\n",
      "Epoch: 697, loss 0.7233717881222679\n",
      "Epoch: 698, loss 0.7233719232918945\n",
      "Epoch: 699, loss 0.7233720593402173\n",
      "Epoch: 700, loss 0.7233721962469917\n",
      "Epoch: 701, loss 0.7233723339922448\n",
      "Epoch: 702, loss 0.7233724725561912\n",
      "Epoch: 703, loss 0.7233726119193599\n",
      "Epoch: 704, loss 0.723372752062455\n",
      "Epoch: 705, loss 0.7233728929664222\n",
      "Epoch: 706, loss 0.7233730346124794\n",
      "Epoch: 707, loss 0.7233731769820375\n",
      "Epoch: 708, loss 0.7233733200567618\n",
      "Epoch: 709, loss 0.7233734638185165\n",
      "Epoch: 710, loss 0.7233736082494379\n",
      "Epoch: 711, loss 0.7233737533318074\n",
      "Epoch: 712, loss 0.7233738990481843\n",
      "Epoch: 713, loss 0.7233740453813515\n",
      "Epoch: 714, loss 0.7233741923143155\n",
      "Epoch: 715, loss 0.723374339830222\n",
      "Epoch: 716, loss 0.7233744879125186\n",
      "Epoch: 717, loss 0.7233746365448038\n",
      "Epoch: 718, loss 0.7233747857109305\n",
      "Epoch: 719, loss 0.7233749353949203\n",
      "Epoch: 720, loss 0.7233750855810185\n",
      "Epoch: 721, loss 0.7233752362536698\n",
      "Epoch: 722, loss 0.7233753873975369\n",
      "Epoch: 723, loss 0.7233755389974329\n",
      "Epoch: 724, loss 0.7233756910384251\n",
      "Epoch: 725, loss 0.7233758435057499\n",
      "Epoch: 726, loss 0.723375996384813\n",
      "Epoch: 727, loss 0.7233761496612737\n",
      "Epoch: 728, loss 0.7233763033209065\n",
      "Epoch: 729, loss 0.7233764573497029\n",
      "Epoch: 730, loss 0.7233766117339149\n",
      "Epoch: 731, loss 0.7233767664598543\n",
      "Epoch: 732, loss 0.7233769215140871\n",
      "Epoch: 733, loss 0.7233770768833303\n",
      "Epoch: 734, loss 0.7233772325545124\n",
      "Epoch: 735, loss 0.7233773885147311\n",
      "Epoch: 736, loss 0.723377544751217\n",
      "Epoch: 737, loss 0.7233777012514002\n",
      "Epoch: 738, loss 0.7233778580029404\n",
      "Epoch: 739, loss 0.7233780149935699\n",
      "Epoch: 740, loss 0.7233781722112503\n",
      "Epoch: 741, loss 0.7233783296440707\n",
      "Epoch: 742, loss 0.7233784872803312\n",
      "Epoch: 743, loss 0.7233786451084407\n",
      "Epoch: 744, loss 0.7233788031170322\n",
      "Epoch: 745, loss 0.7233789612948528\n",
      "Epoch: 746, loss 0.7233791196308014\n",
      "Epoch: 747, loss 0.7233792781139695\n",
      "Epoch: 748, loss 0.7233794367335883\n",
      "Epoch: 749, loss 0.7233795954789974\n",
      "Epoch: 750, loss 0.7233797543397904\n",
      "Epoch: 751, loss 0.7233799133055969\n",
      "Epoch: 752, loss 0.7233800723662824\n",
      "Epoch: 753, loss 0.723380231511797\n",
      "Epoch: 754, loss 0.723380390732284\n",
      "Epoch: 755, loss 0.7233805500179895\n",
      "Epoch: 756, loss 0.7233807093593352\n",
      "Epoch: 757, loss 0.7233808687468388\n",
      "Epoch: 758, loss 0.7233810281712303\n",
      "Epoch: 759, loss 0.7233811876232934\n",
      "Epoch: 760, loss 0.7233813470940176\n",
      "Epoch: 761, loss 0.7233815065744771\n",
      "Epoch: 762, loss 0.7233816660559028\n",
      "Epoch: 763, loss 0.7233818255296712\n",
      "Epoch: 764, loss 0.7233819849872309\n",
      "Epoch: 765, loss 0.7233821444202483\n",
      "Epoch: 766, loss 0.7233823038204198\n",
      "Epoch: 767, loss 0.7233824631796654\n",
      "Epoch: 768, loss 0.7233826224899477\n",
      "Epoch: 769, loss 0.7233827817433739\n",
      "Epoch: 770, loss 0.7233829409322148\n",
      "Epoch: 771, loss 0.7233831000488133\n",
      "Epoch: 772, loss 0.7233832590856398\n",
      "Epoch: 773, loss 0.723383418035321\n",
      "Epoch: 774, loss 0.7233835768905569\n",
      "Epoch: 775, loss 0.7233837356441437\n",
      "Epoch: 776, loss 0.7233838942890831\n",
      "Epoch: 777, loss 0.723384052818365\n",
      "Epoch: 778, loss 0.7233842112252089\n",
      "Epoch: 779, loss 0.7233843695028519\n",
      "Epoch: 780, loss 0.7233845276447011\n",
      "Epoch: 781, loss 0.7233846856442354\n",
      "Epoch: 782, loss 0.7233848434950733\n",
      "Epoch: 783, loss 0.7233850011908932\n",
      "Epoch: 784, loss 0.7233851587255069\n",
      "Epoch: 785, loss 0.7233853160928467\n",
      "Epoch: 786, loss 0.7233854732868935\n",
      "Epoch: 787, loss 0.7233856303017793\n",
      "Epoch: 788, loss 0.7233857871316901\n",
      "Epoch: 789, loss 0.7233859437709695\n",
      "Epoch: 790, loss 0.7233861002139911\n",
      "Epoch: 791, loss 0.7233862564552733\n",
      "Epoch: 792, loss 0.7233864124894016\n",
      "Epoch: 793, loss 0.7233865683110636\n",
      "Epoch: 794, loss 0.7233867239150682\n",
      "Epoch: 795, loss 0.723386879296236\n",
      "Epoch: 796, loss 0.7233870344495632\n",
      "Epoch: 797, loss 0.7233871893701124\n",
      "Epoch: 798, loss 0.7233873440529882\n",
      "Epoch: 799, loss 0.7233874984934527\n",
      "Epoch: 800, loss 0.7233876526867861\n",
      "Epoch: 801, loss 0.7233878066284012\n",
      "Epoch: 802, loss 0.7233879603137958\n",
      "Epoch: 803, loss 0.7233881137384917\n",
      "Epoch: 804, loss 0.7233882668981798\n",
      "Epoch: 805, loss 0.7233884197885574\n",
      "Epoch: 806, loss 0.7233885724054302\n",
      "Epoch: 807, loss 0.7233887247447067\n",
      "Epoch: 808, loss 0.7233888768023441\n",
      "Epoch: 809, loss 0.7233890285743715\n",
      "Epoch: 810, loss 0.7233891800569274\n",
      "Epoch: 811, loss 0.723389331246162\n",
      "Epoch: 812, loss 0.7233894821383706\n",
      "Epoch: 813, loss 0.7233896327299151\n",
      "Epoch: 814, loss 0.7233897830171452\n",
      "Epoch: 815, loss 0.7233899329966161\n",
      "Epoch: 816, loss 0.7233900826648528\n",
      "Epoch: 817, loss 0.7233902320184529\n",
      "Epoch: 818, loss 0.7233903810541407\n",
      "Epoch: 819, loss 0.7233905297686708\n",
      "Epoch: 820, loss 0.7233906781588825\n",
      "Epoch: 821, loss 0.7233908262216452\n",
      "Epoch: 822, loss 0.7233909739539373\n",
      "Epoch: 823, loss 0.7233911213527731\n",
      "Epoch: 824, loss 0.7233912684152698\n",
      "Epoch: 825, loss 0.7233914151385206\n",
      "Epoch: 826, loss 0.7233915615198119\n",
      "Epoch: 827, loss 0.7233917075563637\n",
      "Epoch: 828, loss 0.7233918532455348\n",
      "Epoch: 829, loss 0.7233919985847266\n",
      "Epoch: 830, loss 0.7233921435713947\n",
      "Epoch: 831, loss 0.723392288203031\n",
      "Epoch: 832, loss 0.7233924324772423\n",
      "Epoch: 833, loss 0.7233925763916171\n",
      "Epoch: 834, loss 0.7233927199439012\n",
      "Epoch: 835, loss 0.7233928631317678\n",
      "Epoch: 836, loss 0.7233930059530471\n",
      "Epoch: 837, loss 0.7233931484055696\n",
      "Epoch: 838, loss 0.7233932904872622\n",
      "Epoch: 839, loss 0.7233934321960641\n",
      "Epoch: 840, loss 0.723393573529999\n",
      "Epoch: 841, loss 0.7233937144871148\n",
      "Epoch: 842, loss 0.7233938550654956\n",
      "Epoch: 843, loss 0.7233939952633343\n",
      "Epoch: 844, loss 0.7233941350788481\n",
      "Epoch: 845, loss 0.7233942745102541\n",
      "Epoch: 846, loss 0.723394413555878\n",
      "Epoch: 847, loss 0.7233945522140821\n",
      "Epoch: 848, loss 0.7233946904832528\n",
      "Epoch: 849, loss 0.7233948283618487\n",
      "Epoch: 850, loss 0.7233949658483287\n",
      "Epoch: 851, loss 0.7233951029412485\n",
      "Epoch: 852, loss 0.7233952396392119\n",
      "Epoch: 853, loss 0.7233953759407924\n",
      "Epoch: 854, loss 0.7233955118447088\n",
      "Epoch: 855, loss 0.7233956473496255\n",
      "Epoch: 856, loss 0.7233957824543034\n",
      "Epoch: 857, loss 0.7233959171575578\n",
      "Epoch: 858, loss 0.7233960514581922\n",
      "Epoch: 859, loss 0.7233961853551004\n",
      "Epoch: 860, loss 0.7233963188471886\n",
      "Epoch: 861, loss 0.7233964519333929\n",
      "Epoch: 862, loss 0.7233965846127403\n",
      "Epoch: 863, loss 0.7233967168842274\n",
      "Epoch: 864, loss 0.7233968487469234\n",
      "Epoch: 865, loss 0.723396980199946\n",
      "Epoch: 866, loss 0.7233971112424187\n",
      "Epoch: 867, loss 0.7233972418735256\n",
      "Epoch: 868, loss 0.7233973720924507\n",
      "Epoch: 869, loss 0.7233975018984867\n",
      "Epoch: 870, loss 0.7233976312908783\n",
      "Epoch: 871, loss 0.7233977602689483\n",
      "Epoch: 872, loss 0.7233978888320622\n",
      "Epoch: 873, loss 0.7233980169795672\n",
      "Epoch: 874, loss 0.7233981447108828\n",
      "Epoch: 875, loss 0.7233982720254956\n",
      "Epoch: 876, loss 0.7233983989228189\n",
      "Epoch: 877, loss 0.7233985254023936\n",
      "Epoch: 878, loss 0.723398651463772\n",
      "Epoch: 879, loss 0.7233987771064709\n",
      "Epoch: 880, loss 0.7233989023301457\n",
      "Epoch: 881, loss 0.7233990271344032\n",
      "Epoch: 882, loss 0.7233991515188869\n",
      "Epoch: 883, loss 0.7233992754832885\n",
      "Epoch: 884, loss 0.7233993990273299\n",
      "Epoch: 885, loss 0.7233995221507329\n",
      "Epoch: 886, loss 0.7233996448532678\n",
      "Epoch: 887, loss 0.7233997671347592\n",
      "Epoch: 888, loss 0.7233998889950016\n",
      "Epoch: 889, loss 0.7234000104338498\n",
      "Epoch: 890, loss 0.7234001314511466\n",
      "Epoch: 891, loss 0.7234002520468313\n",
      "Epoch: 892, loss 0.7234003722208074\n",
      "Epoch: 893, loss 0.7234004919730384\n",
      "Epoch: 894, loss 0.7234006113034575\n",
      "Epoch: 895, loss 0.7234007302121012\n",
      "Epoch: 896, loss 0.7234008486989691\n",
      "Epoch: 897, loss 0.7234009667641036\n",
      "Epoch: 898, loss 0.723401084407559\n",
      "Epoch: 899, loss 0.7234012016294378\n",
      "Epoch: 900, loss 0.7234013184298367\n",
      "Epoch: 901, loss 0.7234014348089005\n",
      "Epoch: 902, loss 0.7234015507667441\n",
      "Epoch: 903, loss 0.7234016663035848\n",
      "Epoch: 904, loss 0.7234017814195858\n",
      "Epoch: 905, loss 0.7234018961149826\n",
      "Epoch: 906, loss 0.7234020103899745\n",
      "Epoch: 907, loss 0.7234021242448456\n",
      "Epoch: 908, loss 0.7234022376798315\n",
      "Epoch: 909, loss 0.7234023506952703\n",
      "Epoch: 910, loss 0.723402463291434\n",
      "Epoch: 911, loss 0.7234025754686609\n",
      "Epoch: 912, loss 0.7234026872272954\n",
      "Epoch: 913, loss 0.7234027985677122\n",
      "Epoch: 914, loss 0.7234029094902675\n",
      "Epoch: 915, loss 0.7234030199953844\n",
      "Epoch: 916, loss 0.7234031300834678\n",
      "Epoch: 917, loss 0.7234032397549405\n",
      "Epoch: 918, loss 0.7234033490102556\n",
      "Epoch: 919, loss 0.7234034578498725\n",
      "Epoch: 920, loss 0.7234035662742866\n",
      "Epoch: 921, loss 0.7234036742839811\n",
      "Epoch: 922, loss 0.7234037818794639\n",
      "Epoch: 923, loss 0.7234038890612664\n",
      "Epoch: 924, loss 0.7234039958299144\n",
      "Epoch: 925, loss 0.723404102185982\n",
      "Epoch: 926, loss 0.723404208130031\n",
      "Epoch: 927, loss 0.7234043136626416\n",
      "Epoch: 928, loss 0.7234044187843999\n",
      "Epoch: 929, loss 0.7234045234959282\n",
      "Epoch: 930, loss 0.7234046277978309\n",
      "Epoch: 931, loss 0.7234047316907665\n",
      "Epoch: 932, loss 0.7234048351753816\n",
      "Epoch: 933, loss 0.7234049382523167\n",
      "Epoch: 934, loss 0.7234050409222668\n",
      "Epoch: 935, loss 0.7234051431859084\n",
      "Epoch: 936, loss 0.7234052450439247\n",
      "Epoch: 937, loss 0.7234053464970285\n",
      "Epoch: 938, loss 0.7234054475459751\n",
      "Epoch: 939, loss 0.7234055481914535\n",
      "Epoch: 940, loss 0.723405648434213\n",
      "Epoch: 941, loss 0.7234057482750149\n",
      "Epoch: 942, loss 0.7234058477146085\n",
      "Epoch: 943, loss 0.7234059467537854\n",
      "Epoch: 944, loss 0.7234060453933191\n",
      "Epoch: 945, loss 0.7234061436340073\n",
      "Epoch: 946, loss 0.7234062414766537\n",
      "Epoch: 947, loss 0.7234063389220498\n",
      "Epoch: 948, loss 0.7234064359710476\n",
      "Epoch: 949, loss 0.7234065326244509\n",
      "Epoch: 950, loss 0.7234066288831299\n",
      "Epoch: 951, loss 0.7234067247479002\n",
      "Epoch: 952, loss 0.7234068202196504\n",
      "Epoch: 953, loss 0.7234069152992202\n",
      "Epoch: 954, loss 0.723407009987498\n",
      "Epoch: 955, loss 0.72340710428536\n",
      "Epoch: 956, loss 0.7234071981936825\n",
      "Epoch: 957, loss 0.7234072917133838\n",
      "Epoch: 958, loss 0.7234073848453524\n",
      "Epoch: 959, loss 0.7234074775905249\n",
      "Epoch: 960, loss 0.7234075699497957\n",
      "Epoch: 961, loss 0.7234076619241013\n",
      "Epoch: 962, loss 0.7234077535143786\n",
      "Epoch: 963, loss 0.7234078447215458\n",
      "Epoch: 964, loss 0.7234079355465762\n",
      "Epoch: 965, loss 0.7234080259904001\n",
      "Epoch: 966, loss 0.7234081160539966\n",
      "Epoch: 967, loss 0.7234082057383084\n",
      "Epoch: 968, loss 0.7234082950443265\n",
      "Epoch: 969, loss 0.7234083839730238\n",
      "Epoch: 970, loss 0.7234084725253612\n",
      "Epoch: 971, loss 0.723408560702366\n",
      "Epoch: 972, loss 0.7234086485049869\n",
      "Epoch: 973, loss 0.7234087359342574\n",
      "Epoch: 974, loss 0.7234088229911683\n",
      "Epoch: 975, loss 0.7234089096767229\n",
      "Epoch: 976, loss 0.7234089959919485\n",
      "Epoch: 977, loss 0.7234090819378421\n",
      "Epoch: 978, loss 0.7234091675154313\n",
      "Epoch: 979, loss 0.7234092527257612\n",
      "Epoch: 980, loss 0.7234093375698472\n",
      "Epoch: 981, loss 0.7234094220487166\n",
      "Epoch: 982, loss 0.7234095061634269\n",
      "Epoch: 983, loss 0.7234095899150236\n",
      "Epoch: 984, loss 0.723409673304534\n",
      "Epoch: 985, loss 0.7234097563330095\n",
      "Epoch: 986, loss 0.7234098390015199\n",
      "Epoch: 987, loss 0.7234099213111287\n",
      "Epoch: 988, loss 0.7234100032628691\n",
      "Epoch: 989, loss 0.7234100848578291\n",
      "Epoch: 990, loss 0.7234101660970661\n",
      "Epoch: 991, loss 0.7234102469816498\n",
      "Epoch: 992, loss 0.7234103275126618\n",
      "Epoch: 993, loss 0.7234104076911779\n",
      "Epoch: 994, loss 0.7234104875182737\n",
      "Epoch: 995, loss 0.7234105669950128\n",
      "Epoch: 996, loss 0.723410646122501\n",
      "Epoch: 997, loss 0.7234107249018323\n",
      "Epoch: 998, loss 0.723410803334058\n",
      "Epoch: 999, loss 0.7234108814203204\n",
      "Epoch: 1000, loss 0.7234109591616709\n"
     ]
    }
   ],
   "source": [
    "# The loop runs for a specified number of epochs which is 1000 as of now\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # loop processes each row in the dataset one at a time.\n",
    "    for row in data:\n",
    "        input1 = row[0] # first feature\n",
    "        input2 = row[1]  # second feature\n",
    "        true_value = row[2] # true value\n",
    "\n",
    "        # FORWARD PASS\n",
    "\n",
    "\n",
    "        # NODE 1 OUTPUT\n",
    "        node_1_output = input1 * w1 + input2 * w3 + bias1\n",
    "        node_1_output = activation_ReLu(node_1_output)\n",
    "\n",
    "        # NODE 2 OUTPUT\n",
    "        node_2_output = input1 * w2 + input2 * w4 + bias2\n",
    "        node_2_output = activation_ReLu(node_2_output)\n",
    "\n",
    "\n",
    "        # NODE 3 OUTPUT\n",
    "        # we can just use Node 1 and 2 outputs, since they\n",
    "        # already contain the the previous weights\n",
    "        node_3_output = node_1_output * w5 + node_2_output * w6 + bias3\n",
    "        node_3_output = activation_ReLu(node_3_output)\n",
    "\n",
    "        # probably used later, we might want to have error metrics (MSE)\n",
    "        predicted_value = node_3_output\n",
    "        loss = (predicted_value - true_value) ** 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        deriv_L_w5 = 2 * node_1_output * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        new_w5 = w5 - LR * deriv_L_w5\n",
    "\n",
    "\n",
    "        deriv_L_w6 = 2 * node_2_output * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        new_w6 = w6 - LR * deriv_L_w6\n",
    "\n",
    "\n",
    "        deriv_L_b3 = 2 * 1 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        new_b3 = bias3 - LR * deriv_L_b3\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        deriv_L_w1_left = 2 * w5 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_w1_right = activation_ReLu_partial_derivative(input1 * w1 + input2 * w3 + bias1) * input1\n",
    "        deriv_L_w1 = deriv_L_w1_left * deriv_L_w1_right\n",
    "        new_w1 = w1 - LR * deriv_L_w1\n",
    "\n",
    "        # weight 2\n",
    "        deriv_L_w2_left = 2 * w6 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_w2_right = activation_ReLu_partial_derivative(input1 * w2 + input2 * w4 + bias2) * input1\n",
    "        deriv_L_w2 = deriv_L_w2_left * deriv_L_w2_right\n",
    "        new_w2 = w2 - LR * deriv_L_w2\n",
    "\n",
    "        \n",
    "        deriv_L_w3_left = 2 * w5 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_w3_right = activation_ReLu_partial_derivative(input1 * w1 + input2 * w3 + bias1) * input2\n",
    "        deriv_L_w3 = deriv_L_w3_left * deriv_L_w3_right\n",
    "        new_w3 = w3 - LR * deriv_L_w3\n",
    "\n",
    "        \n",
    "        # weight 4\n",
    "        deriv_L_w4_left = 2 * w6 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_w4_right = activation_ReLu_partial_derivative(input1 * w2 + input2 * w4 + bias2) * input2\n",
    "        deriv_L_w4 = deriv_L_w4_left * deriv_L_w4_right\n",
    "        new_w4 = w4 - LR * deriv_L_w4\n",
    "\n",
    "        # bias 1\n",
    "        deriv_L_b1_left = 2 * w5 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_b1_right = activation_ReLu_partial_derivative(input1 * w1 + input2 * w3 + bias1) * 1\n",
    "        deriv_L_b1 = deriv_L_b1_left * deriv_L_b1_right\n",
    "        new_b1 = bias1 - LR * deriv_L_b1\n",
    "\n",
    "       \n",
    "        # bias 2\n",
    "        deriv_L_b2_left = 2 * w6 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_b2_right = activation_ReLu_partial_derivative(input1 * w2 + input2 * w4 + bias2) * 1\n",
    "        deriv_L_b2 = deriv_L_b2_left * deriv_L_b2_right\n",
    "        new_b2 = bias2 - LR * deriv_L_b2\n",
    "\n",
    "        \n",
    "        #FINALLY UPDATE THE EXISTING WEIGHTS!\n",
    "        w1 = new_w1\n",
    "        w2 = new_w2\n",
    "        w3 = new_w3\n",
    "        w4 = new_w4\n",
    "        w5 = new_w5\n",
    "        w6 = new_w6\n",
    "        bias1 = new_b1\n",
    "        bias2 = new_b2\n",
    "        bias3 = new_b3\n",
    "\n",
    "    loss_points.append(loss)\n",
    "    print(f\"Epoch: {epoch +1}, loss {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL WEIGHTS AND BIASES\n",
      "w1: 1\n",
      "w2: 0.5\n",
      "w3: 1\n",
      "w4: -0.5\n",
      "w5: 1\n",
      "w6: 1\n",
      "b1: 0.5\n",
      "b2: 0\n",
      "b3: 0.5\n",
      "\n",
      "\n",
      "######################################\n",
      "NEW WEIGHTS AND BIASES\n",
      "w1: 1.369447300539387\n",
      "w2: 4.135868713299464\n",
      "w3: 1.0968426279451817\n",
      "w4: -0.009479410183040179\n",
      "w5: 0.9038163830423045\n",
      "w6: 1.203496292133524\n",
      "b1: -3.5636099366061633\n",
      "b2: -6.958199230579098\n",
      "b3: 5.310421951994228\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL WEIGHTS AND BIASES\")\n",
    "\n",
    "print(f\"w1: {w1_initial}\")\n",
    "print(f\"w2: {w2_initial}\")\n",
    "print(f\"w3: {w3_initial}\")\n",
    "print(f\"w4: {w4_initial}\")\n",
    "print(f\"w5: {w5_initial}\")\n",
    "print(f\"w6: {w6_initial}\")\n",
    "print(f\"b1: {bias1_initial}\")\n",
    "print(f\"b2: {bias2_initial}\")\n",
    "print(f\"b3: {bias3_initial}\")\n",
    "\n",
    "print(\"\\n\\n######################################\")\n",
    "\n",
    "print(\"NEW WEIGHTS AND BIASES\")\n",
    "print(f\"w1: {w1}\")\n",
    "print(f\"w2: {w2}\")\n",
    "print(f\"w3: {w3}\")\n",
    "print(f\"w4: {w4}\")\n",
    "print(f\"w5: {w5}\")\n",
    "print(f\"w6: {w6}\")\n",
    "print(f\"b1: {bias1}\")\n",
    "print(f\"b2: {bias2}\")\n",
    "print(f\"b3: {bias3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_points)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x1, x2):\n",
    "    input1 = x1\n",
    "    input2 = x2\n",
    "\n",
    "    # FORWARD PASS\n",
    "\n",
    "    # NODE 1 OUTPUT\n",
    "    node_1_output = input1 * w1 + input2 * w3 + bias1\n",
    "    node_1_output = activation_ReLu(node_1_output)\n",
    "\n",
    "    # NODE 2 OUTPUT\n",
    "    node_2_output = input1 * w2 + input2 * w4 + bias2\n",
    "    node_2_output = activation_ReLu(node_2_output)\n",
    "\n",
    "    # NODE 3 OUTPUT\n",
    "    # we can just use Node 1 and 2 outputs, since they\n",
    "    # already contain the the previous weights\n",
    "    node_3_output = node_1_output * w5 + node_2_output * w6 + bias3\n",
    "    node_3_output = activation_ReLu(node_3_output)\n",
    "\n",
    "    return node_3_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.04554857762961"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(2, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with different values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change LR to 0.001 and we got a great one"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
