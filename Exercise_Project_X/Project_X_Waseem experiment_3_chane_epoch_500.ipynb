{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_ReLu(number):\n",
    "    if number > 0:\n",
    "        return number\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def activation_ReLu_partial_derivative(number):\n",
    "    if number > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_data():\n",
    "    result = []\n",
    "\n",
    "    for x in range(1000):\n",
    "        n1 = np.random.randint(0, 5)\n",
    "        n2 = np.random.randint(3, 7)\n",
    "\n",
    "        n3 = n1 ** 2 + n2 + np.random.randint(0, 5)\n",
    "        n3 = int(n3)\n",
    "\n",
    "        result.append([n1, n2, n3])\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assign valuesw1 to w6\n",
    "w1 = 1\n",
    "w2 = 0.5\n",
    "w3 = 1\n",
    "w4 = -0.5\n",
    "w5 = 1\n",
    "w6 = 1\n",
    "\n",
    "# and three biases\n",
    "bias1 = 0.5\n",
    "bias2 = 0\n",
    "bias3 = 0.5\n",
    "\n",
    "# We store the original weights and biases\n",
    "w1_initial = w1\n",
    "w2_initial = w2\n",
    "w3_initial = w3\n",
    "w4_initial = w4\n",
    "w5_initial = w5\n",
    "w6_initial = w6\n",
    "bias1_initial = bias1\n",
    "bias2_initial = bias2\n",
    "bias3_initial = bias3\n",
    "\n",
    "# Training Parameters\n",
    "LR = 0.001\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "# Dataset for training\n",
    "data = [\n",
    "    [1, 0, 2],\n",
    "    [2, 1, 6],\n",
    "    [3, 3, 17]\n",
    "]\n",
    "\n",
    "data = generate_train_data()\n",
    "\n",
    "# Initialize a list for loss points\n",
    "loss_points = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, loss 0.48626760365620003\n",
      "Epoch: 2, loss 0.2604956143422382\n",
      "Epoch: 3, loss 0.1537976134792466\n",
      "Epoch: 4, loss 0.10076379502531102\n",
      "Epoch: 5, loss 0.07043070326590983\n",
      "Epoch: 6, loss 0.05187110442080704\n",
      "Epoch: 7, loss 0.04344916883876694\n",
      "Epoch: 8, loss 0.038012350693958634\n",
      "Epoch: 9, loss 0.034819820749310504\n",
      "Epoch: 10, loss 0.04239916234459598\n",
      "Epoch: 11, loss 0.03073972648231138\n",
      "Epoch: 12, loss 0.04248795456294658\n",
      "Epoch: 13, loss 0.04023668516417044\n",
      "Epoch: 14, loss 0.043920769354081346\n",
      "Epoch: 15, loss 0.04377285420896347\n",
      "Epoch: 16, loss 0.045681512190026835\n",
      "Epoch: 17, loss 0.0471163987426649\n",
      "Epoch: 18, loss 0.04841948477344111\n",
      "Epoch: 19, loss 0.049664983813057784\n",
      "Epoch: 20, loss 0.05100710301983687\n",
      "Epoch: 21, loss 0.05225399135601341\n",
      "Epoch: 22, loss 0.05345502379242318\n",
      "Epoch: 23, loss 0.05462491242100734\n",
      "Epoch: 24, loss 0.05576911038355893\n",
      "Epoch: 25, loss 0.05688935650174415\n",
      "Epoch: 26, loss 0.05798607379169607\n",
      "Epoch: 27, loss 0.05905935626021334\n",
      "Epoch: 28, loss 0.060109336006089045\n",
      "Epoch: 29, loss 0.06303931758372118\n",
      "Epoch: 30, loss 0.0656430739274508\n",
      "Epoch: 31, loss 0.0683149212044913\n",
      "Epoch: 32, loss 0.07108533257457836\n",
      "Epoch: 33, loss 0.07223720996677378\n",
      "Epoch: 34, loss 0.07408295043046897\n",
      "Epoch: 35, loss 0.07538433741822391\n",
      "Epoch: 36, loss 0.0765258818302035\n",
      "Epoch: 37, loss 0.07750345216967237\n",
      "Epoch: 38, loss 0.07851846703356659\n",
      "Epoch: 39, loss 0.07954802295647181\n",
      "Epoch: 40, loss 0.08057865923042534\n",
      "Epoch: 41, loss 0.08163397175405475\n",
      "Epoch: 42, loss 0.0815786985413851\n",
      "Epoch: 43, loss 0.08267150470116592\n",
      "Epoch: 44, loss 0.08320984153049023\n",
      "Epoch: 45, loss 0.08404317868328136\n",
      "Epoch: 46, loss 0.08492398811505458\n",
      "Epoch: 47, loss 0.08580468088965766\n",
      "Epoch: 48, loss 0.08667136382494195\n",
      "Epoch: 49, loss 0.08752088845371084\n",
      "Epoch: 50, loss 0.08818668255002551\n",
      "Epoch: 51, loss 0.08897734552444542\n",
      "Epoch: 52, loss 0.08978052199535806\n",
      "Epoch: 53, loss 0.0905723332030113\n",
      "Epoch: 54, loss 0.09134830622631092\n",
      "Epoch: 55, loss 0.08635151171537311\n",
      "Epoch: 56, loss 0.09257803552551605\n",
      "Epoch: 57, loss 0.08769943459166964\n",
      "Epoch: 58, loss 0.08815280175079511\n",
      "Epoch: 59, loss 0.08989533344946546\n",
      "Epoch: 60, loss 0.09037340932700921\n",
      "Epoch: 61, loss 0.09098995748794009\n",
      "Epoch: 62, loss 0.09162426115603899\n",
      "Epoch: 63, loss 0.09228577583190231\n",
      "Epoch: 64, loss 0.09291480534654124\n",
      "Epoch: 65, loss 0.09354079095671933\n",
      "Epoch: 66, loss 0.09406139029124239\n",
      "Epoch: 67, loss 0.0946648269942812\n",
      "Epoch: 68, loss 0.09528423622943451\n",
      "Epoch: 69, loss 0.09590602190023419\n",
      "Epoch: 70, loss 0.09652612584954677\n",
      "Epoch: 71, loss 0.0971434084258341\n",
      "Epoch: 72, loss 0.09769928996078504\n",
      "Epoch: 73, loss 0.09829686034707466\n",
      "Epoch: 74, loss 0.098899806672021\n",
      "Epoch: 75, loss 0.09950155524687923\n",
      "Epoch: 76, loss 0.10010061497856232\n",
      "Epoch: 77, loss 0.10069686088382207\n",
      "Epoch: 78, loss 0.10129048526272555\n",
      "Epoch: 79, loss 0.10188171163720591\n",
      "Epoch: 80, loss 0.09153763376270181\n",
      "Epoch: 81, loss 0.09244172520401596\n",
      "Epoch: 82, loss 0.09313349375477728\n",
      "Epoch: 83, loss 0.09376814503624577\n",
      "Epoch: 84, loss 0.094377591317166\n",
      "Epoch: 85, loss 0.09497418427450526\n",
      "Epoch: 86, loss 0.09556338563492035\n",
      "Epoch: 87, loss 0.09574756805003272\n",
      "Epoch: 88, loss 0.09661990141240105\n",
      "Epoch: 89, loss 0.09686360307776828\n",
      "Epoch: 90, loss 0.09776043372144193\n",
      "Epoch: 91, loss 0.09800564191242572\n",
      "Epoch: 92, loss 0.09849724744939992\n",
      "Epoch: 93, loss 0.09903952342965061\n",
      "Epoch: 94, loss 0.09959839111679447\n",
      "Epoch: 95, loss 0.10016291553545602\n",
      "Epoch: 96, loss 0.100729203226295\n",
      "Epoch: 97, loss 0.101295722847907\n",
      "Epoch: 98, loss 0.10186180356694498\n",
      "Epoch: 99, loss 0.10276012976654846\n",
      "Epoch: 100, loss 0.10337666243368053\n",
      "Epoch: 101, loss 0.10399838857049817\n",
      "Epoch: 102, loss 0.10457216561552635\n",
      "Epoch: 103, loss 0.10516328590015603\n",
      "Epoch: 104, loss 0.10576485267043564\n",
      "Epoch: 105, loss 0.10634818018321449\n",
      "Epoch: 106, loss 0.10687330875278972\n",
      "Epoch: 107, loss 0.10742107053069988\n",
      "Epoch: 108, loss 0.10799543773983188\n",
      "Epoch: 109, loss 0.10856158933737299\n",
      "Epoch: 110, loss 0.10911726420479283\n",
      "Epoch: 111, loss 0.10966509854659301\n",
      "Epoch: 112, loss 0.1102078677879009\n",
      "Epoch: 113, loss 0.11074759382467037\n",
      "Epoch: 114, loss 0.11128558638463436\n",
      "Epoch: 115, loss 0.11182264568899662\n",
      "Epoch: 116, loss 0.1123592400405207\n",
      "Epoch: 117, loss 0.11289563057059661\n",
      "Epoch: 118, loss 0.11343195226950722\n",
      "Epoch: 119, loss 0.11343597750355051\n",
      "Epoch: 120, loss 0.11440209950491456\n",
      "Epoch: 121, loss 0.1144836800478802\n",
      "Epoch: 122, loss 0.11547342056284232\n",
      "Epoch: 123, loss 0.11555399754652196\n",
      "Epoch: 124, loss 0.11654734974728141\n",
      "Epoch: 125, loss 0.11701196130006578\n",
      "Epoch: 126, loss 0.11752429385329512\n",
      "Epoch: 127, loss 0.11807589386795325\n",
      "Epoch: 128, loss 0.11860267029709551\n",
      "Epoch: 129, loss 0.11913777349567974\n",
      "Epoch: 130, loss 0.11968168870503859\n",
      "Epoch: 131, loss 0.12023134567128373\n",
      "Epoch: 132, loss 0.12078398660645287\n",
      "Epoch: 133, loss 0.12099169323539065\n",
      "Epoch: 134, loss 0.12186824133976658\n",
      "Epoch: 135, loss 0.1220896176866805\n",
      "Epoch: 136, loss 0.12296686876441042\n",
      "Epoch: 137, loss 0.12317727094124893\n",
      "Epoch: 138, loss 0.12369604338269594\n",
      "Epoch: 139, loss 0.12459141961089619\n",
      "Epoch: 140, loss 0.12478981599802427\n",
      "Epoch: 141, loss 0.12530126529688013\n",
      "Epoch: 142, loss 0.12583147048293147\n",
      "Epoch: 143, loss 0.12636187273156121\n",
      "Epoch: 144, loss 0.19619409246812225\n",
      "Epoch: 145, loss 0.2278106734397075\n",
      "Epoch: 146, loss 0.20796564396532938\n",
      "Epoch: 147, loss 0.20485244254672733\n",
      "Epoch: 148, loss 0.20133907658961178\n",
      "Epoch: 149, loss 0.19864136401502605\n",
      "Epoch: 150, loss 0.19670021596921924\n",
      "Epoch: 151, loss 0.19550842330903412\n",
      "Epoch: 152, loss 0.19469117618136506\n",
      "Epoch: 153, loss 0.19416142677035264\n",
      "Epoch: 154, loss 0.19385659478385533\n",
      "Epoch: 155, loss 0.1937278132622381\n",
      "Epoch: 156, loss 0.19373672056550365\n",
      "Epoch: 157, loss 0.1938531223037479\n",
      "Epoch: 158, loss 0.1940532202305849\n",
      "Epoch: 159, loss 0.19431825549642479\n",
      "Epoch: 160, loss 0.19463345461369772\n",
      "Epoch: 161, loss 0.19498720130835584\n",
      "Epoch: 162, loss 0.1953703811113303\n",
      "Epoch: 163, loss 0.19577586065847877\n",
      "Epoch: 164, loss 0.19619807341700657\n",
      "Epoch: 165, loss 0.1966326901180574\n",
      "Epoch: 166, loss 0.1970763568328305\n",
      "Epoch: 167, loss 0.19752648710428777\n",
      "Epoch: 168, loss 0.19798109723933208\n",
      "Epoch: 169, loss 0.1984386760050873\n",
      "Epoch: 170, loss 0.19889808169545087\n",
      "Epoch: 171, loss 0.1993584609286166\n",
      "Epoch: 172, loss 0.19981918466644333\n",
      "Epoch: 173, loss 0.20027979786024686\n",
      "Epoch: 174, loss 0.20073997986395736\n",
      "Epoch: 175, loss 0.20119951334649228\n",
      "Epoch: 176, loss 0.201658259907685\n",
      "Epoch: 177, loss 0.20211614097834255\n",
      "Epoch: 178, loss 0.20257312288386842\n",
      "Epoch: 179, loss 0.2030292051874917\n",
      "Epoch: 180, loss 0.20348441161619893\n",
      "Epoch: 181, loss 0.20393878301993693\n",
      "Epoch: 182, loss 0.20439237193109105\n",
      "Epoch: 183, loss 0.2048452383826994\n",
      "Epoch: 184, loss 0.20529744671609954\n",
      "Epoch: 185, loss 0.20574906316551655\n",
      "Epoch: 186, loss 0.20620015405178488\n",
      "Epoch: 187, loss 0.20665078445267865\n",
      "Epoch: 188, loss 0.20710101724530247\n",
      "Epoch: 189, loss 0.20755091243768709\n",
      "Epoch: 190, loss 0.20800052672439384\n",
      "Epoch: 191, loss 0.20844991321445014\n",
      "Epoch: 192, loss 0.20889912129090518\n",
      "Epoch: 193, loss 0.20934819656994286\n",
      "Epoch: 194, loss 0.2097971809342324\n",
      "Epoch: 195, loss 0.21024611262071186\n",
      "Epoch: 196, loss 0.21069502634725082\n",
      "Epoch: 197, loss 0.21114395346610434\n",
      "Epoch: 198, loss 0.2115929221346973\n",
      "Epoch: 199, loss 0.21204195749659005\n",
      "Epoch: 200, loss 0.2124910818669982\n",
      "Epoch: 201, loss 0.21294031491873944\n",
      "Epoch: 202, loss 0.2133896738654567\n",
      "Epoch: 203, loss 0.21383917363988494\n",
      "Epoch: 204, loss 0.21428882706550892\n",
      "Epoch: 205, loss 0.2147386450205286\n",
      "Epoch: 206, loss 0.21518863659346066\n",
      "Epoch: 207, loss 0.21563880922995124\n",
      "Epoch: 208, loss 0.21608916887070923\n",
      "Epoch: 209, loss 0.21653972008053557\n",
      "Epoch: 210, loss 0.21699046616864567\n",
      "Epoch: 211, loss 0.21744140930055575\n",
      "Epoch: 212, loss 0.21789255060183363\n",
      "Epoch: 213, loss 0.21834389025411097\n",
      "Epoch: 214, loss 0.21879542758377443\n",
      "Epoch: 215, loss 0.21924716114370169\n",
      "Epoch: 216, loss 0.21969908878853336\n",
      "Epoch: 217, loss 0.22015120774386418\n",
      "Epoch: 218, loss 0.22060351466973788\n",
      "Epoch: 219, loss 0.22105600571892073\n",
      "Epoch: 220, loss 0.22150867659024726\n",
      "Epoch: 221, loss 0.22196152257746754\n",
      "Epoch: 222, loss 0.22241453861388807\n",
      "Epoch: 223, loss 0.22286771931318558\n",
      "Epoch: 224, loss 0.22332105900663807\n",
      "Epoch: 225, loss 0.2237745517770994\n",
      "Epoch: 226, loss 0.22422819148996675\n",
      "Epoch: 227, loss 0.22468197182138863\n",
      "Epoch: 228, loss 0.22513588628393497\n",
      "Epoch: 229, loss 0.22558992824994598\n",
      "Epoch: 230, loss 0.22604409097275469\n",
      "Epoch: 231, loss 0.22649836760597677\n",
      "Epoch: 232, loss 0.22695275122099637\n",
      "Epoch: 233, loss 0.22740723482283423\n",
      "Epoch: 234, loss 0.2278618113645352\n",
      "Epoch: 235, loss 0.2283164737601774\n",
      "Epoch: 236, loss 0.2287712148966625\n",
      "Epoch: 237, loss 0.22922602764434238\n",
      "Epoch: 238, loss 0.22968090486665466\n",
      "Epoch: 239, loss 0.23013583942875998\n",
      "Epoch: 240, loss 0.23059082420538285\n",
      "Epoch: 241, loss 0.2310458520877983\n",
      "Epoch: 242, loss 0.23150091599017675\n",
      "Epoch: 243, loss 0.2319560088552107\n",
      "Epoch: 244, loss 0.2324111236592041\n",
      "Epoch: 245, loss 0.2328662534165783\n",
      "Epoch: 246, loss 0.23332139118392833\n",
      "Epoch: 247, loss 0.23377653006358587\n",
      "Epoch: 248, loss 0.23423166320682548\n",
      "Epoch: 249, loss 0.23468678381666572\n",
      "Epoch: 250, loss 0.2351418851503494\n",
      "Epoch: 251, loss 0.23554692809857017\n",
      "Epoch: 252, loss 0.23598005541528624\n",
      "Epoch: 253, loss 0.23641378927056603\n",
      "Epoch: 254, loss 0.23684605680775717\n",
      "Epoch: 255, loss 0.23727710347424813\n",
      "Epoch: 256, loss 0.23770727372180356\n",
      "Epoch: 257, loss 0.2380677094716097\n",
      "Epoch: 258, loss 0.2387927607402861\n",
      "Epoch: 259, loss 0.2393195444867944\n",
      "Epoch: 260, loss 0.23982700332518608\n",
      "Epoch: 261, loss 0.24033217312368965\n",
      "Epoch: 262, loss 0.2408354257446189\n",
      "Epoch: 263, loss 0.24133567475717146\n",
      "Epoch: 264, loss 0.24183219987638743\n",
      "Epoch: 265, loss 0.24232468634948162\n",
      "Epoch: 266, loss 0.24281307391929172\n",
      "Epoch: 267, loss 0.24329743993121886\n",
      "Epoch: 268, loss 0.24377792812121063\n",
      "Epoch: 269, loss 0.24425470836617133\n",
      "Epoch: 270, loss 0.24472795496249664\n",
      "Epoch: 271, loss 0.24519783553582264\n",
      "Epoch: 272, loss 0.24561806455631982\n",
      "Epoch: 273, loss 0.24603969826066238\n",
      "Epoch: 274, loss 0.24646465786842725\n",
      "Epoch: 275, loss 0.24699022763705983\n",
      "Epoch: 276, loss 0.2473593125579221\n",
      "Epoch: 277, loss 0.2487211141565402\n",
      "Epoch: 278, loss 0.24934747262924573\n",
      "Epoch: 279, loss 0.25016365533775753\n",
      "Epoch: 280, loss 0.25078000138820133\n",
      "Epoch: 281, loss 0.2538062628028512\n",
      "Epoch: 282, loss 0.2542424386222359\n",
      "Epoch: 283, loss 0.2550015477913587\n",
      "Epoch: 284, loss 0.25566519229463097\n",
      "Epoch: 285, loss 0.25574453573080447\n",
      "Epoch: 286, loss 0.2562839247744906\n",
      "Epoch: 287, loss 0.22333416750648857\n",
      "Epoch: 288, loss 0.22379945543892343\n",
      "Epoch: 289, loss 0.2178925282977926\n",
      "Epoch: 290, loss 0.21842429129129304\n",
      "Epoch: 291, loss 0.21884570024054342\n",
      "Epoch: 292, loss 0.21921262029779376\n",
      "Epoch: 293, loss 0.21950204579108432\n",
      "Epoch: 294, loss 0.21974395951895115\n",
      "Epoch: 295, loss 0.21995453564476497\n",
      "Epoch: 296, loss 0.22014259067389336\n",
      "Epoch: 297, loss 0.22031327763560715\n",
      "Epoch: 298, loss 0.22046978264623998\n",
      "Epoch: 299, loss 0.22061418660493481\n",
      "Epoch: 300, loss 0.22055141953932947\n",
      "Epoch: 301, loss 0.22065212208057136\n",
      "Epoch: 302, loss 0.22080750116669604\n",
      "Epoch: 303, loss 0.2210591875025239\n",
      "Epoch: 304, loss 0.22123002192401153\n",
      "Epoch: 305, loss 0.22135273144229264\n",
      "Epoch: 306, loss 0.22144894055583964\n",
      "Epoch: 307, loss 0.22152885984359064\n",
      "Epoch: 308, loss 0.22161035715895783\n",
      "Epoch: 309, loss 0.22165358722692466\n",
      "Epoch: 310, loss 0.2216764206020603\n",
      "Epoch: 311, loss 0.22168883427749303\n",
      "Epoch: 312, loss 0.22173326450796815\n",
      "Epoch: 313, loss 0.22173397225616842\n",
      "Epoch: 314, loss 0.22171324439504408\n",
      "Epoch: 315, loss 0.2216829198090204\n",
      "Epoch: 316, loss 0.22164870849318197\n",
      "Epoch: 317, loss 0.22161345909423544\n",
      "Epoch: 318, loss 0.2215785822654101\n",
      "Epoch: 319, loss 0.22154473400423055\n",
      "Epoch: 320, loss 0.22151217088439754\n",
      "Epoch: 321, loss 0.22148094117551606\n",
      "Epoch: 322, loss 0.22145098869154017\n",
      "Epoch: 323, loss 0.22142220908022936\n",
      "Epoch: 324, loss 0.22139447998404505\n",
      "Epoch: 325, loss 0.22136767683280004\n",
      "Epoch: 326, loss 0.22134168076084662\n",
      "Epoch: 327, loss 0.2213163822391097\n",
      "Epoch: 328, loss 0.22129168240625893\n",
      "Epoch: 329, loss 0.2212674931933813\n",
      "Epoch: 330, loss 0.2212437368429448\n",
      "Epoch: 331, loss 0.22122034514975886\n",
      "Epoch: 332, loss 0.2211972585998559\n",
      "Epoch: 333, loss 0.22117442550011576\n",
      "Epoch: 334, loss 0.22115180114514552\n",
      "Epoch: 335, loss 0.22112934704302212\n",
      "Epoch: 336, loss 0.22110703020794406\n",
      "Epoch: 337, loss 0.22108482252053213\n",
      "Epoch: 338, loss 0.22106270015322424\n",
      "Epoch: 339, loss 0.22104064305614157\n",
      "Epoch: 340, loss 0.22101863449846712\n",
      "Epoch: 341, loss 0.2209966606601177\n",
      "Epoch: 342, loss 0.2209747102687281\n",
      "Epoch: 343, loss 0.22095277427725188\n",
      "Epoch: 344, loss 0.22093084557803594\n",
      "Epoch: 345, loss 0.22090891874932175\n",
      "Epoch: 346, loss 0.22088698983076274\n",
      "Epoch: 347, loss 0.22086505612480872\n",
      "Epoch: 348, loss 0.22084311602107223\n",
      "Epoch: 349, loss 0.22082116884119493\n",
      "Epoch: 350, loss 0.22079921470194638\n",
      "Epoch: 351, loss 0.22077725439453044\n",
      "Epoch: 352, loss 0.22075528927829977\n",
      "Epoch: 353, loss 0.22073332118726055\n",
      "Epoch: 354, loss 0.22071123914234275\n",
      "Epoch: 355, loss 0.2206889907630255\n",
      "Epoch: 356, loss 0.22066662766483608\n",
      "Epoch: 357, loss 0.22064418133910166\n",
      "Epoch: 358, loss 0.22062167503086372\n",
      "Epoch: 359, loss 0.2205991262834484\n",
      "Epoch: 360, loss 0.22057654896436749\n",
      "Epoch: 361, loss 0.22055395459268917\n",
      "Epoch: 362, loss 0.22053135313127223\n",
      "Epoch: 363, loss 0.22050875344908197\n",
      "Epoch: 364, loss 0.2204861635930437\n",
      "Epoch: 365, loss 0.2204635909521355\n",
      "Epoch: 366, loss 0.22044104236047943\n",
      "Epoch: 367, loss 0.22041852416596927\n",
      "Epoch: 368, loss 0.2203960422788515\n",
      "Epoch: 369, loss 0.22037360220870228\n",
      "Epoch: 370, loss 0.2203512090942526\n",
      "Epoch: 371, loss 0.2203288677286783\n",
      "Epoch: 372, loss 0.2203065825818711\n",
      "Epoch: 373, loss 0.22028435782049502\n",
      "Epoch: 374, loss 0.22026219732633076\n",
      "Epoch: 375, loss 0.22024010471325906\n",
      "Epoch: 376, loss 0.22021808334303983\n",
      "Epoch: 377, loss 0.22019613634003943\n",
      "Epoch: 378, loss 0.22017426660500283\n",
      "Epoch: 379, loss 0.22015247682799305\n",
      "Epoch: 380, loss 0.22013076950046614\n",
      "Epoch: 381, loss 0.22010914692666564\n",
      "Epoch: 382, loss 0.22008761123427967\n",
      "Epoch: 383, loss 0.2200661643844649\n",
      "Epoch: 384, loss 0.2200448081812703\n",
      "Epoch: 385, loss 0.22002354428050788\n",
      "Epoch: 386, loss 0.2200023741980722\n",
      "Epoch: 387, loss 0.21998129931779734\n",
      "Epoch: 388, loss 0.219960320898843\n",
      "Epoch: 389, loss 0.21993944008261967\n",
      "Epoch: 390, loss 0.21991865789938037\n",
      "Epoch: 391, loss 0.2198979752743916\n",
      "Epoch: 392, loss 0.21987739303373433\n",
      "Epoch: 393, loss 0.21985691190984644\n",
      "Epoch: 394, loss 0.21983653254666835\n",
      "Epoch: 395, loss 0.21981625550458236\n",
      "Epoch: 396, loss 0.2197960812650153\n",
      "Epoch: 397, loss 0.21977601023485477\n",
      "Epoch: 398, loss 0.21975604275054111\n",
      "Epoch: 399, loss 0.21973617908203438\n",
      "Epoch: 400, loss 0.21971641943648212\n",
      "Epoch: 401, loss 0.21969676396174953\n",
      "Epoch: 402, loss 0.2196772127497499\n",
      "Epoch: 403, loss 0.21965776583957805\n",
      "Epoch: 404, loss 0.21963842322051216\n",
      "Epoch: 405, loss 0.21961918483483892\n",
      "Epoch: 406, loss 0.21960005058053236\n",
      "Epoch: 407, loss 0.21958102031383217\n",
      "Epoch: 408, loss 0.21956209385162467\n",
      "Epoch: 409, loss 0.21954327097375653\n",
      "Epoch: 410, loss 0.21952455142522792\n",
      "Epoch: 411, loss 0.21950593491824494\n",
      "Epoch: 412, loss 0.21948742113419026\n",
      "Epoch: 413, loss 0.21946900972551445\n",
      "Epoch: 414, loss 0.21945070031748398\n",
      "Epoch: 415, loss 0.2194324925098886\n",
      "Epoch: 416, loss 0.2194143858786483\n",
      "Epoch: 417, loss 0.21939637997733508\n",
      "Epoch: 418, loss 0.21937847433862917\n",
      "Epoch: 419, loss 0.21936066847570687\n",
      "Epoch: 420, loss 0.21934296188353947\n",
      "Epoch: 421, loss 0.2193253540401588\n",
      "Epoch: 422, loss 0.21930784440784418\n",
      "Epoch: 423, loss 0.21929043243424892\n",
      "Epoch: 424, loss 0.21927311755349357\n",
      "Epoch: 425, loss 0.21925589918715882\n",
      "Epoch: 426, loss 0.21923877674529643\n",
      "Epoch: 427, loss 0.21922174962733526\n",
      "Epoch: 428, loss 0.2192048172229637\n",
      "Epoch: 429, loss 0.21918797891297345\n",
      "Epoch: 430, loss 0.21917123407006847\n",
      "Epoch: 431, loss 0.21915458205961186\n",
      "Epoch: 432, loss 0.2191380222403362\n",
      "Epoch: 433, loss 0.21912155396505698\n",
      "Epoch: 434, loss 0.21910517658131262\n",
      "Epoch: 435, loss 0.21908888943197447\n",
      "Epoch: 436, loss 0.2190726918558516\n",
      "Epoch: 437, loss 0.21905658318824747\n",
      "Epoch: 438, loss 0.21904056276148282\n",
      "Epoch: 439, loss 0.2190246299054022\n",
      "Epoch: 440, loss 0.21900878394787016\n",
      "Epoch: 441, loss 0.2189930242152093\n",
      "Epoch: 442, loss 0.21897735003263155\n",
      "Epoch: 443, loss 0.21896176072464754\n",
      "Epoch: 444, loss 0.21894625561546632\n",
      "Epoch: 445, loss 0.2189308340293631\n",
      "Epoch: 446, loss 0.2189154952909971\n",
      "Epoch: 447, loss 0.21890023872578265\n",
      "Epoch: 448, loss 0.21888506366016708\n",
      "Epoch: 449, loss 0.21886996942194506\n",
      "Epoch: 450, loss 0.21885495534053312\n",
      "Epoch: 451, loss 0.21884002074721748\n",
      "Epoch: 452, loss 0.2188251649754317\n",
      "Epoch: 453, loss 0.21881038736095632\n",
      "Epoch: 454, loss 0.21879568724217152\n",
      "Epoch: 455, loss 0.218781063960235\n",
      "Epoch: 456, loss 0.21876651685930149\n",
      "Epoch: 457, loss 0.2187520452866855\n",
      "Epoch: 458, loss 0.21873764859305256\n",
      "Epoch: 459, loss 0.21872332613256049\n",
      "Epoch: 460, loss 0.21870907726301883\n",
      "Epoch: 461, loss 0.21869490134605013\n",
      "Epoch: 462, loss 0.21868079774717625\n",
      "Epoch: 463, loss 0.21866676583598288\n",
      "Epoch: 464, loss 0.21865280498621098\n",
      "Epoch: 465, loss 0.21863891457587295\n",
      "Epoch: 466, loss 0.21862509398734575\n",
      "Epoch: 467, loss 0.21861134260745563\n",
      "Epoch: 468, loss 0.21859765982757443\n",
      "Epoch: 469, loss 0.21858404504368276\n",
      "Epoch: 470, loss 0.2185704976564614\n",
      "Epoch: 471, loss 0.2185570170713261\n",
      "Epoch: 472, loss 0.21854360269850423\n",
      "Epoch: 473, loss 0.21853025395307948\n",
      "Epoch: 474, loss 0.21851697025506006\n",
      "Epoch: 475, loss 0.21850375102938552\n",
      "Epoch: 476, loss 0.21849059570597487\n",
      "Epoch: 477, loss 0.21847750371979147\n",
      "Epoch: 478, loss 0.21846447451082326\n",
      "Epoch: 479, loss 0.21845150752413597\n",
      "Epoch: 480, loss 0.21843860220988662\n",
      "Epoch: 481, loss 0.21842575802334177\n",
      "Epoch: 482, loss 0.21841297442487626\n",
      "Epoch: 483, loss 0.21840025087999804\n",
      "Epoch: 484, loss 0.2183875868593569\n",
      "Epoch: 485, loss 0.21837498183872792\n",
      "Epoch: 486, loss 0.21836243529902505\n",
      "Epoch: 487, loss 0.2183499467262997\n",
      "Epoch: 488, loss 0.21833751561172432\n",
      "Epoch: 489, loss 0.21832514145159446\n",
      "Epoch: 490, loss 0.21831282374730904\n",
      "Epoch: 491, loss 0.2183005620053757\n",
      "Epoch: 492, loss 0.21828835573737457\n",
      "Epoch: 493, loss 0.21827620445994206\n",
      "Epoch: 494, loss 0.2182641076947728\n",
      "Epoch: 495, loss 0.21825206496859026\n",
      "Epoch: 496, loss 0.2182400758131006\n",
      "Epoch: 497, loss 0.21836154743148278\n",
      "Epoch: 498, loss 0.2184890735898818\n",
      "Epoch: 499, loss 0.2186082637652828\n",
      "Epoch: 500, loss 0.21871544348696617\n"
     ]
    }
   ],
   "source": [
    "# The loop runs for a specified number of epochs which is 1000 as of now\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # loop processes each row in the dataset one at a time.\n",
    "    for row in data:\n",
    "        input1 = row[0] # first feature\n",
    "        input2 = row[1]  # second feature\n",
    "        true_value = row[2] # true value\n",
    "\n",
    "        # FORWARD PASS\n",
    "\n",
    "\n",
    "        # NODE 1 OUTPUT\n",
    "        node_1_output = input1 * w1 + input2 * w3 + bias1\n",
    "        node_1_output = activation_ReLu(node_1_output)\n",
    "\n",
    "        # NODE 2 OUTPUT\n",
    "        node_2_output = input1 * w2 + input2 * w4 + bias2\n",
    "        node_2_output = activation_ReLu(node_2_output)\n",
    "\n",
    "\n",
    "        # NODE 3 OUTPUT\n",
    "        # we can just use Node 1 and 2 outputs, since they\n",
    "        # already contain the the previous weights\n",
    "        node_3_output = node_1_output * w5 + node_2_output * w6 + bias3\n",
    "        node_3_output = activation_ReLu(node_3_output)\n",
    "\n",
    "        # probably used later, we might want to have error metrics (MSE)\n",
    "        predicted_value = node_3_output\n",
    "        loss = (predicted_value - true_value) ** 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        deriv_L_w5 = 2 * node_1_output * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        new_w5 = w5 - LR * deriv_L_w5\n",
    "\n",
    "\n",
    "        deriv_L_w6 = 2 * node_2_output * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        new_w6 = w6 - LR * deriv_L_w6\n",
    "\n",
    "\n",
    "        deriv_L_b3 = 2 * 1 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        new_b3 = bias3 - LR * deriv_L_b3\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        deriv_L_w1_left = 2 * w5 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_w1_right = activation_ReLu_partial_derivative(input1 * w1 + input2 * w3 + bias1) * input1\n",
    "        deriv_L_w1 = deriv_L_w1_left * deriv_L_w1_right\n",
    "        new_w1 = w1 - LR * deriv_L_w1\n",
    "\n",
    "        # weight 2\n",
    "        deriv_L_w2_left = 2 * w6 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_w2_right = activation_ReLu_partial_derivative(input1 * w2 + input2 * w4 + bias2) * input1\n",
    "        deriv_L_w2 = deriv_L_w2_left * deriv_L_w2_right\n",
    "        new_w2 = w2 - LR * deriv_L_w2\n",
    "\n",
    "        \n",
    "        deriv_L_w3_left = 2 * w5 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_w3_right = activation_ReLu_partial_derivative(input1 * w1 + input2 * w3 + bias1) * input2\n",
    "        deriv_L_w3 = deriv_L_w3_left * deriv_L_w3_right\n",
    "        new_w3 = w3 - LR * deriv_L_w3\n",
    "\n",
    "        \n",
    "        # weight 4\n",
    "        deriv_L_w4_left = 2 * w6 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_w4_right = activation_ReLu_partial_derivative(input1 * w2 + input2 * w4 + bias2) * input2\n",
    "        deriv_L_w4 = deriv_L_w4_left * deriv_L_w4_right\n",
    "        new_w4 = w4 - LR * deriv_L_w4\n",
    "\n",
    "        # bias 1\n",
    "        deriv_L_b1_left = 2 * w5 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_b1_right = activation_ReLu_partial_derivative(input1 * w1 + input2 * w3 + bias1) * 1\n",
    "        deriv_L_b1 = deriv_L_b1_left * deriv_L_b1_right\n",
    "        new_b1 = bias1 - LR * deriv_L_b1\n",
    "\n",
    "       \n",
    "        # bias 2\n",
    "        deriv_L_b2_left = 2 * w6 * (node_1_output * w5 + node_2_output * w6 + bias3 - true_value)\n",
    "        deriv_L_b2_right = activation_ReLu_partial_derivative(input1 * w2 + input2 * w4 + bias2) * 1\n",
    "        deriv_L_b2 = deriv_L_b2_left * deriv_L_b2_right\n",
    "        new_b2 = bias2 - LR * deriv_L_b2\n",
    "\n",
    "        \n",
    "        #FINALLY UPDATE THE EXISTING WEIGHTS!\n",
    "        w1 = new_w1\n",
    "        w2 = new_w2\n",
    "        w3 = new_w3\n",
    "        w4 = new_w4\n",
    "        w5 = new_w5\n",
    "        w6 = new_w6\n",
    "        bias1 = new_b1\n",
    "        bias2 = new_b2\n",
    "        bias3 = new_b3\n",
    "\n",
    "    loss_points.append(loss)\n",
    "    print(f\"Epoch: {epoch +1}, loss {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORIGINAL WEIGHTS AND BIASES\n",
      "w1: 1\n",
      "w2: 0.5\n",
      "w3: 1\n",
      "w4: -0.5\n",
      "w5: 1\n",
      "w6: 1\n",
      "b1: 0.5\n",
      "b2: 0\n",
      "b3: 0.5\n",
      "\n",
      "\n",
      "######################################\n",
      "NEW WEIGHTS AND BIASES\n",
      "w1: 1.8304690632055116\n",
      "w2: 4.178664086125869\n",
      "w3: 0.9220177803885863\n",
      "w4: -0.14026401153006568\n",
      "w5: 1.0415569149571864\n",
      "w6: 1.152763363122509\n",
      "b1: -3.180471245025987\n",
      "b2: -9.020108155285087\n",
      "b3: 5.033588894504174\n"
     ]
    }
   ],
   "source": [
    "print(\"ORIGINAL WEIGHTS AND BIASES\")\n",
    "\n",
    "print(f\"w1: {w1_initial}\")\n",
    "print(f\"w2: {w2_initial}\")\n",
    "print(f\"w3: {w3_initial}\")\n",
    "print(f\"w4: {w4_initial}\")\n",
    "print(f\"w5: {w5_initial}\")\n",
    "print(f\"w6: {w6_initial}\")\n",
    "print(f\"b1: {bias1_initial}\")\n",
    "print(f\"b2: {bias2_initial}\")\n",
    "print(f\"b3: {bias3_initial}\")\n",
    "\n",
    "print(\"\\n\\n######################################\")\n",
    "\n",
    "print(\"NEW WEIGHTS AND BIASES\")\n",
    "print(f\"w1: {w1}\")\n",
    "print(f\"w2: {w2}\")\n",
    "print(f\"w3: {w3}\")\n",
    "print(f\"w4: {w4}\")\n",
    "print(f\"w5: {w5}\")\n",
    "print(f\"w6: {w6}\")\n",
    "print(f\"b1: {bias1}\")\n",
    "print(f\"b2: {bias2}\")\n",
    "print(f\"b3: {bias3}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_points)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x1, x2):\n",
    "    input1 = x1\n",
    "    input2 = x2\n",
    "\n",
    "    # FORWARD PASS\n",
    "\n",
    "    # NODE 1 OUTPUT\n",
    "    node_1_output = input1 * w1 + input2 * w3 + bias1\n",
    "    node_1_output = activation_ReLu(node_1_output)\n",
    "\n",
    "    # NODE 2 OUTPUT\n",
    "    node_2_output = input1 * w2 + input2 * w4 + bias2\n",
    "    node_2_output = activation_ReLu(node_2_output)\n",
    "\n",
    "    # NODE 3 OUTPUT\n",
    "    # we can just use Node 1 and 2 outputs, since they\n",
    "    # already contain the the previous weights\n",
    "    node_3_output = node_1_output * w5 + node_2_output * w6 + bias3\n",
    "    node_3_output = activation_ReLu(node_3_output)\n",
    "\n",
    "    return node_3_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.335692471604714"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(2, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with different values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change epoch to 500 we got a worst one very bad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
