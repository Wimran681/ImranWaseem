{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "# pip install tensorflow\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h1>I have not studied Data Anylitical course so this dataset is complete new for me</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have not studied Data anyaltics course, So, this dataset is completely new for me\n",
    "# loading the dataset \n",
    "df = pd.read_csv(\"Housing_Prices.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7229300521</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>231300.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.51</td>\n",
       "      <td>-122.26</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.72</td>\n",
       "      <td>-122.32</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.74</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.00</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.52</td>\n",
       "      <td>-122.39</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.62</td>\n",
       "      <td>-122.05</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7237550310</td>\n",
       "      <td>20140512T000000</td>\n",
       "      <td>1225000.00</td>\n",
       "      <td>4</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5420</td>\n",
       "      <td>101930</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>3890</td>\n",
       "      <td>1530</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>98053</td>\n",
       "      <td>47.66</td>\n",
       "      <td>-122.00</td>\n",
       "      <td>4760</td>\n",
       "      <td>101930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1321400060</td>\n",
       "      <td>20140627T000000</td>\n",
       "      <td>257500.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1715</td>\n",
       "      <td>6819</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.31</td>\n",
       "      <td>-122.33</td>\n",
       "      <td>2238</td>\n",
       "      <td>6819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008000270</td>\n",
       "      <td>20150115T000000</td>\n",
       "      <td>291850.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1060</td>\n",
       "      <td>9711</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>98198</td>\n",
       "      <td>47.41</td>\n",
       "      <td>-122.31</td>\n",
       "      <td>1650</td>\n",
       "      <td>9711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2414600126</td>\n",
       "      <td>20150415T000000</td>\n",
       "      <td>229500.00</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1780</td>\n",
       "      <td>7470</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>730</td>\n",
       "      <td>1960</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.51</td>\n",
       "      <td>-122.34</td>\n",
       "      <td>1780</td>\n",
       "      <td>8113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3793500160</td>\n",
       "      <td>20150312T000000</td>\n",
       "      <td>323000.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1890</td>\n",
       "      <td>6560</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1890</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>98038</td>\n",
       "      <td>47.37</td>\n",
       "      <td>-122.03</td>\n",
       "      <td>2390</td>\n",
       "      <td>7570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date      price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7229300521  20141013T000000  231300.00         2       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.00         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.00         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.00         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.00         3       2.00         1680   \n",
       "5  7237550310  20140512T000000 1225000.00         4       4.50         5420   \n",
       "6  1321400060  20140627T000000  257500.00         3       2.25         1715   \n",
       "7  2008000270  20150115T000000  291850.00         3       1.50         1060   \n",
       "8  2414600126  20150415T000000  229500.00         3       1.00         1780   \n",
       "9  3793500160  20150312T000000  323000.00         3       2.50         1890   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650    1.00           0     0  ...      7        1180              0   \n",
       "1      7242    2.00           0     0  ...      7        2170            400   \n",
       "2     10000    1.00           0     0  ...      6         770              0   \n",
       "3      5000    1.00           0     0  ...      7        1050            910   \n",
       "4      8080    1.00           0     0  ...      8        1680              0   \n",
       "5    101930    1.00           0     0  ...     11        3890           1530   \n",
       "6      6819    2.00           0     0  ...      7        1715              0   \n",
       "7      9711    1.00           0     0  ...      7        1060              0   \n",
       "8      7470    1.00           0     0  ...      7        1050            730   \n",
       "9      6560    2.00           0     0  ...      7        1890              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode   lat    long  sqft_living15  sqft_lot15  \n",
       "0      1955             0    98178 47.51 -122.26           1340        5650  \n",
       "1      1951          1991    98125 47.72 -122.32           1690        7639  \n",
       "2      1933             0    98028 47.74 -122.23           2720        8062  \n",
       "3      1965             0    98136 47.52 -122.39           1360        5000  \n",
       "4      1987             0    98074 47.62 -122.05           1800        7503  \n",
       "5      2001             0    98053 47.66 -122.00           4760      101930  \n",
       "6      1995             0    98003 47.31 -122.33           2238        6819  \n",
       "7      1963             0    98198 47.41 -122.31           1650        9711  \n",
       "8      1960             0    98146 47.51 -122.34           1780        8113  \n",
       "9      2003             0    98038 47.37 -122.03           2390        7570  \n",
       "\n",
       "[10 rows x 21 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see what we have in the data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We can see in the data that we have many yes/no fields and one field with multiple text categories. We have to convert all of these correctly into numeric format.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "date             0\n",
       "price            0\n",
       "bedrooms         0\n",
       "bathrooms        0\n",
       "sqft_living      0\n",
       "sqft_lot         0\n",
       "floors           0\n",
       "waterfront       0\n",
       "view             0\n",
       "condition        0\n",
       "grade            0\n",
       "sqft_above       0\n",
       "sqft_basement    0\n",
       "yr_built         0\n",
       "yr_renovated     0\n",
       "zipcode          0\n",
       "lat              0\n",
       "long             0\n",
       "sqft_living15    0\n",
       "sqft_lot15       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quickly check if we have missing values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21613 entries, 0 to 21612\n",
      "Data columns (total 21 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   id             21613 non-null  int64  \n",
      " 1   date           21613 non-null  object \n",
      " 2   price          21613 non-null  float64\n",
      " 3   bedrooms       21613 non-null  int64  \n",
      " 4   bathrooms      21613 non-null  float64\n",
      " 5   sqft_living    21613 non-null  int64  \n",
      " 6   sqft_lot       21613 non-null  int64  \n",
      " 7   floors         21613 non-null  float64\n",
      " 8   waterfront     21613 non-null  int64  \n",
      " 9   view           21613 non-null  int64  \n",
      " 10  condition      21613 non-null  int64  \n",
      " 11  grade          21613 non-null  int64  \n",
      " 12  sqft_above     21613 non-null  int64  \n",
      " 13  sqft_basement  21613 non-null  int64  \n",
      " 14  yr_built       21613 non-null  int64  \n",
      " 15  yr_renovated   21613 non-null  int64  \n",
      " 16  zipcode        21613 non-null  int64  \n",
      " 17  lat            21613 non-null  float64\n",
      " 18  long           21613 non-null  float64\n",
      " 19  sqft_living15  21613 non-null  int64  \n",
      " 20  sqft_lot15     21613 non-null  int64  \n",
      "dtypes: float64(5), int64(15), object(1)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Convert no/yes -columns into 0/1</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this just converts the value of column to 0 or 1\n",
    "# factorize in pandas works too, but only one column at a time\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# variables = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
    "# encoder = LabelEncoder()\n",
    "# df[variables] = df[variables].apply(encoder.fit_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Convert text categories with multiple choices into multiple variables</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when converting a category with multiple options\n",
    "# into multiple variables, we can always remove the last one of them\n",
    "# for the optimizations. See the ANN regression materials why this works \n",
    "# (the Rovaniemi/Oulu/Helsinki -example)\n",
    "# df = df.drop([\"id\", \"date\",  \"sqft_living15\",  \"waterfront\",\"sqft_lot15\", \"long\", \"lat\",\"zipcode\"], axis=1)\n",
    "df = df.drop([\"id\", \"date\",\"floors\",\"bedrooms\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>231300.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.51</td>\n",
       "      <td>-122.26</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538000.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.72</td>\n",
       "      <td>-122.32</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180000.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.74</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604000.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.52</td>\n",
       "      <td>-122.39</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510000.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.62</td>\n",
       "      <td>-122.05</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1225000.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5420</td>\n",
       "      <td>101930</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3890</td>\n",
       "      <td>1530</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>98053</td>\n",
       "      <td>47.66</td>\n",
       "      <td>-122.00</td>\n",
       "      <td>4760</td>\n",
       "      <td>101930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>257500.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1715</td>\n",
       "      <td>6819</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1715</td>\n",
       "      <td>0</td>\n",
       "      <td>1995</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.31</td>\n",
       "      <td>-122.33</td>\n",
       "      <td>2238</td>\n",
       "      <td>6819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>291850.00</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1060</td>\n",
       "      <td>9711</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>98198</td>\n",
       "      <td>47.41</td>\n",
       "      <td>-122.31</td>\n",
       "      <td>1650</td>\n",
       "      <td>9711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>229500.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1780</td>\n",
       "      <td>7470</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>730</td>\n",
       "      <td>1960</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.51</td>\n",
       "      <td>-122.34</td>\n",
       "      <td>1780</td>\n",
       "      <td>8113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>323000.00</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1890</td>\n",
       "      <td>6560</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1890</td>\n",
       "      <td>0</td>\n",
       "      <td>2003</td>\n",
       "      <td>0</td>\n",
       "      <td>98038</td>\n",
       "      <td>47.37</td>\n",
       "      <td>-122.03</td>\n",
       "      <td>2390</td>\n",
       "      <td>7570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       price  bathrooms  sqft_living  sqft_lot  waterfront  view  condition  \\\n",
       "0  231300.00       1.00         1180      5650           0     0          3   \n",
       "1  538000.00       2.25         2570      7242           0     0          3   \n",
       "2  180000.00       1.00          770     10000           0     0          3   \n",
       "3  604000.00       3.00         1960      5000           0     0          5   \n",
       "4  510000.00       2.00         1680      8080           0     0          3   \n",
       "5 1225000.00       4.50         5420    101930           0     0          3   \n",
       "6  257500.00       2.25         1715      6819           0     0          3   \n",
       "7  291850.00       1.50         1060      9711           0     0          3   \n",
       "8  229500.00       1.00         1780      7470           0     0          3   \n",
       "9  323000.00       2.50         1890      6560           0     0          3   \n",
       "\n",
       "   grade  sqft_above  sqft_basement  yr_built  yr_renovated  zipcode   lat  \\\n",
       "0      7        1180              0      1955             0    98178 47.51   \n",
       "1      7        2170            400      1951          1991    98125 47.72   \n",
       "2      6         770              0      1933             0    98028 47.74   \n",
       "3      7        1050            910      1965             0    98136 47.52   \n",
       "4      8        1680              0      1987             0    98074 47.62   \n",
       "5     11        3890           1530      2001             0    98053 47.66   \n",
       "6      7        1715              0      1995             0    98003 47.31   \n",
       "7      7        1060              0      1963             0    98198 47.41   \n",
       "8      7        1050            730      1960             0    98146 47.51   \n",
       "9      7        1890              0      2003             0    98038 47.37   \n",
       "\n",
       "     long  sqft_living15  sqft_lot15  \n",
       "0 -122.26           1340        5650  \n",
       "1 -122.32           1690        7639  \n",
       "2 -122.23           2720        8062  \n",
       "3 -122.39           1360        5000  \n",
       "4 -122.05           1800        7503  \n",
       "5 -122.00           4760      101930  \n",
       "6 -122.33           2238        6819  \n",
       "7 -122.31           1650        9711  \n",
       "8 -122.34           1780        8113  \n",
       "9 -122.03           2390        7570  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 4, 2, 1])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"view\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'bathrooms', 'sqft_living', 'sqft_lot', 'waterfront', 'view',\n",
       "       'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built',\n",
       "       'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15',\n",
       "       'sqft_lot15'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing out the column names for easier copying for X/y\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>X/y -variables</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you  have more than one independent variables, list them all here\n",
    "# leave out the target variable! (dependent variable)\n",
    "# in this case, everything else except the amount_paid\n",
    "X = df[[\"bathrooms\",\"sqft_living\",\"sqft_lot\",\n",
    "       'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built',\n",
    "       'yr_renovated',\"sqft_living15\",  \"waterfront\",\"sqft_lot15\", \"long\", \"lat\",\"zipcode\"]]\n",
    "# have only the target variable here (dependent variable)\n",
    "# in this case, amount_paid => how big is the electricity bill\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sqft_lot</td>\n",
       "      <td>396029092.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sqft_lot15</td>\n",
       "      <td>187396143.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>yr_renovated</td>\n",
       "      <td>9283729.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sqft_living</td>\n",
       "      <td>5497630.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sqft_above</td>\n",
       "      <td>4434186.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sqft_basement</td>\n",
       "      <td>4405626.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sqft_living15</td>\n",
       "      <td>2772242.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>view</td>\n",
       "      <td>19413.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>waterfront</td>\n",
       "      <td>8184.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bathrooms</td>\n",
       "      <td>2840.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>grade</td>\n",
       "      <td>2391.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>yr_built</td>\n",
       "      <td>2107.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>condition</td>\n",
       "      <td>527.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>zipcode</td>\n",
       "      <td>124.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>lat</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>long</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Features        Score\n",
       "2        sqft_lot 396029092.85\n",
       "12     sqft_lot15 187396143.23\n",
       "9    yr_renovated   9283729.13\n",
       "1     sqft_living   5497630.88\n",
       "6      sqft_above   4434186.56\n",
       "7   sqft_basement   4405626.51\n",
       "10  sqft_living15   2772242.04\n",
       "3            view     19413.99\n",
       "11     waterfront      8184.49\n",
       "0       bathrooms      2840.78\n",
       "5           grade      2391.99\n",
       "8        yr_built      2107.91\n",
       "4       condition       527.31\n",
       "15        zipcode       124.75\n",
       "14            lat         0.00\n",
       "13           long          NaN"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# convert all continuous variables to integer,\n",
    "# and convert all negative numbers to 0\n",
    "X_cat = X.astype(int)\n",
    "X_cat = X_cat.clip(lower=0)\n",
    "\n",
    "# initialize chi2 and SelectKBest\n",
    "# Note: chi2 -test is a very common test\n",
    "# in statistics and quantitative analysis\n",
    "# basically it studies the data whether variables are related\n",
    "# or independent of each other\n",
    "chi_2_features = SelectKBest(chi2, k=len(X_cat.columns))\n",
    "\n",
    "# fit our data to the SelectKBest\n",
    "best_features = chi_2_features.fit(X_cat,y.astype(int))\n",
    "\n",
    "# use decimal format in table print later\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "# wrap it up, and show the results\n",
    "# the higher the score, the more effect that column has on price\n",
    "df_features = pd.DataFrame(best_features.scores_)\n",
    "df_columns = pd.DataFrame(X_cat.columns)\n",
    "f_scores = pd.concat([df_columns,df_features],axis=1)\n",
    "f_scores.columns = ['Features','Score']\n",
    "f_scores.sort_values(by='Score',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train/test/validation -split</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unfortunately the scikit-learn's train_test_split doesn't support validation\n",
    "# set split in itself.\n",
    "# if you want to split the test set into two for a validation set too, try this trick:\n",
    "\n",
    "# first, train/test split => 70% for training, 30% for other purposes (temp)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=101)\n",
    "\n",
    "# now, split the 30% for other purposes by 50% (resulting in 2 x 15%)\n",
    "# so finally, we have:\n",
    "# 70% for training\n",
    "# 15% for testing\n",
    "# 15% for validation\n",
    "# => 70 + 15 +15 = 100%\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data amount: 15129\n",
      "Test data amount: 3242\n",
      "Validation data amount: 3242\n"
     ]
    }
   ],
   "source": [
    "# just seeing how much data we have in each\n",
    "print(f\"Train data amount: {len(X_train)}\")\n",
    "print(f\"Test data amount: {len(X_test)}\")\n",
    "print(f\"Validation data amount: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> First Approach</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by using Sequential neural network model and changing the layers nodes along with manuplating the colum, I droping the colums like id, date and bedroom, bathrooms, time zoon, or tried to experiment with different colums as well, Unfortunatielly I get just only best R-squared value 0.71, in other experiments or manuplation sometime i got 6, 6.5, or 5 like that..\n",
    "# model = keras.Sequential(\n",
    "#     [\n",
    "#         layers.Dense(8, activation=\"relu\", input_shape=(variable_amount,)),\n",
    "#         layers.Dense(32, activation=\"relu\"),\n",
    "#         layers.Dense(16, activation=\"relu\"),\n",
    "#         layers.Dense(1)\n",
    "#     ]\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Second Approach & Optimization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/layers/normalization/batch_normalization.py:143: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m2,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,561</span> (41.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m10,561\u001b[0m (41.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,529</span> (41.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,529\u001b[0m (41.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> (128.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m32\u001b[0m (128.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# I feel there is something wrong like underfitting and I could not get the best results, so i am changing my approach and applying optimization along with best checkpoint and saving the best score\n",
    "\n",
    "# I got best score which is 0.85 by using modelCheckpoint and save the best score by using closer the layers\n",
    "# by wider the layers \n",
    "\n",
    "# save this info to a variable so we don't have to change this after\n",
    "# changing the dataset\n",
    "variable_amount = len(X.columns)\n",
    "\n",
    "# for EarlyStop/ReduceLROnPlateau, see materials and Moodle\n",
    "# for examples on how to use and when to use (usually more useful with classification)\n",
    "\n",
    "# create a model checkpoint to a file, and only save the best one\n",
    "mc = ModelCheckpoint('best_model_regression1.keras', monitor='val_loss', mode='min', save_best_only=True)\n",
    "\n",
    "# combine all active callbacks into a list\n",
    "# have only those you need, for example only ModelCheckpoint\n",
    "callback_list = [mc]\n",
    "\n",
    "# Define Sequential neural network model\n",
    "# modify the input shape to match your training column count\n",
    "# remember, one of the columns is removed from training columns\n",
    "# to be the target value. so if your data originally had 10 columns\n",
    "# the input shape is 9 ... (10 - 1 => 9)\n",
    "# the input layer itself can have a different number of nodes\n",
    "# Tip: have at least the same number of nodes as in the input shape\n",
    "# output layer in regression is always 1 node without activation function\n",
    "\n",
    "# three most common alternatives for the regularizer\n",
    "# kernel_regularizer=keras.regularizers.l1(l1=0.1)\n",
    "# kernel_regularizer=keras.regularizers.l2(l2=0.1)\n",
    "# kernel_regularizer=keras.regularizers.l1_l2(l1=0.1, l2=0.1)\n",
    "\n",
    "# typically you can use normalization + regularizer for your model\n",
    "# also try to alter the complexity and size of the neural network\n",
    "# it can greatly affect the performance\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.BatchNormalization(input_shape=(variable_amount,)),\n",
    "        layers.Dense(128, activation=\"relu\", kernel_regularizer=keras.regularizers.l1(l1=0.1)),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# select the optimizer and loss function\n",
    "# you can try rmsprop also as optimizer, or stochastic gradient descent\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# common tips on how to change neural network structure if your metrics are not good:\n",
    "\n",
    "# make wider (or narrower) layers (for example, 64 or 128 nodes)\n",
    "# make a longer or shorter network (add or remove layers)\n",
    "# use Dropout -layers (e.g. layers.Dropout(0.1))\n",
    "\n",
    "# remember: there's no process or mathematical formula\n",
    "# in order to figure out the optimal neural network structure\n",
    "# it's mostly all about trial and error => EXPERIMENTATION!\n",
    "\n",
    "# remember to have enough \"decision-space\" for your data!\n",
    "# it's highly unlikely a dataset with 20 different variables is going\n",
    "# to work well with only 8 nodes in each layer etc.\n",
    "\n",
    "# print out the summary of your model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create neural network structure</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "  #variable_amount = len(X.columns)\n",
    "\n",
    "\n",
    "# Second Approch\n",
    "\n",
    "\n",
    " #model = keras.Sequential(\n",
    "  #  [\n",
    "   #     layers.BatchNormalization(input_shape=(variable_amount,)),\n",
    "    #    layers.Dense(8, activation=\"relu\", kernel_regularizer=keras.regularizers.l1(l1=0.1)),\n",
    "     #   layers.Dropout(0.1),\n",
    "      #  layers.Dense(8, activation=\"relu\"),\n",
    "       # layers.Dense(1)\n",
    "   # ]\n",
    "#)\n",
    "\n",
    "# select the optimizer and loss function\n",
    "# you can try rmsprop also as optimizer, or stochastic gradient descent\n",
    "\n",
    "    #model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# common tips on how to change neural network structure if your metrics are not good:\n",
    "\n",
    "# make wider (or narrower) layers (for example, 64 or 128 nodes)\n",
    "# make a longer or shorter network (add or remove layers)\n",
    "# use Dropout -layers (e.g. layers.Dropout(0.1))\n",
    "\n",
    "# remember: there's no process or mathematical formula\n",
    "# in order to figure out the optimal neural network structure\n",
    "# it's mostly all about trial and error => EXPERIMENTATION!\n",
    "\n",
    "# remember to have enough \"decision-space\" for your data!\n",
    "# it's highly unlikely a dataset with 20 different variables is going\n",
    "# to work well with only 8 nodes in each layer etc.\n",
    "\n",
    "# print out the summary of your model\n",
    " # model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train the neural network with our data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516us/step - loss: 418536947712.0000 - val_loss: 373146550272.0000\n",
      "Epoch 2/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 256025821184.0000 - val_loss: 55317749760.0000\n",
      "Epoch 3/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - loss: 67308474368.0000 - val_loss: 46850723840.0000\n",
      "Epoch 4/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 58776100864.0000 - val_loss: 44349878272.0000\n",
      "Epoch 5/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 54136659968.0000 - val_loss: 42824830976.0000\n",
      "Epoch 6/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 58135793664.0000 - val_loss: 42155884544.0000\n",
      "Epoch 7/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 57814802432.0000 - val_loss: 41202733056.0000\n",
      "Epoch 8/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 48389857280.0000 - val_loss: 40656371712.0000\n",
      "Epoch 9/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 55619059712.0000 - val_loss: 40072404992.0000\n",
      "Epoch 10/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 56092962816.0000 - val_loss: 39565402112.0000\n",
      "Epoch 11/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 55672168448.0000 - val_loss: 39175491584.0000\n",
      "Epoch 12/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - loss: 55531343872.0000 - val_loss: 38737125376.0000\n",
      "Epoch 13/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 59230765056.0000 - val_loss: 38368010240.0000\n",
      "Epoch 14/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 49275547648.0000 - val_loss: 38349377536.0000\n",
      "Epoch 15/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 46935867392.0000 - val_loss: 38066737152.0000\n",
      "Epoch 16/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 51592564736.0000 - val_loss: 37792808960.0000\n",
      "Epoch 17/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 50291920896.0000 - val_loss: 37690138624.0000\n",
      "Epoch 18/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 45569359872.0000 - val_loss: 37573152768.0000\n",
      "Epoch 19/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 52117037056.0000 - val_loss: 37621075968.0000\n",
      "Epoch 20/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 50946211840.0000 - val_loss: 37610668032.0000\n",
      "Epoch 21/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 47374516224.0000 - val_loss: 37497049088.0000\n",
      "Epoch 22/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 52484591616.0000 - val_loss: 37457698816.0000\n",
      "Epoch 23/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 48211996672.0000 - val_loss: 37766393856.0000\n",
      "Epoch 24/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 49491783680.0000 - val_loss: 37816004608.0000\n",
      "Epoch 25/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 46671417344.0000 - val_loss: 38269812736.0000\n",
      "Epoch 26/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 50879553536.0000 - val_loss: 37587898368.0000\n",
      "Epoch 27/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 48223662080.0000 - val_loss: 38214340608.0000\n",
      "Epoch 28/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 48978247680.0000 - val_loss: 38482251776.0000\n",
      "Epoch 29/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 47184621568.0000 - val_loss: 38180265984.0000\n",
      "Epoch 30/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 51527520256.0000 - val_loss: 38742937600.0000\n",
      "Epoch 31/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 48797671424.0000 - val_loss: 38634078208.0000\n",
      "Epoch 32/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 55828553728.0000 - val_loss: 39109156864.0000\n",
      "Epoch 33/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 53639127040.0000 - val_loss: 38768476160.0000\n",
      "Epoch 34/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 47986491392.0000 - val_loss: 38824665088.0000\n",
      "Epoch 35/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 47170977792.0000 - val_loss: 39930736640.0000\n",
      "Epoch 36/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 48488624128.0000 - val_loss: 39548911616.0000\n",
      "Epoch 37/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 44434296832.0000 - val_loss: 39403466752.0000\n",
      "Epoch 38/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 52964319232.0000 - val_loss: 40165011456.0000\n",
      "Epoch 39/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 53637730304.0000 - val_loss: 40916541440.0000\n",
      "Epoch 40/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 51943485440.0000 - val_loss: 40093044736.0000\n",
      "Epoch 41/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 48457084928.0000 - val_loss: 40937385984.0000\n",
      "Epoch 42/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 54718939136.0000 - val_loss: 40668123136.0000\n",
      "Epoch 43/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 49951420416.0000 - val_loss: 40812023808.0000\n",
      "Epoch 44/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - loss: 46364979200.0000 - val_loss: 40351821824.0000\n",
      "Epoch 45/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 47562067968.0000 - val_loss: 40461631488.0000\n",
      "Epoch 46/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 51987861504.0000 - val_loss: 40648273920.0000\n",
      "Epoch 47/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 47838588928.0000 - val_loss: 40186003456.0000\n",
      "Epoch 48/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 49133543424.0000 - val_loss: 40208883712.0000\n",
      "Epoch 49/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 51990024192.0000 - val_loss: 39784853504.0000\n",
      "Epoch 50/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 49573064704.0000 - val_loss: 41280421888.0000\n",
      "Epoch 51/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 49165205504.0000 - val_loss: 40378851328.0000\n",
      "Epoch 52/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 44073410560.0000 - val_loss: 41374380032.0000\n",
      "Epoch 53/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 49486782464.0000 - val_loss: 40049225728.0000\n",
      "Epoch 54/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 51333136384.0000 - val_loss: 40722079744.0000\n",
      "Epoch 55/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - loss: 51714985984.0000 - val_loss: 40404688896.0000\n",
      "Epoch 56/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 44964425728.0000 - val_loss: 40346562560.0000\n",
      "Epoch 57/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 48999010304.0000 - val_loss: 41062391808.0000\n",
      "Epoch 58/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 48516382720.0000 - val_loss: 40837455872.0000\n",
      "Epoch 59/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - loss: 56751165440.0000 - val_loss: 41652207616.0000\n",
      "Epoch 60/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 51538157568.0000 - val_loss: 40339238912.0000\n",
      "Epoch 61/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 44936048640.0000 - val_loss: 39580647424.0000\n",
      "Epoch 62/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 49935704064.0000 - val_loss: 41067802624.0000\n",
      "Epoch 63/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 58780643328.0000 - val_loss: 41111019520.0000\n",
      "Epoch 64/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 46303178752.0000 - val_loss: 38797864960.0000\n",
      "Epoch 65/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - loss: 44442689536.0000 - val_loss: 40760639488.0000\n",
      "Epoch 66/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 43646291968.0000 - val_loss: 40371159040.0000\n",
      "Epoch 67/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 49105608704.0000 - val_loss: 39278440448.0000\n",
      "Epoch 68/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 49208233984.0000 - val_loss: 39579598848.0000\n",
      "Epoch 69/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 43606384640.0000 - val_loss: 39850360832.0000\n",
      "Epoch 70/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - loss: 46037630976.0000 - val_loss: 39689621504.0000\n",
      "Epoch 71/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 47836368896.0000 - val_loss: 40037502976.0000\n",
      "Epoch 72/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 48880848896.0000 - val_loss: 38954250240.0000\n",
      "Epoch 73/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - loss: 53146681344.0000 - val_loss: 39120257024.0000\n",
      "Epoch 74/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 44631302144.0000 - val_loss: 40387031040.0000\n",
      "Epoch 75/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 47240777728.0000 - val_loss: 40145256448.0000\n",
      "Epoch 76/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 47313362944.0000 - val_loss: 39667957760.0000\n",
      "Epoch 77/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 48853413888.0000 - val_loss: 39020814336.0000\n",
      "Epoch 78/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 48997019648.0000 - val_loss: 38985973760.0000\n",
      "Epoch 79/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 52737814528.0000 - val_loss: 39152455680.0000\n",
      "Epoch 80/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 45904089088.0000 - val_loss: 40989822976.0000\n",
      "Epoch 81/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 42960011264.0000 - val_loss: 39218053120.0000\n",
      "Epoch 82/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 42834436096.0000 - val_loss: 38826196992.0000\n",
      "Epoch 83/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 49559412736.0000 - val_loss: 39263322112.0000\n",
      "Epoch 84/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 46102630400.0000 - val_loss: 37976170496.0000\n",
      "Epoch 85/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 40449773568.0000 - val_loss: 38729101312.0000\n",
      "Epoch 86/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 46060097536.0000 - val_loss: 38174527488.0000\n",
      "Epoch 87/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 48409571328.0000 - val_loss: 38532698112.0000\n",
      "Epoch 88/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 41604141056.0000 - val_loss: 37987483648.0000\n",
      "Epoch 89/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 42978041856.0000 - val_loss: 37953970176.0000\n",
      "Epoch 90/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 47593259008.0000 - val_loss: 38712524800.0000\n",
      "Epoch 91/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 44801060864.0000 - val_loss: 37525594112.0000\n",
      "Epoch 92/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 44802232320.0000 - val_loss: 37615656960.0000\n",
      "Epoch 93/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 42977902592.0000 - val_loss: 37285638144.0000\n",
      "Epoch 94/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 43053223936.0000 - val_loss: 38318370816.0000\n",
      "Epoch 95/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 48018923520.0000 - val_loss: 38622523392.0000\n",
      "Epoch 96/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 43853533184.0000 - val_loss: 36587737088.0000\n",
      "Epoch 97/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 39764815872.0000 - val_loss: 36234272768.0000\n",
      "Epoch 98/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 44438749184.0000 - val_loss: 36733071360.0000\n",
      "Epoch 99/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 42553303040.0000 - val_loss: 36442611712.0000\n",
      "Epoch 100/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 43399790592.0000 - val_loss: 36854226944.0000\n",
      "Epoch 101/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 44907712512.0000 - val_loss: 38921846784.0000\n",
      "Epoch 102/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 46998867968.0000 - val_loss: 38036500480.0000\n",
      "Epoch 103/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 39318528000.0000 - val_loss: 37841788928.0000\n",
      "Epoch 104/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 44484517888.0000 - val_loss: 37631279104.0000\n",
      "Epoch 105/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 41535545344.0000 - val_loss: 37563539456.0000\n",
      "Epoch 106/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 38939254784.0000 - val_loss: 37840244736.0000\n",
      "Epoch 107/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 45777674240.0000 - val_loss: 35840970752.0000\n",
      "Epoch 108/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - loss: 44693331968.0000 - val_loss: 36993134592.0000\n",
      "Epoch 109/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 43095572480.0000 - val_loss: 35640029184.0000\n",
      "Epoch 110/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 40917991424.0000 - val_loss: 36333903872.0000\n",
      "Epoch 111/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 39978729472.0000 - val_loss: 36826320896.0000\n",
      "Epoch 112/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 42629595136.0000 - val_loss: 36976799744.0000\n",
      "Epoch 113/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 40368439296.0000 - val_loss: 35017830400.0000\n",
      "Epoch 114/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 45934714880.0000 - val_loss: 35805786112.0000\n",
      "Epoch 115/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 39358558208.0000 - val_loss: 36264263680.0000\n",
      "Epoch 116/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - loss: 39783550976.0000 - val_loss: 35759886336.0000\n",
      "Epoch 117/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 41559654400.0000 - val_loss: 35248087040.0000\n",
      "Epoch 118/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 39084933120.0000 - val_loss: 35546693632.0000\n",
      "Epoch 119/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 43240456192.0000 - val_loss: 34632126464.0000\n",
      "Epoch 120/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 38296309760.0000 - val_loss: 36060983296.0000\n",
      "Epoch 121/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 40184340480.0000 - val_loss: 34382475264.0000\n",
      "Epoch 122/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 38630055936.0000 - val_loss: 34698379264.0000\n",
      "Epoch 123/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 41038901248.0000 - val_loss: 36020514816.0000\n",
      "Epoch 124/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 38915100672.0000 - val_loss: 35581255680.0000\n",
      "Epoch 125/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 39425146880.0000 - val_loss: 33903671296.0000\n",
      "Epoch 126/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - loss: 40982487040.0000 - val_loss: 36901294080.0000\n",
      "Epoch 127/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 40669429760.0000 - val_loss: 34932477952.0000\n",
      "Epoch 128/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 40649867264.0000 - val_loss: 34069676032.0000\n",
      "Epoch 129/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 40592003072.0000 - val_loss: 34675113984.0000\n",
      "Epoch 130/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 40483446784.0000 - val_loss: 34243596288.0000\n",
      "Epoch 131/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 40856317952.0000 - val_loss: 33624225792.0000\n",
      "Epoch 132/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 41166458880.0000 - val_loss: 36031963136.0000\n",
      "Epoch 133/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 41455374336.0000 - val_loss: 35345117184.0000\n",
      "Epoch 134/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 50800762880.0000 - val_loss: 33410557952.0000\n",
      "Epoch 135/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 39924490240.0000 - val_loss: 33441167360.0000\n",
      "Epoch 136/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 39135576064.0000 - val_loss: 35474677760.0000\n",
      "Epoch 137/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 42379423744.0000 - val_loss: 35026931712.0000\n",
      "Epoch 138/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 38859829248.0000 - val_loss: 34875817984.0000\n",
      "Epoch 139/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 41013178368.0000 - val_loss: 34297372672.0000\n",
      "Epoch 140/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 41121812480.0000 - val_loss: 34048184320.0000\n",
      "Epoch 141/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 39161905152.0000 - val_loss: 35561775104.0000\n",
      "Epoch 142/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 36891508736.0000 - val_loss: 35004387328.0000\n",
      "Epoch 143/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - loss: 40841924608.0000 - val_loss: 33149075456.0000\n",
      "Epoch 144/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 36342018048.0000 - val_loss: 34116075520.0000\n",
      "Epoch 145/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 37906411520.0000 - val_loss: 34991685632.0000\n",
      "Epoch 146/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 40990216192.0000 - val_loss: 33995921408.0000\n",
      "Epoch 147/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 41993568256.0000 - val_loss: 34349787136.0000\n",
      "Epoch 148/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 39985414144.0000 - val_loss: 32908251136.0000\n",
      "Epoch 149/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 34649452544.0000 - val_loss: 36450881536.0000\n",
      "Epoch 150/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 38361997312.0000 - val_loss: 36273672192.0000\n",
      "Epoch 151/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - loss: 37743185920.0000 - val_loss: 33554724864.0000\n",
      "Epoch 152/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 39636512768.0000 - val_loss: 33997158400.0000\n",
      "Epoch 153/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 38621278208.0000 - val_loss: 34555154432.0000\n",
      "Epoch 154/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 37064908800.0000 - val_loss: 34609270784.0000\n",
      "Epoch 155/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 39257862144.0000 - val_loss: 35849125888.0000\n",
      "Epoch 156/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 38747996160.0000 - val_loss: 36354822144.0000\n",
      "Epoch 157/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 39783137280.0000 - val_loss: 35757027328.0000\n",
      "Epoch 158/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 44392042496.0000 - val_loss: 35108962304.0000\n",
      "Epoch 159/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 36304449536.0000 - val_loss: 34204297216.0000\n",
      "Epoch 160/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 40470532096.0000 - val_loss: 34762723328.0000\n",
      "Epoch 161/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 39958675456.0000 - val_loss: 33419853824.0000\n",
      "Epoch 162/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 37828333568.0000 - val_loss: 33393909760.0000\n",
      "Epoch 163/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 38229733376.0000 - val_loss: 34071136256.0000\n",
      "Epoch 164/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 39635795968.0000 - val_loss: 32883003392.0000\n",
      "Epoch 165/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 34883297280.0000 - val_loss: 35800080384.0000\n",
      "Epoch 166/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 39160098816.0000 - val_loss: 32922421248.0000\n",
      "Epoch 167/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 35582251008.0000 - val_loss: 34178162688.0000\n",
      "Epoch 168/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 38045716480.0000 - val_loss: 33715447808.0000\n",
      "Epoch 169/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 37734170624.0000 - val_loss: 34780442624.0000\n",
      "Epoch 170/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 35474313216.0000 - val_loss: 34227544064.0000\n",
      "Epoch 171/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 39711789056.0000 - val_loss: 36406005760.0000\n",
      "Epoch 172/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 37238919168.0000 - val_loss: 34337144832.0000\n",
      "Epoch 173/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 41545699328.0000 - val_loss: 34596130816.0000\n",
      "Epoch 174/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 41350823936.0000 - val_loss: 35376181248.0000\n",
      "Epoch 175/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 41323884544.0000 - val_loss: 34601676800.0000\n",
      "Epoch 176/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 37949579264.0000 - val_loss: 36224262144.0000\n",
      "Epoch 177/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 36250066944.0000 - val_loss: 34959585280.0000\n",
      "Epoch 178/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 39032864768.0000 - val_loss: 36678651904.0000\n",
      "Epoch 179/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 36643786752.0000 - val_loss: 33702354944.0000\n",
      "Epoch 180/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 36957253632.0000 - val_loss: 33857646592.0000\n",
      "Epoch 181/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 36158455808.0000 - val_loss: 35026890752.0000\n",
      "Epoch 182/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 36727848960.0000 - val_loss: 33539219456.0000\n",
      "Epoch 183/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 38484860928.0000 - val_loss: 34317555712.0000\n",
      "Epoch 184/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 41175252992.0000 - val_loss: 35242561536.0000\n",
      "Epoch 185/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 36071784448.0000 - val_loss: 34560143360.0000\n",
      "Epoch 186/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 41425575936.0000 - val_loss: 34794373120.0000\n",
      "Epoch 187/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 36706877440.0000 - val_loss: 35529404416.0000\n",
      "Epoch 188/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 39974146048.0000 - val_loss: 34386866176.0000\n",
      "Epoch 189/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 40414949376.0000 - val_loss: 33912922112.0000\n",
      "Epoch 190/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 35475128320.0000 - val_loss: 33780420608.0000\n",
      "Epoch 191/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 38207627264.0000 - val_loss: 35081089024.0000\n",
      "Epoch 192/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 37779550208.0000 - val_loss: 32513755136.0000\n",
      "Epoch 193/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 39095644160.0000 - val_loss: 34608861184.0000\n",
      "Epoch 194/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 35931365376.0000 - val_loss: 33080379392.0000\n",
      "Epoch 195/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 36078596096.0000 - val_loss: 34785361920.0000\n",
      "Epoch 196/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 35766099968.0000 - val_loss: 35155886080.0000\n",
      "Epoch 197/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 39349710848.0000 - val_loss: 36231270400.0000\n",
      "Epoch 198/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 36660264960.0000 - val_loss: 34530365440.0000\n",
      "Epoch 199/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 37005209600.0000 - val_loss: 33918576640.0000\n",
      "Epoch 200/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 40994963456.0000 - val_loss: 36156035072.0000\n",
      "Epoch 201/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 37771083776.0000 - val_loss: 34721742848.0000\n",
      "Epoch 202/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 37713379328.0000 - val_loss: 36610383872.0000\n",
      "Epoch 203/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 38451326976.0000 - val_loss: 38067998720.0000\n",
      "Epoch 204/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 38645071872.0000 - val_loss: 37073948672.0000\n",
      "Epoch 205/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 42743394304.0000 - val_loss: 37597249536.0000\n",
      "Epoch 206/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 36695941120.0000 - val_loss: 34132449280.0000\n",
      "Epoch 207/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 36197830656.0000 - val_loss: 35603410944.0000\n",
      "Epoch 208/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 36728737792.0000 - val_loss: 38018228224.0000\n",
      "Epoch 209/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 37710073856.0000 - val_loss: 36141416448.0000\n",
      "Epoch 210/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 34854604800.0000 - val_loss: 33389254656.0000\n",
      "Epoch 211/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 37025746944.0000 - val_loss: 34902515712.0000\n",
      "Epoch 212/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 38717640704.0000 - val_loss: 34876784640.0000\n",
      "Epoch 213/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 36810989568.0000 - val_loss: 34473590784.0000\n",
      "Epoch 214/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 34424246272.0000 - val_loss: 34135728128.0000\n",
      "Epoch 215/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 38826328064.0000 - val_loss: 36727050240.0000\n",
      "Epoch 216/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 38222266368.0000 - val_loss: 35372634112.0000\n",
      "Epoch 217/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 42923057152.0000 - val_loss: 33011769344.0000\n",
      "Epoch 218/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 38105759744.0000 - val_loss: 35760758784.0000\n",
      "Epoch 219/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 35956203520.0000 - val_loss: 34552434688.0000\n",
      "Epoch 220/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 37909897216.0000 - val_loss: 37611159552.0000\n",
      "Epoch 221/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 35977756672.0000 - val_loss: 33293824000.0000\n",
      "Epoch 222/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 36210851840.0000 - val_loss: 35249934336.0000\n",
      "Epoch 223/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: 37537927168.0000 - val_loss: 36316934144.0000\n",
      "Epoch 224/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 35144654848.0000 - val_loss: 33578387456.0000\n",
      "Epoch 225/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 36230062080.0000 - val_loss: 38437240832.0000\n",
      "Epoch 226/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 37067673600.0000 - val_loss: 34540498944.0000\n",
      "Epoch 227/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 33123260416.0000 - val_loss: 36361191424.0000\n",
      "Epoch 228/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 35689218048.0000 - val_loss: 36604407808.0000\n",
      "Epoch 229/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 34596126720.0000 - val_loss: 35639996416.0000\n",
      "Epoch 230/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 35956654080.0000 - val_loss: 36726816768.0000\n",
      "Epoch 231/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 38064771072.0000 - val_loss: 35657326592.0000\n",
      "Epoch 232/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 37236350976.0000 - val_loss: 35955867648.0000\n",
      "Epoch 233/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 35640057856.0000 - val_loss: 36853702656.0000\n",
      "Epoch 234/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 36740403200.0000 - val_loss: 37403336704.0000\n",
      "Epoch 235/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 37582544896.0000 - val_loss: 36482990080.0000\n",
      "Epoch 236/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 40346066944.0000 - val_loss: 35156721664.0000\n",
      "Epoch 237/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 36774109184.0000 - val_loss: 34606194688.0000\n",
      "Epoch 238/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 37106610176.0000 - val_loss: 33603184640.0000\n",
      "Epoch 239/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 35873419264.0000 - val_loss: 33763442688.0000\n",
      "Epoch 240/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 35136729088.0000 - val_loss: 34321152000.0000\n",
      "Epoch 241/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 34266284032.0000 - val_loss: 35140583424.0000\n",
      "Epoch 242/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 36036317184.0000 - val_loss: 36291678208.0000\n",
      "Epoch 243/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 36197380096.0000 - val_loss: 35189518336.0000\n",
      "Epoch 244/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 36201906176.0000 - val_loss: 37578993664.0000\n",
      "Epoch 245/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 34094589952.0000 - val_loss: 35050569728.0000\n",
      "Epoch 246/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 38931128320.0000 - val_loss: 37471281152.0000\n",
      "Epoch 247/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 35054350336.0000 - val_loss: 35245568000.0000\n",
      "Epoch 248/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 34776252416.0000 - val_loss: 33576857600.0000\n",
      "Epoch 249/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 36972982272.0000 - val_loss: 36206530560.0000\n",
      "Epoch 250/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 38328123392.0000 - val_loss: 34140600320.0000\n",
      "Epoch 251/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 38074712064.0000 - val_loss: 37846593536.0000\n",
      "Epoch 252/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 35519565824.0000 - val_loss: 34699132928.0000\n",
      "Epoch 253/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 37376094208.0000 - val_loss: 36900339712.0000\n",
      "Epoch 254/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 37224894464.0000 - val_loss: 34807451648.0000\n",
      "Epoch 255/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 34791141376.0000 - val_loss: 36241879040.0000\n",
      "Epoch 256/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 36221812736.0000 - val_loss: 35838644224.0000\n",
      "Epoch 257/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 35862458368.0000 - val_loss: 34437763072.0000\n",
      "Epoch 258/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 35392708608.0000 - val_loss: 36041719808.0000\n",
      "Epoch 259/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 35868188672.0000 - val_loss: 34775392256.0000\n",
      "Epoch 260/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 39192629248.0000 - val_loss: 36343836672.0000\n",
      "Epoch 261/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 36634755072.0000 - val_loss: 37461872640.0000\n",
      "Epoch 262/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 37942292480.0000 - val_loss: 37334339584.0000\n",
      "Epoch 263/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 37347151872.0000 - val_loss: 39457845248.0000\n",
      "Epoch 264/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 36473720832.0000 - val_loss: 35449950208.0000\n",
      "Epoch 265/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 38911299584.0000 - val_loss: 35753488384.0000\n",
      "Epoch 266/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 41341095936.0000 - val_loss: 35631935488.0000\n",
      "Epoch 267/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 33781350400.0000 - val_loss: 37618520064.0000\n",
      "Epoch 268/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 35562307584.0000 - val_loss: 35098787840.0000\n",
      "Epoch 269/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 37219786752.0000 - val_loss: 35009581056.0000\n",
      "Epoch 270/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 36791689216.0000 - val_loss: 35331907584.0000\n",
      "Epoch 271/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 35650445312.0000 - val_loss: 33849700352.0000\n",
      "Epoch 272/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - loss: 34548744192.0000 - val_loss: 36138590208.0000\n",
      "Epoch 273/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 33741776896.0000 - val_loss: 34984108032.0000\n",
      "Epoch 274/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 38539268096.0000 - val_loss: 35814125568.0000\n",
      "Epoch 275/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 34377228288.0000 - val_loss: 36538626048.0000\n",
      "Epoch 276/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 35971821568.0000 - val_loss: 38211526656.0000\n",
      "Epoch 277/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 32071057408.0000 - val_loss: 36923297792.0000\n",
      "Epoch 278/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - loss: 34140485632.0000 - val_loss: 37903343616.0000\n",
      "Epoch 279/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 37060333568.0000 - val_loss: 37297168384.0000\n",
      "Epoch 280/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 35168489472.0000 - val_loss: 37976784896.0000\n",
      "Epoch 281/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 32312743936.0000 - val_loss: 35344351232.0000\n",
      "Epoch 282/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 37239287808.0000 - val_loss: 35057709056.0000\n",
      "Epoch 283/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - loss: 37356716032.0000 - val_loss: 41620090880.0000\n",
      "Epoch 284/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 39324155904.0000 - val_loss: 37412696064.0000\n",
      "Epoch 285/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 33435076608.0000 - val_loss: 35727351808.0000\n",
      "Epoch 286/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 34570612736.0000 - val_loss: 35510751232.0000\n",
      "Epoch 287/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 38223130624.0000 - val_loss: 35808976896.0000\n",
      "Epoch 288/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - loss: 35959222272.0000 - val_loss: 36723777536.0000\n",
      "Epoch 289/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 34395828224.0000 - val_loss: 34689523712.0000\n",
      "Epoch 290/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 32701855744.0000 - val_loss: 39192211456.0000\n",
      "Epoch 291/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 35893395456.0000 - val_loss: 35353194496.0000\n",
      "Epoch 292/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 35192668160.0000 - val_loss: 36443041792.0000\n",
      "Epoch 293/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 38014812160.0000 - val_loss: 39617089536.0000\n",
      "Epoch 294/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 32417265664.0000 - val_loss: 41150279680.0000\n",
      "Epoch 295/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 34885115904.0000 - val_loss: 35053617152.0000\n",
      "Epoch 296/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 37125308416.0000 - val_loss: 36911788032.0000\n",
      "Epoch 297/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 33761153024.0000 - val_loss: 37989584896.0000\n",
      "Epoch 298/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 37489471488.0000 - val_loss: 37805305856.0000\n",
      "Epoch 299/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 36716425216.0000 - val_loss: 35050725376.0000\n",
      "Epoch 300/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 36017008640.0000 - val_loss: 35477344256.0000\n",
      "Epoch 301/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 34279481344.0000 - val_loss: 36995850240.0000\n",
      "Epoch 302/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 35746979840.0000 - val_loss: 37482582016.0000\n",
      "Epoch 303/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 34969628672.0000 - val_loss: 36150620160.0000\n",
      "Epoch 304/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 33644650496.0000 - val_loss: 35335417856.0000\n",
      "Epoch 305/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 37181120512.0000 - val_loss: 36252479488.0000\n",
      "Epoch 306/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 34180874240.0000 - val_loss: 33694003200.0000\n",
      "Epoch 307/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 36749742080.0000 - val_loss: 35764666368.0000\n",
      "Epoch 308/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 36982837248.0000 - val_loss: 36745109504.0000\n",
      "Epoch 309/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 36291203072.0000 - val_loss: 38246621184.0000\n",
      "Epoch 310/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 35804536832.0000 - val_loss: 37070499840.0000\n",
      "Epoch 311/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 35609612288.0000 - val_loss: 34854592512.0000\n",
      "Epoch 312/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 34318413824.0000 - val_loss: 38623711232.0000\n",
      "Epoch 313/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 34051018752.0000 - val_loss: 38807650304.0000\n",
      "Epoch 314/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 33528827904.0000 - val_loss: 36203909120.0000\n",
      "Epoch 315/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 33087950848.0000 - val_loss: 37477634048.0000\n",
      "Epoch 316/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 31893856256.0000 - val_loss: 34279655424.0000\n",
      "Epoch 317/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 32589504512.0000 - val_loss: 34194552832.0000\n",
      "Epoch 318/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 34935697408.0000 - val_loss: 35248607232.0000\n",
      "Epoch 319/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 34581704704.0000 - val_loss: 37146243072.0000\n",
      "Epoch 320/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 35739361280.0000 - val_loss: 38582640640.0000\n",
      "Epoch 321/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - loss: 36067106816.0000 - val_loss: 36543598592.0000\n",
      "Epoch 322/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 34293547008.0000 - val_loss: 37368676352.0000\n",
      "Epoch 323/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 35072950272.0000 - val_loss: 37049991168.0000\n",
      "Epoch 324/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 34419171328.0000 - val_loss: 40033378304.0000\n",
      "Epoch 325/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - loss: 32991422464.0000 - val_loss: 39363878912.0000\n",
      "Epoch 326/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: 34697150464.0000 - val_loss: 36957028352.0000\n",
      "Epoch 327/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 33096249344.0000 - val_loss: 33900347392.0000\n",
      "Epoch 328/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 32964802560.0000 - val_loss: 39875903488.0000\n",
      "Epoch 329/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 550us/step - loss: 34009221120.0000 - val_loss: 36792844288.0000\n",
      "Epoch 330/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 33633507328.0000 - val_loss: 35513491456.0000\n",
      "Epoch 331/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - loss: 32298409984.0000 - val_loss: 34720858112.0000\n",
      "Epoch 332/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 33525846016.0000 - val_loss: 35839840256.0000\n",
      "Epoch 333/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 32123512832.0000 - val_loss: 37218869248.0000\n",
      "Epoch 334/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 32265259008.0000 - val_loss: 37870198784.0000\n",
      "Epoch 335/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 33537406976.0000 - val_loss: 37779873792.0000\n",
      "Epoch 336/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 37230772224.0000 - val_loss: 38592864256.0000\n",
      "Epoch 337/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - loss: 33743886336.0000 - val_loss: 39233683456.0000\n",
      "Epoch 338/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 34363797504.0000 - val_loss: 36203761664.0000\n",
      "Epoch 339/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 36187992064.0000 - val_loss: 41049227264.0000\n",
      "Epoch 340/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 35345219584.0000 - val_loss: 38527651840.0000\n",
      "Epoch 341/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 34179293184.0000 - val_loss: 38581743616.0000\n",
      "Epoch 342/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - loss: 34606366720.0000 - val_loss: 35881807872.0000\n",
      "Epoch 343/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 32863590400.0000 - val_loss: 43477565440.0000\n",
      "Epoch 344/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 35763077120.0000 - val_loss: 36624977920.0000\n",
      "Epoch 345/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 34440810496.0000 - val_loss: 39169265664.0000\n",
      "Epoch 346/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 33863905280.0000 - val_loss: 34337718272.0000\n",
      "Epoch 347/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 35112574976.0000 - val_loss: 35979796480.0000\n",
      "Epoch 348/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 35558830080.0000 - val_loss: 36733399040.0000\n",
      "Epoch 349/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 36753072128.0000 - val_loss: 34724896768.0000\n",
      "Epoch 350/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 32654217216.0000 - val_loss: 36026314752.0000\n",
      "Epoch 351/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 34892562432.0000 - val_loss: 35561967616.0000\n",
      "Epoch 352/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 36411072512.0000 - val_loss: 34951163904.0000\n",
      "Epoch 353/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 32492908544.0000 - val_loss: 39897948160.0000\n",
      "Epoch 354/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 32334551040.0000 - val_loss: 34870272000.0000\n",
      "Epoch 355/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 38208843776.0000 - val_loss: 38679363584.0000\n",
      "Epoch 356/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 32714641408.0000 - val_loss: 36171407360.0000\n",
      "Epoch 357/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 35429990400.0000 - val_loss: 40247799808.0000\n",
      "Epoch 358/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 38634049536.0000 - val_loss: 36638625792.0000\n",
      "Epoch 359/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 32130785280.0000 - val_loss: 35043012608.0000\n",
      "Epoch 360/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 33373941760.0000 - val_loss: 36741324800.0000\n",
      "Epoch 361/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 34824544256.0000 - val_loss: 39532576768.0000\n",
      "Epoch 362/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - loss: 36404178944.0000 - val_loss: 39387131904.0000\n",
      "Epoch 363/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 31983077376.0000 - val_loss: 35492282368.0000\n",
      "Epoch 364/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 34728996864.0000 - val_loss: 39526752256.0000\n",
      "Epoch 365/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 32145643520.0000 - val_loss: 37547593728.0000\n",
      "Epoch 366/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 38249549824.0000 - val_loss: 37975838720.0000\n",
      "Epoch 367/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 31805284352.0000 - val_loss: 41080578048.0000\n",
      "Epoch 368/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 34444283904.0000 - val_loss: 34217721856.0000\n",
      "Epoch 369/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 32787945472.0000 - val_loss: 37441327104.0000\n",
      "Epoch 370/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 35646353408.0000 - val_loss: 39042949120.0000\n",
      "Epoch 371/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 31636928512.0000 - val_loss: 38528094208.0000\n",
      "Epoch 372/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 33336033280.0000 - val_loss: 38016684032.0000\n",
      "Epoch 373/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - loss: 32597106688.0000 - val_loss: 36255326208.0000\n",
      "Epoch 374/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 32886212608.0000 - val_loss: 37504126976.0000\n",
      "Epoch 375/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 35095105536.0000 - val_loss: 37840850944.0000\n",
      "Epoch 376/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 33303320576.0000 - val_loss: 35374559232.0000\n",
      "Epoch 377/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 34517561344.0000 - val_loss: 38526398464.0000\n",
      "Epoch 378/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 35687985152.0000 - val_loss: 37811408896.0000\n",
      "Epoch 379/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 35806609408.0000 - val_loss: 38766874624.0000\n",
      "Epoch 380/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 35733880832.0000 - val_loss: 40481558528.0000\n",
      "Epoch 381/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 32053878784.0000 - val_loss: 36490801152.0000\n",
      "Epoch 382/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 35755761664.0000 - val_loss: 37350641664.0000\n",
      "Epoch 383/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 35435499520.0000 - val_loss: 41249640448.0000\n",
      "Epoch 384/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 33874358272.0000 - val_loss: 36407980032.0000\n",
      "Epoch 385/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 33456480256.0000 - val_loss: 36160221184.0000\n",
      "Epoch 386/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 31768999936.0000 - val_loss: 37704224768.0000\n",
      "Epoch 387/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 33465104384.0000 - val_loss: 36956536832.0000\n",
      "Epoch 388/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 33207463936.0000 - val_loss: 34924257280.0000\n",
      "Epoch 389/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 35674542080.0000 - val_loss: 34834718720.0000\n",
      "Epoch 390/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 37234339840.0000 - val_loss: 38870016000.0000\n",
      "Epoch 391/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 32109901824.0000 - val_loss: 40976801792.0000\n",
      "Epoch 392/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 34659856384.0000 - val_loss: 34703970304.0000\n",
      "Epoch 393/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 32237711360.0000 - val_loss: 40169443328.0000\n",
      "Epoch 394/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 31228096512.0000 - val_loss: 37098467328.0000\n",
      "Epoch 395/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 31534032896.0000 - val_loss: 39285927936.0000\n",
      "Epoch 396/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 35001552896.0000 - val_loss: 40831094784.0000\n",
      "Epoch 397/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 35551113216.0000 - val_loss: 43404095488.0000\n",
      "Epoch 398/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 35320803328.0000 - val_loss: 36116054016.0000\n",
      "Epoch 399/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 33802756096.0000 - val_loss: 38845423616.0000\n",
      "Epoch 400/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 32090238976.0000 - val_loss: 38551633920.0000\n",
      "Epoch 401/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 31405762560.0000 - val_loss: 37722103808.0000\n",
      "Epoch 402/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 34120087552.0000 - val_loss: 37437087744.0000\n",
      "Epoch 403/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 31650781184.0000 - val_loss: 40112267264.0000\n",
      "Epoch 404/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 32766713856.0000 - val_loss: 39576469504.0000\n",
      "Epoch 405/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 35002916864.0000 - val_loss: 37574295552.0000\n",
      "Epoch 406/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 31894345728.0000 - val_loss: 43286654976.0000\n",
      "Epoch 407/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 32089673728.0000 - val_loss: 37133447168.0000\n",
      "Epoch 408/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - loss: 33679710208.0000 - val_loss: 37728419840.0000\n",
      "Epoch 409/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 33391593472.0000 - val_loss: 41154424832.0000\n",
      "Epoch 410/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 33068990464.0000 - val_loss: 37239336960.0000\n",
      "Epoch 411/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 31815839744.0000 - val_loss: 36437352448.0000\n",
      "Epoch 412/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 37963485184.0000 - val_loss: 44705443840.0000\n",
      "Epoch 413/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 33179545600.0000 - val_loss: 37291880448.0000\n",
      "Epoch 414/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 30442133504.0000 - val_loss: 35289202688.0000\n",
      "Epoch 415/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 35089162240.0000 - val_loss: 37849067520.0000\n",
      "Epoch 416/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 33242830848.0000 - val_loss: 37364940800.0000\n",
      "Epoch 417/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 30985037824.0000 - val_loss: 36020588544.0000\n",
      "Epoch 418/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 33570273280.0000 - val_loss: 43644583936.0000\n",
      "Epoch 419/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 31737477120.0000 - val_loss: 36632756224.0000\n",
      "Epoch 420/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 32556154880.0000 - val_loss: 39645892608.0000\n",
      "Epoch 421/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 34377523200.0000 - val_loss: 46427619328.0000\n",
      "Epoch 422/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 34704162816.0000 - val_loss: 44317511680.0000\n",
      "Epoch 423/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 33363859456.0000 - val_loss: 39281352704.0000\n",
      "Epoch 424/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 31815569408.0000 - val_loss: 39305519104.0000\n",
      "Epoch 425/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 33109993472.0000 - val_loss: 44147007488.0000\n",
      "Epoch 426/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 30487932928.0000 - val_loss: 44695363584.0000\n",
      "Epoch 427/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 31927300096.0000 - val_loss: 33884319744.0000\n",
      "Epoch 428/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 32484317184.0000 - val_loss: 37547106304.0000\n",
      "Epoch 429/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 32564430848.0000 - val_loss: 40979513344.0000\n",
      "Epoch 430/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 30660614144.0000 - val_loss: 37014917120.0000\n",
      "Epoch 431/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 30750089216.0000 - val_loss: 40350277632.0000\n",
      "Epoch 432/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 34481684480.0000 - val_loss: 36288278528.0000\n",
      "Epoch 433/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 34451968000.0000 - val_loss: 39059853312.0000\n",
      "Epoch 434/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 32294152192.0000 - val_loss: 36523851776.0000\n",
      "Epoch 435/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - loss: 32305917952.0000 - val_loss: 36639940608.0000\n",
      "Epoch 436/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 33058762752.0000 - val_loss: 36387250176.0000\n",
      "Epoch 437/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 35493093376.0000 - val_loss: 40478691328.0000\n",
      "Epoch 438/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 31754516480.0000 - val_loss: 38770016256.0000\n",
      "Epoch 439/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 31362990080.0000 - val_loss: 38099402752.0000\n",
      "Epoch 440/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 32803770368.0000 - val_loss: 40762650624.0000\n",
      "Epoch 441/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 32701990912.0000 - val_loss: 34787561472.0000\n",
      "Epoch 442/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - loss: 33127966720.0000 - val_loss: 35317374976.0000\n",
      "Epoch 443/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 33897506816.0000 - val_loss: 38326779904.0000\n",
      "Epoch 444/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 32934078464.0000 - val_loss: 39652495360.0000\n",
      "Epoch 445/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 30291927040.0000 - val_loss: 37989769216.0000\n",
      "Epoch 446/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 33474506752.0000 - val_loss: 40826925056.0000\n",
      "Epoch 447/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 32582621184.0000 - val_loss: 41516425216.0000\n",
      "Epoch 448/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 31912812544.0000 - val_loss: 39157334016.0000\n",
      "Epoch 449/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - loss: 32223635456.0000 - val_loss: 38665158656.0000\n",
      "Epoch 450/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 32182970368.0000 - val_loss: 39826726912.0000\n",
      "Epoch 451/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 32037408768.0000 - val_loss: 40040763392.0000\n",
      "Epoch 452/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 32049143808.0000 - val_loss: 33813553152.0000\n",
      "Epoch 453/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 33004263424.0000 - val_loss: 35116466176.0000\n",
      "Epoch 454/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 34527391744.0000 - val_loss: 38011351040.0000\n",
      "Epoch 455/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 34512728064.0000 - val_loss: 38435557376.0000\n",
      "Epoch 456/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 32086468608.0000 - val_loss: 37240016896.0000\n",
      "Epoch 457/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 32450945024.0000 - val_loss: 37602918400.0000\n",
      "Epoch 458/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - loss: 32243527680.0000 - val_loss: 35251924992.0000\n",
      "Epoch 459/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 32369293312.0000 - val_loss: 39597584384.0000\n",
      "Epoch 460/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 32672065536.0000 - val_loss: 46157807616.0000\n",
      "Epoch 461/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 33754077184.0000 - val_loss: 39692406784.0000\n",
      "Epoch 462/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 33805705216.0000 - val_loss: 36953366528.0000\n",
      "Epoch 463/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 31664785408.0000 - val_loss: 36244025344.0000\n",
      "Epoch 464/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 31260682240.0000 - val_loss: 39062405120.0000\n",
      "Epoch 465/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 34449174528.0000 - val_loss: 38819241984.0000\n",
      "Epoch 466/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 34660200448.0000 - val_loss: 38930296832.0000\n",
      "Epoch 467/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 31368701952.0000 - val_loss: 39052136448.0000\n",
      "Epoch 468/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 33928611840.0000 - val_loss: 38022418432.0000\n",
      "Epoch 469/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 32667045888.0000 - val_loss: 45443702784.0000\n",
      "Epoch 470/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 30148593664.0000 - val_loss: 40875274240.0000\n",
      "Epoch 471/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - loss: 31871920128.0000 - val_loss: 39428538368.0000\n",
      "Epoch 472/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - loss: 33206896640.0000 - val_loss: 42286723072.0000\n",
      "Epoch 473/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 33590136832.0000 - val_loss: 43019612160.0000\n",
      "Epoch 474/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - loss: 31282939904.0000 - val_loss: 35207991296.0000\n",
      "Epoch 475/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 30320748544.0000 - val_loss: 34429865984.0000\n",
      "Epoch 476/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 31622600704.0000 - val_loss: 39664164864.0000\n",
      "Epoch 477/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 31334098944.0000 - val_loss: 36060823552.0000\n",
      "Epoch 478/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 31630483456.0000 - val_loss: 36990308352.0000\n",
      "Epoch 479/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 36159950848.0000 - val_loss: 38441762816.0000\n",
      "Epoch 480/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - loss: 31881609216.0000 - val_loss: 35800506368.0000\n",
      "Epoch 481/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 28879616000.0000 - val_loss: 36035227648.0000\n",
      "Epoch 482/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 30710018048.0000 - val_loss: 44644765696.0000\n",
      "Epoch 483/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 30220965888.0000 - val_loss: 33268197376.0000\n",
      "Epoch 484/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 27574990848.0000 - val_loss: 41855655936.0000\n",
      "Epoch 485/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 29252833280.0000 - val_loss: 34003625984.0000\n",
      "Epoch 486/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 28558757888.0000 - val_loss: 35034755072.0000\n",
      "Epoch 487/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 28825911296.0000 - val_loss: 38340165632.0000\n",
      "Epoch 488/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 29565741056.0000 - val_loss: 38889078784.0000\n",
      "Epoch 489/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 28886214656.0000 - val_loss: 33128527872.0000\n",
      "Epoch 490/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 31836151808.0000 - val_loss: 34481946624.0000\n",
      "Epoch 491/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 28378884096.0000 - val_loss: 34990731264.0000\n",
      "Epoch 492/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 30122821632.0000 - val_loss: 37139431424.0000\n",
      "Epoch 493/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 30765647872.0000 - val_loss: 30649217024.0000\n",
      "Epoch 494/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 28519766016.0000 - val_loss: 35793608704.0000\n",
      "Epoch 495/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 30293055488.0000 - val_loss: 37361733632.0000\n",
      "Epoch 496/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 28743946240.0000 - val_loss: 35569254400.0000\n",
      "Epoch 497/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 32715145216.0000 - val_loss: 34948190208.0000\n",
      "Epoch 498/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 27164590080.0000 - val_loss: 33120583680.0000\n",
      "Epoch 499/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 28263657472.0000 - val_loss: 34813800448.0000\n",
      "Epoch 500/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 28689377280.0000 - val_loss: 37015248896.0000\n",
      "Epoch 501/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 26915262464.0000 - val_loss: 38160510976.0000\n",
      "Epoch 502/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 31022768128.0000 - val_loss: 38242738176.0000\n",
      "Epoch 503/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 29133312000.0000 - val_loss: 32923123712.0000\n",
      "Epoch 504/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 28324947968.0000 - val_loss: 35118014464.0000\n",
      "Epoch 505/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 27889565696.0000 - val_loss: 31441436672.0000\n",
      "Epoch 506/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 28660031488.0000 - val_loss: 35188420608.0000\n",
      "Epoch 507/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 28173783040.0000 - val_loss: 33617686528.0000\n",
      "Epoch 508/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 27095468032.0000 - val_loss: 32125755392.0000\n",
      "Epoch 509/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 27807694848.0000 - val_loss: 31686952960.0000\n",
      "Epoch 510/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 28507191296.0000 - val_loss: 34426937344.0000\n",
      "Epoch 511/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 27562330112.0000 - val_loss: 30968985600.0000\n",
      "Epoch 512/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 27744837632.0000 - val_loss: 32126787584.0000\n",
      "Epoch 513/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 27918845952.0000 - val_loss: 35911127040.0000\n",
      "Epoch 514/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 29125978112.0000 - val_loss: 33772509184.0000\n",
      "Epoch 515/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 28418394112.0000 - val_loss: 29860231168.0000\n",
      "Epoch 516/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 25565487104.0000 - val_loss: 28010874880.0000\n",
      "Epoch 517/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - loss: 26529028096.0000 - val_loss: 32223842304.0000\n",
      "Epoch 518/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 25623877632.0000 - val_loss: 34903961600.0000\n",
      "Epoch 519/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 26892369920.0000 - val_loss: 32734074880.0000\n",
      "Epoch 520/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 33487609856.0000 - val_loss: 36476211200.0000\n",
      "Epoch 521/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 28553129984.0000 - val_loss: 34757693440.0000\n",
      "Epoch 522/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - loss: 27436814336.0000 - val_loss: 32834308096.0000\n",
      "Epoch 523/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 27353346048.0000 - val_loss: 29811662848.0000\n",
      "Epoch 524/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 26662461440.0000 - val_loss: 30104582144.0000\n",
      "Epoch 525/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 27752220672.0000 - val_loss: 31591114752.0000\n",
      "Epoch 526/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 27142561792.0000 - val_loss: 31113750528.0000\n",
      "Epoch 527/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 26008684544.0000 - val_loss: 31398725632.0000\n",
      "Epoch 528/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 27058610176.0000 - val_loss: 32717406208.0000\n",
      "Epoch 529/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 27191123968.0000 - val_loss: 33139748864.0000\n",
      "Epoch 530/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: 27964143616.0000 - val_loss: 33184948224.0000\n",
      "Epoch 531/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 28998320128.0000 - val_loss: 34583670784.0000\n",
      "Epoch 532/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 25852071936.0000 - val_loss: 34075285504.0000\n",
      "Epoch 533/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 30012635136.0000 - val_loss: 29844303872.0000\n",
      "Epoch 534/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 26888738816.0000 - val_loss: 34444500992.0000\n",
      "Epoch 535/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 26413148160.0000 - val_loss: 30193899520.0000\n",
      "Epoch 536/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 457us/step - loss: 25484427264.0000 - val_loss: 38012026880.0000\n",
      "Epoch 537/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 27421595648.0000 - val_loss: 30692548608.0000\n",
      "Epoch 538/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 29520691200.0000 - val_loss: 30620592128.0000\n",
      "Epoch 539/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 27010123776.0000 - val_loss: 34113992704.0000\n",
      "Epoch 540/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - loss: 26167662592.0000 - val_loss: 33697460224.0000\n",
      "Epoch 541/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 28099573760.0000 - val_loss: 29110810624.0000\n",
      "Epoch 542/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 27155535872.0000 - val_loss: 32126590976.0000\n",
      "Epoch 543/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 28926709760.0000 - val_loss: 33978083328.0000\n",
      "Epoch 544/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 25590382592.0000 - val_loss: 33171935232.0000\n",
      "Epoch 545/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 25298622464.0000 - val_loss: 33775091712.0000\n",
      "Epoch 546/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 26806517760.0000 - val_loss: 34475880448.0000\n",
      "Epoch 547/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 27124846592.0000 - val_loss: 30552979456.0000\n",
      "Epoch 548/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 25767933952.0000 - val_loss: 34528792576.0000\n",
      "Epoch 549/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 24797290496.0000 - val_loss: 30315898880.0000\n",
      "Epoch 550/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 25287823360.0000 - val_loss: 32059308032.0000\n",
      "Epoch 551/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 25925165056.0000 - val_loss: 35912265728.0000\n",
      "Epoch 552/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 25039947776.0000 - val_loss: 33127772160.0000\n",
      "Epoch 553/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 27179210752.0000 - val_loss: 30671228928.0000\n",
      "Epoch 554/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - loss: 26428366848.0000 - val_loss: 32846399488.0000\n",
      "Epoch 555/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 26234075136.0000 - val_loss: 33950910464.0000\n",
      "Epoch 556/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 24124186624.0000 - val_loss: 33462724608.0000\n",
      "Epoch 557/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 26839447552.0000 - val_loss: 35994320896.0000\n",
      "Epoch 558/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 433us/step - loss: 24304007168.0000 - val_loss: 31447072768.0000\n",
      "Epoch 559/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 27101108224.0000 - val_loss: 33002862592.0000\n",
      "Epoch 560/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 24978884608.0000 - val_loss: 30215241728.0000\n",
      "Epoch 561/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 25803407360.0000 - val_loss: 35310100480.0000\n",
      "Epoch 562/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 24726818816.0000 - val_loss: 33493452800.0000\n",
      "Epoch 563/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 26478149632.0000 - val_loss: 30965291008.0000\n",
      "Epoch 564/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 26208249856.0000 - val_loss: 33442617344.0000\n",
      "Epoch 565/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 25705125888.0000 - val_loss: 32324878336.0000\n",
      "Epoch 566/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 27471960064.0000 - val_loss: 31447083008.0000\n",
      "Epoch 567/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 25475078144.0000 - val_loss: 39254405120.0000\n",
      "Epoch 568/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 23736285184.0000 - val_loss: 37608697856.0000\n",
      "Epoch 569/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 26548770816.0000 - val_loss: 31356323840.0000\n",
      "Epoch 570/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: 25276829696.0000 - val_loss: 32654807040.0000\n",
      "Epoch 571/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - loss: 28454242304.0000 - val_loss: 32274538496.0000\n",
      "Epoch 572/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - loss: 25344108544.0000 - val_loss: 34883444736.0000\n",
      "Epoch 573/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 398us/step - loss: 25415223296.0000 - val_loss: 33963599872.0000\n",
      "Epoch 574/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - loss: 27239550976.0000 - val_loss: 32517869568.0000\n",
      "Epoch 575/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - loss: 26208911360.0000 - val_loss: 32293283840.0000\n",
      "Epoch 576/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 25553000448.0000 - val_loss: 36117057536.0000\n",
      "Epoch 577/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - loss: 27553771520.0000 - val_loss: 31031994368.0000\n",
      "Epoch 578/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - loss: 27575347200.0000 - val_loss: 32996745216.0000\n",
      "Epoch 579/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - loss: 25733601280.0000 - val_loss: 34893594624.0000\n",
      "Epoch 580/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 25138876416.0000 - val_loss: 30668828672.0000\n",
      "Epoch 581/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 24830042112.0000 - val_loss: 32312723456.0000\n",
      "Epoch 582/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 23147407360.0000 - val_loss: 35453661184.0000\n",
      "Epoch 583/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 25710155776.0000 - val_loss: 35314868224.0000\n",
      "Epoch 584/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 26962479104.0000 - val_loss: 36202061824.0000\n",
      "Epoch 585/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - loss: 27170664448.0000 - val_loss: 32956071936.0000\n",
      "Epoch 586/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 25642721280.0000 - val_loss: 31022249984.0000\n",
      "Epoch 587/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 26113685504.0000 - val_loss: 37647761408.0000\n",
      "Epoch 588/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - loss: 27294664704.0000 - val_loss: 35000430592.0000\n",
      "Epoch 589/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - loss: 28227059712.0000 - val_loss: 34722963456.0000\n",
      "Epoch 590/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 24166686720.0000 - val_loss: 30466756608.0000\n",
      "Epoch 591/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - loss: 23449755648.0000 - val_loss: 29677723648.0000\n",
      "Epoch 592/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 25635387392.0000 - val_loss: 31705305088.0000\n",
      "Epoch 593/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 23946149888.0000 - val_loss: 29528315904.0000\n",
      "Epoch 594/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 26014267392.0000 - val_loss: 33087461376.0000\n",
      "Epoch 595/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 27264757760.0000 - val_loss: 34927083520.0000\n",
      "Epoch 596/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 26617464832.0000 - val_loss: 31569477632.0000\n",
      "Epoch 597/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 24478146560.0000 - val_loss: 33270310912.0000\n",
      "Epoch 598/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 26041276416.0000 - val_loss: 37050380288.0000\n",
      "Epoch 599/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 27726802944.0000 - val_loss: 31038253056.0000\n",
      "Epoch 600/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - loss: 25709084672.0000 - val_loss: 33743519744.0000\n",
      "Epoch 601/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 28855095296.0000 - val_loss: 33485021184.0000\n",
      "Epoch 602/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 24899250176.0000 - val_loss: 36208205824.0000\n",
      "Epoch 603/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - loss: 25523738624.0000 - val_loss: 33904877568.0000\n",
      "Epoch 604/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 25067927552.0000 - val_loss: 33577646080.0000\n",
      "Epoch 605/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 26125113344.0000 - val_loss: 35349721088.0000\n",
      "Epoch 606/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 26468542464.0000 - val_loss: 30288160768.0000\n",
      "Epoch 607/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 25557837824.0000 - val_loss: 31962630144.0000\n",
      "Epoch 608/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 24836546560.0000 - val_loss: 31724214272.0000\n",
      "Epoch 609/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 25927561216.0000 - val_loss: 31958181888.0000\n",
      "Epoch 610/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 27932620800.0000 - val_loss: 34027552768.0000\n",
      "Epoch 611/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 26153705472.0000 - val_loss: 35097538560.0000\n",
      "Epoch 612/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 27019558912.0000 - val_loss: 33667295232.0000\n",
      "Epoch 613/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 26469003264.0000 - val_loss: 38565912576.0000\n",
      "Epoch 614/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 24819910656.0000 - val_loss: 34341697536.0000\n",
      "Epoch 615/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 24275232768.0000 - val_loss: 34566332416.0000\n",
      "Epoch 616/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 25067067392.0000 - val_loss: 30922940416.0000\n",
      "Epoch 617/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 27149971456.0000 - val_loss: 37319385088.0000\n",
      "Epoch 618/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 28235378688.0000 - val_loss: 32144982016.0000\n",
      "Epoch 619/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 23636609024.0000 - val_loss: 32489615360.0000\n",
      "Epoch 620/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 24745119744.0000 - val_loss: 32621981696.0000\n",
      "Epoch 621/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 24264433664.0000 - val_loss: 33747933184.0000\n",
      "Epoch 622/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 25961836544.0000 - val_loss: 34818064384.0000\n",
      "Epoch 623/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 25275154432.0000 - val_loss: 31577098240.0000\n",
      "Epoch 624/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 26002702336.0000 - val_loss: 34186641408.0000\n",
      "Epoch 625/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 25172719616.0000 - val_loss: 35842699264.0000\n",
      "Epoch 626/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 25893910528.0000 - val_loss: 30753945600.0000\n",
      "Epoch 627/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - loss: 26800246784.0000 - val_loss: 30546612224.0000\n",
      "Epoch 628/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 26389798912.0000 - val_loss: 34539810816.0000\n",
      "Epoch 629/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 25253136384.0000 - val_loss: 32689033216.0000\n",
      "Epoch 630/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 22944989184.0000 - val_loss: 31297402880.0000\n",
      "Epoch 631/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 25042067456.0000 - val_loss: 34880745472.0000\n",
      "Epoch 632/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 23616907264.0000 - val_loss: 34494431232.0000\n",
      "Epoch 633/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 25181003776.0000 - val_loss: 35429859328.0000\n",
      "Epoch 634/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 24898891776.0000 - val_loss: 36500217856.0000\n",
      "Epoch 635/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 23428022272.0000 - val_loss: 30262579200.0000\n",
      "Epoch 636/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 24198662144.0000 - val_loss: 31210434560.0000\n",
      "Epoch 637/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 25803864064.0000 - val_loss: 30611935232.0000\n",
      "Epoch 638/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 26507298816.0000 - val_loss: 38209654784.0000\n",
      "Epoch 639/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 24070488064.0000 - val_loss: 31711522816.0000\n",
      "Epoch 640/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 25620228096.0000 - val_loss: 34043109376.0000\n",
      "Epoch 641/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 25433847808.0000 - val_loss: 35782492160.0000\n",
      "Epoch 642/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 24480411648.0000 - val_loss: 31536582656.0000\n",
      "Epoch 643/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - loss: 24038680576.0000 - val_loss: 33024921600.0000\n",
      "Epoch 644/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 26080217088.0000 - val_loss: 29540755456.0000\n",
      "Epoch 645/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 24656500736.0000 - val_loss: 31655176192.0000\n",
      "Epoch 646/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 26438975488.0000 - val_loss: 32120391680.0000\n",
      "Epoch 647/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 24090130432.0000 - val_loss: 35492085760.0000\n",
      "Epoch 648/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 26954240000.0000 - val_loss: 32296321024.0000\n",
      "Epoch 649/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - loss: 23494404096.0000 - val_loss: 28547870720.0000\n",
      "Epoch 650/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 25561071616.0000 - val_loss: 31464718336.0000\n",
      "Epoch 651/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 26646790144.0000 - val_loss: 31845519360.0000\n",
      "Epoch 652/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 23098583040.0000 - val_loss: 30364833792.0000\n",
      "Epoch 653/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 25390213120.0000 - val_loss: 34295152640.0000\n",
      "Epoch 654/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 26702600192.0000 - val_loss: 31006308352.0000\n",
      "Epoch 655/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 24336306176.0000 - val_loss: 31425519616.0000\n",
      "Epoch 656/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 24714528768.0000 - val_loss: 36473307136.0000\n",
      "Epoch 657/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 23275114496.0000 - val_loss: 31845070848.0000\n",
      "Epoch 658/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 24756004864.0000 - val_loss: 33665677312.0000\n",
      "Epoch 659/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 26652057600.0000 - val_loss: 33492983808.0000\n",
      "Epoch 660/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 24967456768.0000 - val_loss: 35537674240.0000\n",
      "Epoch 661/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - loss: 25038800896.0000 - val_loss: 33892636672.0000\n",
      "Epoch 662/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 26242187264.0000 - val_loss: 35928801280.0000\n",
      "Epoch 663/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 25330036736.0000 - val_loss: 30442729472.0000\n",
      "Epoch 664/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 25715810304.0000 - val_loss: 34553614336.0000\n",
      "Epoch 665/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 27054923776.0000 - val_loss: 36103729152.0000\n",
      "Epoch 666/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 24084385792.0000 - val_loss: 35724374016.0000\n",
      "Epoch 667/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 26268665856.0000 - val_loss: 35195256832.0000\n",
      "Epoch 668/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 24794290176.0000 - val_loss: 38351114240.0000\n",
      "Epoch 669/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 25039153152.0000 - val_loss: 39499771904.0000\n",
      "Epoch 670/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 24703193088.0000 - val_loss: 32527142912.0000\n",
      "Epoch 671/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 24011644928.0000 - val_loss: 33509435392.0000\n",
      "Epoch 672/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 23941867520.0000 - val_loss: 32718626816.0000\n",
      "Epoch 673/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 24675698688.0000 - val_loss: 33637609472.0000\n",
      "Epoch 674/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 27015622656.0000 - val_loss: 37691604992.0000\n",
      "Epoch 675/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 25830356992.0000 - val_loss: 32204394496.0000\n",
      "Epoch 676/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 25165649920.0000 - val_loss: 31143913472.0000\n",
      "Epoch 677/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 25398085632.0000 - val_loss: 36983521280.0000\n",
      "Epoch 678/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 28659130368.0000 - val_loss: 35323711488.0000\n",
      "Epoch 679/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 22634964992.0000 - val_loss: 35355181056.0000\n",
      "Epoch 680/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 22955765760.0000 - val_loss: 33219837952.0000\n",
      "Epoch 681/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 25050896384.0000 - val_loss: 40689274880.0000\n",
      "Epoch 682/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 24632705024.0000 - val_loss: 35686023168.0000\n",
      "Epoch 683/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 25268465664.0000 - val_loss: 34084071424.0000\n",
      "Epoch 684/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 24279570432.0000 - val_loss: 33477916672.0000\n",
      "Epoch 685/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - loss: 25251700736.0000 - val_loss: 34258219008.0000\n",
      "Epoch 686/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 24258441216.0000 - val_loss: 32295741440.0000\n",
      "Epoch 687/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 26445899776.0000 - val_loss: 35982925824.0000\n",
      "Epoch 688/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 25563576320.0000 - val_loss: 42066993152.0000\n",
      "Epoch 689/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 23417518080.0000 - val_loss: 32402792448.0000\n",
      "Epoch 690/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 26565787648.0000 - val_loss: 34284654592.0000\n",
      "Epoch 691/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 26256236544.0000 - val_loss: 38450151424.0000\n",
      "Epoch 692/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 23170277376.0000 - val_loss: 31162812416.0000\n",
      "Epoch 693/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 25290659840.0000 - val_loss: 34431553536.0000\n",
      "Epoch 694/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 23306002432.0000 - val_loss: 30421899264.0000\n",
      "Epoch 695/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 23935133696.0000 - val_loss: 34714632192.0000\n",
      "Epoch 696/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 24561491968.0000 - val_loss: 37128454144.0000\n",
      "Epoch 697/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 25362364416.0000 - val_loss: 34828247040.0000\n",
      "Epoch 698/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 24372334592.0000 - val_loss: 31916029952.0000\n",
      "Epoch 699/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 25405716480.0000 - val_loss: 36039733248.0000\n",
      "Epoch 700/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 25136461824.0000 - val_loss: 37240770560.0000\n",
      "Epoch 701/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 23066279936.0000 - val_loss: 33821747200.0000\n",
      "Epoch 702/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 24386248704.0000 - val_loss: 36364464128.0000\n",
      "Epoch 703/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 25569691648.0000 - val_loss: 33385889792.0000\n",
      "Epoch 704/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 24833714176.0000 - val_loss: 34511466496.0000\n",
      "Epoch 705/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 27035142144.0000 - val_loss: 33085626368.0000\n",
      "Epoch 706/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 22672947200.0000 - val_loss: 33914939392.0000\n",
      "Epoch 707/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 24027219968.0000 - val_loss: 32613922816.0000\n",
      "Epoch 708/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 25650395136.0000 - val_loss: 43133050880.0000\n",
      "Epoch 709/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 25877219328.0000 - val_loss: 39783600128.0000\n",
      "Epoch 710/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 24739362816.0000 - val_loss: 33045889024.0000\n",
      "Epoch 711/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 25845786624.0000 - val_loss: 41237872640.0000\n",
      "Epoch 712/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 24219623424.0000 - val_loss: 34906238976.0000\n",
      "Epoch 713/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 23555913728.0000 - val_loss: 35945046016.0000\n",
      "Epoch 714/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 22672424960.0000 - val_loss: 33920030720.0000\n",
      "Epoch 715/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 25202794496.0000 - val_loss: 34571051008.0000\n",
      "Epoch 716/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 24274933760.0000 - val_loss: 39134109696.0000\n",
      "Epoch 717/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 23803426816.0000 - val_loss: 32533051392.0000\n",
      "Epoch 718/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 23324739584.0000 - val_loss: 33127043072.0000\n",
      "Epoch 719/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 445us/step - loss: 24391487488.0000 - val_loss: 33534973952.0000\n",
      "Epoch 720/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 24705089536.0000 - val_loss: 35769573376.0000\n",
      "Epoch 721/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 26802378752.0000 - val_loss: 34781204480.0000\n",
      "Epoch 722/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 24767559680.0000 - val_loss: 31372212224.0000\n",
      "Epoch 723/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 25676333056.0000 - val_loss: 33962700800.0000\n",
      "Epoch 724/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 25872017408.0000 - val_loss: 33988528128.0000\n",
      "Epoch 725/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 26532829184.0000 - val_loss: 29920108544.0000\n",
      "Epoch 726/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 23243370496.0000 - val_loss: 35491667968.0000\n",
      "Epoch 727/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 26952554496.0000 - val_loss: 38628208640.0000\n",
      "Epoch 728/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 22001563648.0000 - val_loss: 37802070016.0000\n",
      "Epoch 729/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 23021776896.0000 - val_loss: 34794598400.0000\n",
      "Epoch 730/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 23822161920.0000 - val_loss: 33108944896.0000\n",
      "Epoch 731/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 23568541696.0000 - val_loss: 39123709952.0000\n",
      "Epoch 732/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 27255965696.0000 - val_loss: 33910142976.0000\n",
      "Epoch 733/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 24421875712.0000 - val_loss: 44682850304.0000\n",
      "Epoch 734/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 25033480192.0000 - val_loss: 36340228096.0000\n",
      "Epoch 735/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 26145525760.0000 - val_loss: 32178716672.0000\n",
      "Epoch 736/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 24530333696.0000 - val_loss: 38016212992.0000\n",
      "Epoch 737/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 24578041856.0000 - val_loss: 37883244544.0000\n",
      "Epoch 738/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 24012785664.0000 - val_loss: 33574443008.0000\n",
      "Epoch 739/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 24099862528.0000 - val_loss: 36432297984.0000\n",
      "Epoch 740/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 26783475712.0000 - val_loss: 35924779008.0000\n",
      "Epoch 741/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 23576111104.0000 - val_loss: 42850627584.0000\n",
      "Epoch 742/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 23493140480.0000 - val_loss: 35849207808.0000\n",
      "Epoch 743/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 24342505472.0000 - val_loss: 37809033216.0000\n",
      "Epoch 744/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 24942653440.0000 - val_loss: 32721856512.0000\n",
      "Epoch 745/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 24687980544.0000 - val_loss: 33588320256.0000\n",
      "Epoch 746/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 25352876032.0000 - val_loss: 32946579456.0000\n",
      "Epoch 747/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 21667516416.0000 - val_loss: 36417241088.0000\n",
      "Epoch 748/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 25446807552.0000 - val_loss: 33085095936.0000\n",
      "Epoch 749/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 24276920320.0000 - val_loss: 40305762304.0000\n",
      "Epoch 750/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 22727071744.0000 - val_loss: 37341036544.0000\n",
      "Epoch 751/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 23109736448.0000 - val_loss: 34604916736.0000\n",
      "Epoch 752/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 23953651712.0000 - val_loss: 32725454848.0000\n",
      "Epoch 753/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 23871819776.0000 - val_loss: 35187449856.0000\n",
      "Epoch 754/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 23137167360.0000 - val_loss: 35693617152.0000\n",
      "Epoch 755/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 24742268928.0000 - val_loss: 40479813632.0000\n",
      "Epoch 756/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 22758957056.0000 - val_loss: 34539794432.0000\n",
      "Epoch 757/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 23353948160.0000 - val_loss: 34993225728.0000\n",
      "Epoch 758/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 24217872384.0000 - val_loss: 34672054272.0000\n",
      "Epoch 759/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 395us/step - loss: 24131237888.0000 - val_loss: 34575233024.0000\n",
      "Epoch 760/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - loss: 23146743808.0000 - val_loss: 36350541824.0000\n",
      "Epoch 761/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 25773146112.0000 - val_loss: 34420015104.0000\n",
      "Epoch 762/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 26462111744.0000 - val_loss: 37072916480.0000\n",
      "Epoch 763/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 25098565632.0000 - val_loss: 38357135360.0000\n",
      "Epoch 764/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 23409270784.0000 - val_loss: 33735553024.0000\n",
      "Epoch 765/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 22769518592.0000 - val_loss: 36831199232.0000\n",
      "Epoch 766/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - loss: 23563581440.0000 - val_loss: 40291983360.0000\n",
      "Epoch 767/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 25314983936.0000 - val_loss: 37662523392.0000\n",
      "Epoch 768/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 24284098560.0000 - val_loss: 36372717568.0000\n",
      "Epoch 769/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 25550647296.0000 - val_loss: 36379992064.0000\n",
      "Epoch 770/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 25616912384.0000 - val_loss: 34999578624.0000\n",
      "Epoch 771/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - loss: 24574201856.0000 - val_loss: 33565353984.0000\n",
      "Epoch 772/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434us/step - loss: 21331429376.0000 - val_loss: 34170746880.0000\n",
      "Epoch 773/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 24053862400.0000 - val_loss: 39192141824.0000\n",
      "Epoch 774/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 23914909696.0000 - val_loss: 34686029824.0000\n",
      "Epoch 775/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 22555052032.0000 - val_loss: 37012164608.0000\n",
      "Epoch 776/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 24851296256.0000 - val_loss: 37118001152.0000\n",
      "Epoch 777/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 26992334848.0000 - val_loss: 33496899584.0000\n",
      "Epoch 778/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 25152313344.0000 - val_loss: 38077784064.0000\n",
      "Epoch 779/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 24342384640.0000 - val_loss: 39971311616.0000\n",
      "Epoch 780/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 25167142912.0000 - val_loss: 38246649856.0000\n",
      "Epoch 781/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 25222596608.0000 - val_loss: 34800869376.0000\n",
      "Epoch 782/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 23235917824.0000 - val_loss: 34903515136.0000\n",
      "Epoch 783/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 22866771968.0000 - val_loss: 40100159488.0000\n",
      "Epoch 784/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 25046980608.0000 - val_loss: 35692142592.0000\n",
      "Epoch 785/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 24034910208.0000 - val_loss: 37135732736.0000\n",
      "Epoch 786/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 25565696000.0000 - val_loss: 34345084928.0000\n",
      "Epoch 787/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 27007356928.0000 - val_loss: 32126588928.0000\n",
      "Epoch 788/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 23927758848.0000 - val_loss: 34065373184.0000\n",
      "Epoch 789/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 23510220800.0000 - val_loss: 34143959040.0000\n",
      "Epoch 790/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 24156520448.0000 - val_loss: 37166325760.0000\n",
      "Epoch 791/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 24499832832.0000 - val_loss: 32805449728.0000\n",
      "Epoch 792/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 23467440128.0000 - val_loss: 37143924736.0000\n",
      "Epoch 793/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 23101806592.0000 - val_loss: 34549792768.0000\n",
      "Epoch 794/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 23225866240.0000 - val_loss: 34408402944.0000\n",
      "Epoch 795/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 24497985536.0000 - val_loss: 35375386624.0000\n",
      "Epoch 796/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - loss: 23035373568.0000 - val_loss: 35383005184.0000\n",
      "Epoch 797/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 27196606464.0000 - val_loss: 33762938880.0000\n",
      "Epoch 798/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 25983797248.0000 - val_loss: 34108530688.0000\n",
      "Epoch 799/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 27145959424.0000 - val_loss: 35437150208.0000\n",
      "Epoch 800/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 22367238144.0000 - val_loss: 34407137280.0000\n",
      "Epoch 801/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 24783484928.0000 - val_loss: 39402999808.0000\n",
      "Epoch 802/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 23454777344.0000 - val_loss: 37129175040.0000\n",
      "Epoch 803/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 24048437248.0000 - val_loss: 32882104320.0000\n",
      "Epoch 804/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 25434490880.0000 - val_loss: 34687619072.0000\n",
      "Epoch 805/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 25041287168.0000 - val_loss: 33059620864.0000\n",
      "Epoch 806/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 24654780416.0000 - val_loss: 37857816576.0000\n",
      "Epoch 807/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 24437901312.0000 - val_loss: 35861659648.0000\n",
      "Epoch 808/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 24441720832.0000 - val_loss: 40700186624.0000\n",
      "Epoch 809/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 22785511424.0000 - val_loss: 35439288320.0000\n",
      "Epoch 810/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 23783577600.0000 - val_loss: 33559283712.0000\n",
      "Epoch 811/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 23791067136.0000 - val_loss: 34784616448.0000\n",
      "Epoch 812/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 23479326720.0000 - val_loss: 34321661952.0000\n",
      "Epoch 813/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 23662266368.0000 - val_loss: 36864360448.0000\n",
      "Epoch 814/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 23627808768.0000 - val_loss: 38796328960.0000\n",
      "Epoch 815/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 26666655744.0000 - val_loss: 34424651776.0000\n",
      "Epoch 816/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 23922726912.0000 - val_loss: 35544551424.0000\n",
      "Epoch 817/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 22555611136.0000 - val_loss: 31791155200.0000\n",
      "Epoch 818/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 23663235072.0000 - val_loss: 38367784960.0000\n",
      "Epoch 819/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 22382618624.0000 - val_loss: 33853003776.0000\n",
      "Epoch 820/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 24351528960.0000 - val_loss: 37343182848.0000\n",
      "Epoch 821/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 24238862336.0000 - val_loss: 35862654976.0000\n",
      "Epoch 822/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 23612411904.0000 - val_loss: 36658597888.0000\n",
      "Epoch 823/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 24839696384.0000 - val_loss: 40816279552.0000\n",
      "Epoch 824/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 24638490624.0000 - val_loss: 37647323136.0000\n",
      "Epoch 825/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 26004994048.0000 - val_loss: 35665661952.0000\n",
      "Epoch 826/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 22537250816.0000 - val_loss: 35587833856.0000\n",
      "Epoch 827/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 24448860160.0000 - val_loss: 37947052032.0000\n",
      "Epoch 828/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 23142948864.0000 - val_loss: 44812980224.0000\n",
      "Epoch 829/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 24938502144.0000 - val_loss: 36770684928.0000\n",
      "Epoch 830/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 22236835840.0000 - val_loss: 36931448832.0000\n",
      "Epoch 831/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 24034541568.0000 - val_loss: 36698259456.0000\n",
      "Epoch 832/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 23167244288.0000 - val_loss: 35425296384.0000\n",
      "Epoch 833/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 22786127872.0000 - val_loss: 34342928384.0000\n",
      "Epoch 834/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 23908153344.0000 - val_loss: 32347738112.0000\n",
      "Epoch 835/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 25150742528.0000 - val_loss: 34040201216.0000\n",
      "Epoch 836/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 443us/step - loss: 22441699328.0000 - val_loss: 36780830720.0000\n",
      "Epoch 837/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 22710992896.0000 - val_loss: 36602986496.0000\n",
      "Epoch 838/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 22313326592.0000 - val_loss: 33090093056.0000\n",
      "Epoch 839/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 23867723776.0000 - val_loss: 39072993280.0000\n",
      "Epoch 840/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 24475279360.0000 - val_loss: 36275953664.0000\n",
      "Epoch 841/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 24711667712.0000 - val_loss: 41044365312.0000\n",
      "Epoch 842/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 23240556544.0000 - val_loss: 34143541248.0000\n",
      "Epoch 843/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 23808864256.0000 - val_loss: 36079640576.0000\n",
      "Epoch 844/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 26044897280.0000 - val_loss: 36030267392.0000\n",
      "Epoch 845/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 24000995328.0000 - val_loss: 39244476416.0000\n",
      "Epoch 846/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 24307554304.0000 - val_loss: 37789687808.0000\n",
      "Epoch 847/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 22785353728.0000 - val_loss: 37311647744.0000\n",
      "Epoch 848/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 24061949952.0000 - val_loss: 36297318400.0000\n",
      "Epoch 849/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 24698677248.0000 - val_loss: 36428972032.0000\n",
      "Epoch 850/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 22683277312.0000 - val_loss: 31653496832.0000\n",
      "Epoch 851/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 23969058816.0000 - val_loss: 40457732096.0000\n",
      "Epoch 852/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 22835228672.0000 - val_loss: 35857235968.0000\n",
      "Epoch 853/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 23582752768.0000 - val_loss: 38529863680.0000\n",
      "Epoch 854/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 25664741376.0000 - val_loss: 36971782144.0000\n",
      "Epoch 855/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 24204138496.0000 - val_loss: 37715922944.0000\n",
      "Epoch 856/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 26500206592.0000 - val_loss: 34136565760.0000\n",
      "Epoch 857/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 25042006016.0000 - val_loss: 39216893952.0000\n",
      "Epoch 858/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 22291861504.0000 - val_loss: 36296146944.0000\n",
      "Epoch 859/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 23752329216.0000 - val_loss: 41971998720.0000\n",
      "Epoch 860/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 22089781248.0000 - val_loss: 33553436672.0000\n",
      "Epoch 861/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 25725534208.0000 - val_loss: 34938613760.0000\n",
      "Epoch 862/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 23973478400.0000 - val_loss: 36665491456.0000\n",
      "Epoch 863/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 22754324480.0000 - val_loss: 39320203264.0000\n",
      "Epoch 864/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 23858878464.0000 - val_loss: 36551077888.0000\n",
      "Epoch 865/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 23872139264.0000 - val_loss: 35976388608.0000\n",
      "Epoch 866/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 23386433536.0000 - val_loss: 36653322240.0000\n",
      "Epoch 867/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 23881736192.0000 - val_loss: 45784289280.0000\n",
      "Epoch 868/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 23880699904.0000 - val_loss: 38478356480.0000\n",
      "Epoch 869/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 24887597056.0000 - val_loss: 39045033984.0000\n",
      "Epoch 870/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - loss: 24088854528.0000 - val_loss: 45969174528.0000\n",
      "Epoch 871/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 21949562880.0000 - val_loss: 39074779136.0000\n",
      "Epoch 872/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - loss: 23612086272.0000 - val_loss: 33840687104.0000\n",
      "Epoch 873/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 21794363392.0000 - val_loss: 34698145792.0000\n",
      "Epoch 874/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 23409045504.0000 - val_loss: 36636237824.0000\n",
      "Epoch 875/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 24060794880.0000 - val_loss: 33921239040.0000\n",
      "Epoch 876/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 24156151808.0000 - val_loss: 41600860160.0000\n",
      "Epoch 877/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 21715097600.0000 - val_loss: 40128323584.0000\n",
      "Epoch 878/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 23759054848.0000 - val_loss: 38817681408.0000\n",
      "Epoch 879/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 23402688512.0000 - val_loss: 38240661504.0000\n",
      "Epoch 880/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 23602976768.0000 - val_loss: 38102360064.0000\n",
      "Epoch 881/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 22099501056.0000 - val_loss: 36781625344.0000\n",
      "Epoch 882/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 22848178176.0000 - val_loss: 34286512128.0000\n",
      "Epoch 883/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 23971416064.0000 - val_loss: 36194361344.0000\n",
      "Epoch 884/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - loss: 22862567424.0000 - val_loss: 37320876032.0000\n",
      "Epoch 885/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 22458415104.0000 - val_loss: 36120498176.0000\n",
      "Epoch 886/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 24744400896.0000 - val_loss: 44743122944.0000\n",
      "Epoch 887/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 24801400832.0000 - val_loss: 42117476352.0000\n",
      "Epoch 888/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 21989249024.0000 - val_loss: 39007965184.0000\n",
      "Epoch 889/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 24201220096.0000 - val_loss: 33145802752.0000\n",
      "Epoch 890/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 21997967360.0000 - val_loss: 33957947392.0000\n",
      "Epoch 891/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 23038947328.0000 - val_loss: 39840358400.0000\n",
      "Epoch 892/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 24210106368.0000 - val_loss: 40543293440.0000\n",
      "Epoch 893/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 22909368320.0000 - val_loss: 34705108992.0000\n",
      "Epoch 894/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 20888231936.0000 - val_loss: 34583793664.0000\n",
      "Epoch 895/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 23464841216.0000 - val_loss: 38884761600.0000\n",
      "Epoch 896/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 22219126784.0000 - val_loss: 40961253376.0000\n",
      "Epoch 897/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 22971013120.0000 - val_loss: 37495971840.0000\n",
      "Epoch 898/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 23152596992.0000 - val_loss: 37149483008.0000\n",
      "Epoch 899/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 24488683520.0000 - val_loss: 39071608832.0000\n",
      "Epoch 900/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 22791387136.0000 - val_loss: 38975414272.0000\n",
      "Epoch 901/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 22691792896.0000 - val_loss: 35493093376.0000\n",
      "Epoch 902/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 26567655424.0000 - val_loss: 37470355456.0000\n",
      "Epoch 903/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 23373768704.0000 - val_loss: 33828306944.0000\n",
      "Epoch 904/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: 23184162816.0000 - val_loss: 41731080192.0000\n",
      "Epoch 905/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 24940349440.0000 - val_loss: 34725560320.0000\n",
      "Epoch 906/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 21899497472.0000 - val_loss: 39766917120.0000\n",
      "Epoch 907/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451us/step - loss: 23748556800.0000 - val_loss: 42761453568.0000\n",
      "Epoch 908/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 25420787712.0000 - val_loss: 40315912192.0000\n",
      "Epoch 909/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - loss: 24241643520.0000 - val_loss: 40540557312.0000\n",
      "Epoch 910/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 573us/step - loss: 22852007936.0000 - val_loss: 35419185152.0000\n",
      "Epoch 911/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - loss: 22194065408.0000 - val_loss: 38437863424.0000\n",
      "Epoch 912/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step - loss: 21675522048.0000 - val_loss: 41199476736.0000\n",
      "Epoch 913/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 23114536960.0000 - val_loss: 41916690432.0000\n",
      "Epoch 914/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 22415908864.0000 - val_loss: 38093864960.0000\n",
      "Epoch 915/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 22836613120.0000 - val_loss: 42097803264.0000\n",
      "Epoch 916/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 23407017984.0000 - val_loss: 35061624832.0000\n",
      "Epoch 917/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 21973753856.0000 - val_loss: 38882754560.0000\n",
      "Epoch 918/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 24493260800.0000 - val_loss: 39742439424.0000\n",
      "Epoch 919/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 22875383808.0000 - val_loss: 43089108992.0000\n",
      "Epoch 920/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 25578274816.0000 - val_loss: 40526643200.0000\n",
      "Epoch 921/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 22827704320.0000 - val_loss: 36154138624.0000\n",
      "Epoch 922/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - loss: 23192983552.0000 - val_loss: 41144238080.0000\n",
      "Epoch 923/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 450us/step - loss: 23790530560.0000 - val_loss: 40182566912.0000\n",
      "Epoch 924/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - loss: 24537206784.0000 - val_loss: 40109326336.0000\n",
      "Epoch 925/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 24286781440.0000 - val_loss: 36335321088.0000\n",
      "Epoch 926/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 22348738560.0000 - val_loss: 42154053632.0000\n",
      "Epoch 927/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 23924008960.0000 - val_loss: 41970614272.0000\n",
      "Epoch 928/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 24625276928.0000 - val_loss: 38336974848.0000\n",
      "Epoch 929/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 23080976384.0000 - val_loss: 40390643712.0000\n",
      "Epoch 930/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - loss: 23395485696.0000 - val_loss: 40075501568.0000\n",
      "Epoch 931/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 23640647680.0000 - val_loss: 36743716864.0000\n",
      "Epoch 932/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387us/step - loss: 22019850240.0000 - val_loss: 41387380736.0000\n",
      "Epoch 933/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 22312740864.0000 - val_loss: 36244889600.0000\n",
      "Epoch 934/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 22512783360.0000 - val_loss: 33491488768.0000\n",
      "Epoch 935/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 25239220224.0000 - val_loss: 36284411904.0000\n",
      "Epoch 936/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 22571868160.0000 - val_loss: 38156718080.0000\n",
      "Epoch 937/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 21898805248.0000 - val_loss: 39582302208.0000\n",
      "Epoch 938/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 23379685376.0000 - val_loss: 33936160768.0000\n",
      "Epoch 939/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 24235120640.0000 - val_loss: 37774921728.0000\n",
      "Epoch 940/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 22429104128.0000 - val_loss: 36880646144.0000\n",
      "Epoch 941/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 22684880896.0000 - val_loss: 37135171584.0000\n",
      "Epoch 942/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 24823687168.0000 - val_loss: 34764320768.0000\n",
      "Epoch 943/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 22471538688.0000 - val_loss: 40782598144.0000\n",
      "Epoch 944/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 23251701760.0000 - val_loss: 37629464576.0000\n",
      "Epoch 945/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 23197970432.0000 - val_loss: 36266442752.0000\n",
      "Epoch 946/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - loss: 24190230528.0000 - val_loss: 36197638144.0000\n",
      "Epoch 947/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 23663650816.0000 - val_loss: 38107463680.0000\n",
      "Epoch 948/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 22661150720.0000 - val_loss: 37394317312.0000\n",
      "Epoch 949/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 447us/step - loss: 22310424576.0000 - val_loss: 31439720448.0000\n",
      "Epoch 950/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - loss: 23593699328.0000 - val_loss: 37226577920.0000\n",
      "Epoch 951/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - loss: 22250201088.0000 - val_loss: 37886881792.0000\n",
      "Epoch 952/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431us/step - loss: 23219347456.0000 - val_loss: 38203179008.0000\n",
      "Epoch 953/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - loss: 24174452736.0000 - val_loss: 42676056064.0000\n",
      "Epoch 954/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 23410749440.0000 - val_loss: 37503442944.0000\n",
      "Epoch 955/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 21845878784.0000 - val_loss: 33867626496.0000\n",
      "Epoch 956/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - loss: 22323712000.0000 - val_loss: 36047691776.0000\n",
      "Epoch 957/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - loss: 23689189376.0000 - val_loss: 35780427776.0000\n",
      "Epoch 958/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 23451512832.0000 - val_loss: 35487854592.0000\n",
      "Epoch 959/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 26396930048.0000 - val_loss: 40889638912.0000\n",
      "Epoch 960/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - loss: 22703900672.0000 - val_loss: 38947282944.0000\n",
      "Epoch 961/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - loss: 22156093440.0000 - val_loss: 34462461952.0000\n",
      "Epoch 962/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 435us/step - loss: 22917275648.0000 - val_loss: 33512501248.0000\n",
      "Epoch 963/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 23304112128.0000 - val_loss: 37593030656.0000\n",
      "Epoch 964/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 24242298880.0000 - val_loss: 35887665152.0000\n",
      "Epoch 965/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 23181072384.0000 - val_loss: 37733928960.0000\n",
      "Epoch 966/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 22954600448.0000 - val_loss: 37095899136.0000\n",
      "Epoch 967/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 23478102016.0000 - val_loss: 38668025856.0000\n",
      "Epoch 968/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 22034368512.0000 - val_loss: 34882576384.0000\n",
      "Epoch 969/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 20966158336.0000 - val_loss: 41420529664.0000\n",
      "Epoch 970/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 23952224256.0000 - val_loss: 40017768448.0000\n",
      "Epoch 971/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 22842628096.0000 - val_loss: 44545437696.0000\n",
      "Epoch 972/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 22891866112.0000 - val_loss: 37313458176.0000\n",
      "Epoch 973/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 23158947840.0000 - val_loss: 41035821056.0000\n",
      "Epoch 974/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 22039674880.0000 - val_loss: 34445012992.0000\n",
      "Epoch 975/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 22872375296.0000 - val_loss: 36263841792.0000\n",
      "Epoch 976/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 24693796864.0000 - val_loss: 39224119296.0000\n",
      "Epoch 977/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 20402104320.0000 - val_loss: 35396026368.0000\n",
      "Epoch 978/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 24471193600.0000 - val_loss: 34081886208.0000\n",
      "Epoch 979/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 22340630528.0000 - val_loss: 36509995008.0000\n",
      "Epoch 980/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 404us/step - loss: 22458587136.0000 - val_loss: 39977918464.0000\n",
      "Epoch 981/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 23269814272.0000 - val_loss: 39876075520.0000\n",
      "Epoch 982/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 22554857472.0000 - val_loss: 40755585024.0000\n",
      "Epoch 983/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 23571294208.0000 - val_loss: 34612867072.0000\n",
      "Epoch 984/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 24641449984.0000 - val_loss: 38442323968.0000\n",
      "Epoch 985/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441us/step - loss: 25431824384.0000 - val_loss: 40035336192.0000\n",
      "Epoch 986/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 25180569600.0000 - val_loss: 35267248128.0000\n",
      "Epoch 987/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 23515224064.0000 - val_loss: 35938177024.0000\n",
      "Epoch 988/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 24624906240.0000 - val_loss: 43835584512.0000\n",
      "Epoch 989/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - loss: 22729648128.0000 - val_loss: 38244511744.0000\n",
      "Epoch 990/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 22525448192.0000 - val_loss: 39631581184.0000\n",
      "Epoch 991/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 22387253248.0000 - val_loss: 34631282688.0000\n",
      "Epoch 992/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 22639788032.0000 - val_loss: 38953390080.0000\n",
      "Epoch 993/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 21599330304.0000 - val_loss: 36773613568.0000\n",
      "Epoch 994/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436us/step - loss: 23939031040.0000 - val_loss: 42277941248.0000\n",
      "Epoch 995/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 22904227840.0000 - val_loss: 41497939968.0000\n",
      "Epoch 996/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 22755803136.0000 - val_loss: 37742829568.0000\n",
      "Epoch 997/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440us/step - loss: 22788638720.0000 - val_loss: 36891377664.0000\n",
      "Epoch 998/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390us/step - loss: 21246277632.0000 - val_loss: 40849891328.0000\n",
      "Epoch 999/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 22575806464.0000 - val_loss: 41079881728.0000\n",
      "Epoch 1000/1000\n",
      "\u001b[1m473/473\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - loss: 22458454016.0000 - val_loss: 37552439296.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x29ceabc40>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using validation again for better metrics and optimization\n",
    "model.fit(x=X_train, y=y_train, epochs=1000, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Training metrics</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data evaluation:\n",
      "41510330368.0\n",
      "\n",
      "Train data evaluation:\n",
      "40222883840.0\n"
     ]
    }
   ],
   "source": [
    "# compare test error values to training error values\n",
    "# the model is often good when these error values are similar\n",
    "# even if you training metrics above didn't overlap\n",
    "# you might still get very close values in evaluation => more important\n",
    "\n",
    "# compare the final model loss/evaluation values\n",
    "print(\"Test data evaluation:\")\n",
    "print(model.evaluate(X_test, y_test, verbose=0))\n",
    "print(\"\\nTrain data evaluation:\")\n",
    "print(model.evaluate(X_train, y_train, verbose=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Make some test predictions to see what kind of mistakes the model makes</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test True Y</th>\n",
       "      <th>Model Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>470000.00</td>\n",
       "      <td>508526.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>385000.00</td>\n",
       "      <td>373383.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>488500.00</td>\n",
       "      <td>465300.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>890000.00</td>\n",
       "      <td>459795.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>300000.00</td>\n",
       "      <td>328083.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>450000.00</td>\n",
       "      <td>454300.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>1375000.00</td>\n",
       "      <td>1017249.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>625000.00</td>\n",
       "      <td>566130.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>520000.00</td>\n",
       "      <td>1304442.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>568000.00</td>\n",
       "      <td>521966.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3242 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Test True Y  Model Predictions\n",
       "0       470000.00          508526.97\n",
       "1       385000.00          373383.69\n",
       "2       488500.00          465300.72\n",
       "3       890000.00          459795.56\n",
       "4       300000.00          328083.97\n",
       "...           ...                ...\n",
       "3237    450000.00          454300.53\n",
       "3238   1375000.00         1017249.19\n",
       "3239    625000.00          566130.25\n",
       "3240    520000.00         1304442.50\n",
       "3241    568000.00          521966.34\n",
       "\n",
       "[3242 rows x 2 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# reshape the data for easier comparison table\n",
    "test_predictions = pd.Series(test_predictions.reshape(len(y_test),))\n",
    "pred_df = pd.DataFrame(np.asarray(y_test), columns=['Test True Y'])\n",
    "pred_df = pd.concat([pred_df, test_predictions], axis=1)\n",
    "pred_df.columns = ['Test True Y', 'Model Predictions']\n",
    "\n",
    "# print the comparison table - true values vs. model predicted values\n",
    "# we can nicely see here how far off our model is in some cases\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Test True Y', ylabel='Model Predictions'>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# these values follow a linear line = good predictions\n",
    "# we basically compare the predicted values \n",
    "# to true test values and see the differences\n",
    "sns.scatterplot(x='Test True Y', y='Model Predictions', data=pred_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Regression error metrics</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE\n",
      "83350.12 $\n",
      "\n",
      "MSE\n",
      "41510326211.11 $^2\n",
      "\n",
      "RMSE:\n",
      "203740.83 $\n",
      "\n",
      "R-squared:\n",
      "0.75\n",
      "\n",
      "Explained variance score:\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "# MAE - Mean average error\n",
    "print(\"MAE\")\n",
    "print(round(metrics.mean_absolute_error(y_test, test_predictions), 2), \"$\")\n",
    "\n",
    "# MSE - Mean square error\n",
    "print(\"\\nMSE\")\n",
    "print(round(metrics.mean_squared_error(y_test, test_predictions), 2), \"$^2\")\n",
    "\n",
    "# RMSE - Root mean square error\n",
    "print('\\nRMSE:')\n",
    "print(round(np.sqrt(metrics.mean_squared_error(y_test, test_predictions)), 2), \"$\")\n",
    "\n",
    "# R-squared. 0 = the model descibes the dataset poorly\n",
    "# 1 = model describes the dataset perfectly\n",
    "print('\\nR-squared:')\n",
    "print(round(metrics.r2_score(y_test, test_predictions), 2))\n",
    "\n",
    "# Explained Variance Score => 0 = the model descibes the dataset poorly\n",
    "# 1 = model describes the dataset perfectly\n",
    "# high variance score = model is a good fit for the data \n",
    "# low variance score = model is not a good fit for the data\n",
    "# the higher the score, the model is more able to explain the variation in the data\n",
    "# if score is low, we might need more and better data\n",
    "print(\"\\nExplained variance score:\")\n",
    "print(round(metrics.explained_variance_score(y_test, test_predictions), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gc/n9f0hqw521d0_z3nmf82zyrc0000gn/T/ipykernel_1691/3124900743.py:5: UserWarning: \n",
      "\n",
      "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
      "\n",
      "Please adapt your code to use either `displot` (a figure-level function with\n",
      "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "\n",
      "For a guide to updating your code to use the new functions, please see\n",
      "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
      "\n",
      "  sns.distplot((y_test - test_predictions))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# if the prediction distribution are far from normal distribution\n",
    "# then the model is not probably good enough\n",
    "# distplot is deprecating in future pandas-version\n",
    "# unfortunately, there's no exact alternative to do this plot at the moment\n",
    "sns.distplot((y_test - test_predictions))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Lets' try the model in practice</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['bathrooms', 'sqft_living', 'sqft_lot', 'view', 'condition', 'grade',\n",
       "       'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated',\n",
       "       'sqft_living15', 'waterfront', 'sqft_lot15', 'long', 'lat', 'zipcode'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>231300.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.51</td>\n",
       "      <td>-122.26</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538000.00</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.72</td>\n",
       "      <td>-122.32</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180000.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.74</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604000.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.52</td>\n",
       "      <td>-122.39</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510000.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.62</td>\n",
       "      <td>-122.05</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  bathrooms  sqft_living  sqft_lot  waterfront  view  condition  \\\n",
       "0 231300.00       1.00         1180      5650           0     0          3   \n",
       "1 538000.00       2.25         2570      7242           0     0          3   \n",
       "2 180000.00       1.00          770     10000           0     0          3   \n",
       "3 604000.00       3.00         1960      5000           0     0          5   \n",
       "4 510000.00       2.00         1680      8080           0     0          3   \n",
       "\n",
       "   grade  sqft_above  sqft_basement  yr_built  yr_renovated  zipcode   lat  \\\n",
       "0      7        1180              0      1955             0    98178 47.51   \n",
       "1      7        2170            400      1951          1991    98125 47.72   \n",
       "2      6         770              0      1933             0    98028 47.74   \n",
       "3      7        1050            910      1965             0    98136 47.52   \n",
       "4      8        1680              0      1987             0    98074 47.62   \n",
       "\n",
       "     long  sqft_living15  sqft_lot15  \n",
       "0 -122.26           1340        5650  \n",
       "1 -122.32           1690        7639  \n",
       "2 -122.23           2720        8062  \n",
       "3 -122.39           1360        5000  \n",
       "4 -122.05           1800        7503  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'bedrooms'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bedrooms'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[151], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbedrooms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39munique()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bedrooms'"
     ]
    }
   ],
   "source": [
    "df['bedrooms'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try with some new imaginary data\n",
    "# this example uses the student performance index score dataset\n",
    "# modify this as needed regarding your own dataset\n",
    "tester_row = {\n",
    "    'bedrooms': 3,\n",
    "    'bathrooms': 2.0, \n",
    "    'sqft_living': 1680, \n",
    "    'sqft_lot': 8080,\n",
    "    'floors': 1.0, \n",
    "    'view': 0,\n",
    "    'condition': 3, \n",
    "    'grade': 8, \n",
    "    'sqft_above': 1680, \n",
    "    'sqft_basement': 0, \n",
    "    'yr_built': 1987,\n",
    "    'yr_renovated': 0\n",
    "}\n",
    "\n",
    "# convert to pandas-format\n",
    "tester_row = pd.DataFrame([tester_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(tester_row)[0]\n",
    "\n",
    "print()\n",
    "print(f\"Estimated price for this house:\")\n",
    "print(f\"{round(float(result[0]), 2)} $\")\n",
    "print(\"----------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
